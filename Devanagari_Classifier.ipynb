{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CLASIFICADOR DEVANAGARI**"
      ],
      "metadata": {
        "id": "ZPIqgzEtOtfi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NOMBRE DE LOS AUTORES:**\n",
        "\n",
        "1. César Alberto Mayora Suárez\n",
        "2. Lucas Martín García\n",
        "\n",
        "# **BASE DE DATOS SELECCIONADA**\n",
        "13. Devanagari Handwritten Dataset"
      ],
      "metadata": {
        "id": "btjruC-C0HnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Aclaración inicial: Debido al alto coste computacional de los modelos al entrenarse con el conjutno de datos, este documento tarda entre 15 y 20 minutos en ejecutarse completamente, pero no se queda nunca ejecutando indefinidamente, y los resultados del principio aparecen a medida que se ejecutan para poder ir visualizándose mientras que se ejecuta el resto (en el caso de que se quiera volver a ejecutar el documento)."
      ],
      "metadata": {
        "id": "c4Qr3MBSS2sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Como digerir el archivo .npz\n",
        "- Localizar el archivo localmente, desde Google Drive o bajarlo desde Internet\n",
        "- Utilizar `numpy.load` para obtener los arrays:\n",
        "```\n",
        "data = np.load(\"/path/to/data.npz\")\n",
        "```\n",
        "- Obtener los arrays mediante acceso al diccionario de `data`de la siguiente manera:\n",
        "```\n",
        "X_train, y_train = data['X_train'], data['y_train']\n",
        "X_test, y_test = data['X_test'], data['y_test']\n",
        "```\n",
        "\n",
        "'''\n",
        "\n",
        "# TODO: realizar la descarga de estos archivos y su respectiva separacion en training y test\n",
        "# propia si lo requiere, o sino dejarlo asi y solo descargar los archivos\n",
        "# Más adelante se realiza la inclusión del archivo con los datos en el código"
      ],
      "metadata": {
        "id": "30YOCo1e0jKW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "04113c00-3f11-451a-f9f6-abc6584d073f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nComo digerir el archivo .npz\\n- Localizar el archivo localmente, desde Google Drive o bajarlo desde Internet\\n- Utilizar `numpy.load` para obtener los arrays:\\n```\\ndata = np.load(\"/path/to/data.npz\")\\n```\\n- Obtener los arrays mediante acceso al diccionario de `data`de la siguiente manera:\\n```\\nX_train, y_train = data[\\'X_train\\'], data[\\'y_train\\']\\nX_test, y_test = data[\\'X_test\\'], data[\\'y_test\\']\\n```\\n\\nNOTA: La separacion de training y test es la misma que la que viene por defecto en la\\ndescarga del repositorio de la UCI: https://consigna.ugr.es/?s=download&token=443be550-94ee-48dc-9ca4-5d797aa349d7\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from sklearn.base import clone\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import KFold, cross_validate\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, log_loss, hinge_loss, make_scorer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from skimage import feature\n",
        "from skimage import io\n",
        "\n",
        "\n",
        "#Para acceder a nuestros ficheros de Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "# La carpeta datos (que contiene X_train.npy, y_train.npy, X_test.npy y y_test.npy)\n",
        "# debe estar en vuestro Drive, dentro de la carpeta 'Colab Notebooks'\n",
        "\n",
        "# Establecemos la semilla del RNG\n",
        "np.random.seed(33)\n",
        "\n",
        "# Mapeo de clases a etiquetas (SOLO PARA FUTURAS REFERENCIAS)\n",
        "map_labels = {\n",
        "\t'character_1_ka': 0,\n",
        "\t'character_2_kha': 1,\n",
        "\t'character_3_ga': 2,\n",
        "\t'character_4_gha': 3,\n",
        "\t'character_5_kna': 4,\n",
        "\t'character_6_cha': 5,\n",
        "\t'character_7_chha': 6,\n",
        "\t'character_8_ja': 7,\n",
        "\t'character_9_jha': 8,\n",
        "\t'character_10_yna': 9,\n",
        "\t'character_11_taamatar': 10,\n",
        "\t'character_12_thaa': 11,\n",
        "\t'character_13_daa': 12,\n",
        "\t'character_14_dhaa': 13,\n",
        "\t'character_15_adna': 14,\n",
        "\t'character_16_tabala': 15,\n",
        "\t'character_17_tha': 16,\n",
        "\t'character_18_da': 17,\n",
        "\t'character_19_dha': 18,\n",
        "\t'character_20_na': 19,\n",
        "\t'character_21_pa': 20,\n",
        "\t'character_22_pha': 21,\n",
        "\t'character_23_ba': 22,\n",
        "\t'character_24_bha': 23,\n",
        "\t'character_25_ma': 24,\n",
        "\t'character_26_yaw': 25,\n",
        "\t'character_27_ra': 26,\n",
        "\t'character_28_la': 27,\n",
        "\t'character_29_waw': 28,\n",
        "\t'character_30_motosaw': 29,\n",
        "\t'character_31_petchiryakha': 30,\n",
        "\t'character_32_patalosaw': 31,\n",
        "\t'character_33_ha': 32,\n",
        "\t'character_34_chhya': 33,\n",
        "\t'character_35_tra': 34,\n",
        "\t'character_36_gya': 35,\n",
        "    'digit_0': 36,\n",
        "    'digit_1': 37,\n",
        "    'digit_2': 38,\n",
        "    'digit_3': 39,\n",
        "    'digit_4': 40,\n",
        "    'digit_5': 41,\n",
        "    'digit_6': 42,\n",
        "    'digit_7': 43,\n",
        "    'digit_8': 44,\n",
        "    'digit_9': 45,\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bfcd984-6116-49d7-d96e-15858bae6a0a",
        "id": "zgah6msrH3wl"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **COMIENZO DEL PROYECTO**"
      ],
      "metadata": {
        "id": "0I-pM_F_1i29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descripción y planteamiento del problema\n",
        "\n",
        "Planteamos un problema de clasificación donde se desea construir un sistema de clasificación de caracteres manuscritos del sistema de escritura _**Devanagari**_ o _Devanāgarī_ (ver Figura 1), formalmente descrito como un _Abugida_ o pseudo-alfabeto que consta de $46$ caracteres (en nuestro caso) y es el sistema oficial de escritura en países como la India y Nepal.\n",
        "\n",
        "Nuestro objetivo es poder diseñar y entrenar un modelo de Machine Learning que mejor reconozca o clasifique estos caracteres manuscritos de forma individual (clasificar un caracter dado).\n",
        "\n",
        "![devanagari_1](http://luc.devroye.org/DevanagariAlphabet-1933.png)\n",
        "\n",
        "_[Figura 1](http://luc.devroye.org/DevanagariAlphabet-1933.png): Ejemplo de caracteres del sistema Devanagari_\n",
        "\n",
        "### Datos disponibles\n",
        "\n",
        "Contamos con un conjunto de datos o _dataset_ de dominio público y que podemos encontrar en el repositorio de la UCI (*). Este _dataset_ cuenta con una serie de imágenes en formato PNG etiquetadas con una resolución de $32 \\times 32$ píxeles en escala de grises, es decir, cada píxel de una imágen tendrá un valor entre $[0,255]$, donde $0$ indica un color negro mientras que $255$ indica un color blanco.\n",
        "\n",
        "Disponemos de un total de $92000$ imágenes o ejemplos en nuestro conjunto de datos y de $46$ clases con $2000$ ejemplos cada una. El _dataset_ viene dividido por defecto en dos conjuntos de datos: uno de training y uno de test con un $85\\%$ y un $15\\%$ de los ejemplos totales respectivamente.\n",
        "\n",
        "### Objetivo propuesto\n",
        "\n",
        "Nuestro objetivo es poder diseñar y entrenar un modelo de Machine Learning a partir de nuestros datos disponibles usando un conjunto de entrenamiento (training) para el aprendizaje y selección del mejor modelo de clasificación y un conjunto de test para la evaluación del modelo final. Buscamos obtener el mejor modelo de clasificación que maximice la precisión (_accuracy_) en la clasificación de estas imágenes.\n",
        "\n",
        "Para ello, consideraremos un modelo lineal y dos modelos no lineales, y mediante una proceso de selección de modelos o _model selection_, compararemos y elegiremos el mejor modelo de clasificación para nuestro problema, evaluándo su rendimiento final con el conjunto de test.\n",
        "\n",
        "### Descripción formal del problema\n",
        "\n",
        "Describimos formalmente nuestro problema identificando sus principales componentes. En primer lugar, disponemos de un conjunto de datos (o secuencia de datos) $\\mathcal D$ que está compuesta por una secuencia de ejemplos de la forma $(\\text{x}_1, y_1), ..., (\\text{x}_N, y_N)$, donde $\\text{x}_n$ es un vector de características que definen a un caracter (imágen) concreto, e $y_n$ representa el respectivo nombre del caracter (etiqueta).\n",
        "\n",
        "Definimos el espacio de entrada como $\\mathcal X = ℝ^d$ como un espacio $d$-dimensional de valores reales, en nuestro caso, cada píxel de entrada de una imágen está definido por números enteros en $ℕ$ pero nos conviene usar valores reales en este caso ya que probablemente estos valores pueden ser modificados o transformados y necesitamos que el espacio de entrada extrapole a un espacio real; en todo caso como $ℕ ⊂ ℝ$, nos es válido.\n",
        "\n",
        "Definimos el espacio de salida $\\mathcal Y = \\{0, 1, ..., 45\\}$ donde cada etiqueta $y_i \\in \\mathcal Y$ representa una clase de nuestro problema $C_{i}$. Cada clase corresponde al nombre de cada caracter de nuestro conjunto de datos:\n",
        "$$C_0 = \\textit{\"ka\"}, C_1 = \\textit{\"kha\"}, C_2=\\textit{\"ga\"}, ...$$\n",
        "\n",
        "Definimos nuestra función objetivo $f: \\mathcal X → \\mathcal Y$ que es la función que perfecta y exactamente clasifica los ejemplos de la población y consecuentemente de nuestro conjunto de datos $\\mathcal D$ asignando a cada ejemplo $\\text{x}_n \\in \\mathcal X$ un valor en $y_n \\in \\mathcal Y$. Esta función es y será desconocida para nosotros y es la que intentaremos mediante el ajuste de un modelo de aprendizaje aproximar para clasificar lo mejor posible y con el mínimo error los datos de entrada.\n",
        "\n",
        "> (*) Acharya,Shailesh and Gyawali,Prashnna. (2016). Devanagari Handwritten Character Dataset. UCI Machine Learning Repository. https://doi.org/10.24432/C5XS53."
      ],
      "metadata": {
        "id": "_EL7_2SeUaVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definición de los conjuntos de hipótesis y modelos de aprendizaje usados\n",
        "\n",
        "#### Clase de funciones $\\mathcal H$-lineal -  Modelo lineal\n",
        "Definimos entonces el conjunto de hipótesis que consideraremos en la construcción de nuestros modelos de aprendizaje. En primer lugar consideraremos un conjunto de hipótesis $\\mathcal H$ lineal; para este problema de clasificación tomaremos la clase de funciones lineales más simple que consiste en una combinación lineal de los datos de entrada $\\text{x}$ ponderados con un vector de pesos $\\text{w} \\in ℝ^{d+1}$, por tanto nuestras funciones hipótesis tendrán la forma\n",
        "\n",
        "$$h(\\text{x}) = w_0 + \\sum_{j=1}^{d}{w_j x_j}$$\n",
        "\n",
        "donde $w_0$ es el parámetro denominado _bias_, y que nos permite fijar una base en el modelo que puede influir en la aproximación a la función objetivo mediante el algoritmo de aprendizaje $\\mathcal A$.\n",
        "\n",
        "Para tener una notación más conveniente a lo largo de la solución a este problema, podemos fijar un parámetro en los datos de entrada $\\text{x}$ para que multiplique a este _bias_, quedándonos de esta forma matricial más conveniente:\n",
        "\n",
        "$$h(\\text{x}) = \\sum_{j=0}^{d}{w_j\\phi_j(\\text{x})} = \\text{w}^T\\phi(\\text{x})$$\n",
        "\n",
        "donde $\\phi$ es una denominada _basis function_, que es una función que transforma los datos de entrada $\\text{x}$; la razón por la cual es una conveniencia usar una _basis function_ es porque los datos de entrada durante el procesamiento de los datos sufren transformaciones, preprocesamiento previo o extracción de características (_feature extraction_), siendo luego estos datos preprocesados de los datos originales los que se usarán para la predicción y el aprendizaje del modelo; por tanto, todas las posibles transformaciones podemos expresarlas en términos de _basis functions_ $\\{\\phi_j(\\text{x})\\}$.\n",
        "\n",
        "Nosotros también cambiaremos la notación de la combinación lineal $h(\\text{x})$ a $s(\\text{x})$ tratándola como una \"señal\" más que un predictor. Esto es porque los modelos que hacen uso de esta clase de hipótesis usan una función de predicción diferente que hace uso de esta señal. Sin embargo, hay que tener en cuenta que la clase de funciones de donde queremos obtener el mejor predictor $g$ es uno del tipo $g(\\text{x}) = \\text{w}^T\\phi$, como antes habiamos mencionado, y es en esencia el modelo final de clasificación.\n",
        "\n",
        "Con esta primera clase de funciones lineales podemos definir lo que será nuestro modelo lineal de clasificación, en nuestro caso hemos elegido el modelo de __Regresión Logística__ o RL que consiste en el aprendizaje de los pesos óptimos $\\text{w}$ para calcular la __probabilidad__ de que un ejemplo pertenezca a una clase u otra, es decir, calcula un número en el rango $[0,1]$ que indica esta probabilidad. El clasificador RL se define de la siguiente manera:\n",
        "\n",
        "$$h(\\text{x}_i) = \\theta(s(\\text{x})) = \\theta(\\text{w}^T\\phi(\\text{x}_i))$$\n",
        "\n",
        "donde $\\theta$ es la denominada función logística (_logistic function_) que es una función no lineal aplicada a la combinación lineal de pesos y que asigna una probabilidad entre $[0,1]$. La función logística que usaremos será la función _sigmoide_ por ser una función ampliamente utilizada, es una función derivable y es una función que está acotada para sus valores extremos por lo que es facilmente interpretable en términos probabilísticos.\n",
        "\n",
        "$$\\sigma(s(\\text{x}_n)) = \\frac{1}{1 - e^{-s(\\text{x}_n)}} \\rightarrow\n",
        "\\begin{cases}\n",
        "\\ge 0.5 & y_n = +1 \\\\\n",
        "\\lt 0.5 & y_n = -1\n",
        "\\end{cases}$$\n",
        "\n",
        "Nosotros elegimos RL como primer modelo ya que en general es bastante utilizado en problemas de clasificación y es conocido por ser uno de los mejores modelos de clasificación gracias a su fundamento probabilístico y por ser insensible al ruido, lo cual lo hace un buen clasificador cuando hay mucha presencia de ruido estocástico.\n",
        "\n",
        "#### Modelos no lineales\n",
        "\n",
        "A continuación definiremos dos modelos de clasificación no lineales. Estos modelos se consideran no lineales por ser capaces de capturar características o aspectos no lineales en los datos siendo modelos muy poderosos cuando hay mucha presencia de mucho ruido determinístico o cuando el dominio del problema es muy complejo; nosotros hemos elegido dos de ellos: __SVM-soft__ con kernel no lineal y __Perceptrón Multicapa__.\n",
        "\n",
        "El primero de ellos, el modelo SVM-soft con kernel no lineal es un modelo que consiste en la optimización de pesos $\\text{w}$ de nuestro modelo para conseguir el hiperplano óptimo que separe los ejemplos con el mayor márgen posible (_fat margin_). La función de clasificación del SVM se define muy similar a otros modelos como el Perceptrón que usan la función no lineal escalonada:\n",
        "\n",
        "$$h(s(\\text{x}_i)) = \\text{sign}(s(\\text{x}_i))$$\n",
        "\n",
        "Como podemos ver, usa la función no lineal escalonada, que se interpreta como el \"signo\" de la señal:\n",
        "$$h(s(\\text{x}_i)) =\n",
        "\\begin{cases}\n",
        "s(\\text{x}_i) < 0 & y_n = -1 \\\\\n",
        "s(\\text{x}_i) > 0 & y_n = +1\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Nosotros usamos la formalización _soft_ que quiere decir _soft margin_, que consiste en establecer una restricción $C$ correspondiente a la tolerancia de error de clasificación (ejemplos mal clasificados) que puede permitir el modelo. Por tanto, este modelo tratará de optimizar el siguiente problema, llamado el problema Primal:\n",
        "\n",
        "$$\\min_{b, \\text{w}, \\xi}{\\frac{1}{2} \\text{w}^T\\text{w} + C\\sum_{i=0}^{N}{\\xi_i}} \\\\\n",
        "\\text{subject to:} \\ \\ y_n(\\text{w}^T\\text{x}_n + b) \\ge 1 - \\xi_n\n",
        "$$\n",
        "\n",
        "donde $b$ es el _bias_ y $\\xi$ es el número de ejemplos mal clasificados. El modelo SVM-soft es un clasificador muy reconocido por ser un modelo que optimiza el mismo hiperplano para ser el mejor cuando generaliza fuera de la muestra ya que la maximización del márgen (_fat margin_) lleva implícita regularización, disminuyendo la dimensión VC del modelo, por lo que lo hace especialmente bueno cuando se enfrenta a datos que no ha visto antes.\n",
        "\n",
        "Este modelo aunque use una clase de funciones lineal ($h(\\text{x}) = \\text{w}^T\\phi(\\text{x}))$), se considera un modelo no lineal al hacer uso de un kernel no lineal, puesto que estos kernels mapean los datos de entrada en $\\mathcal X$ a un espacio de mayor dimensión $\\mathcal Z$ donde puede encontrar el separador óptimo cuando los datos no son linealmente separables. En nuestro caso, usaremos el kernel __RBF-Gaussiano_, un kernel no lineal.\n",
        "\n",
        "El último modelo que vamos a utilizar es un Perceptrón Multicapa (_Multilayer Perceptron_ o MLP) que es un tipo de Red Neuronal Artificial (ANN) que consiste en la combinación de múltiples modelos de Perceptrón organizadas en múltiples capas de neuronas completamente conectadas. Aunque el nombre haga referencia a usar modelos de Perceptrón, realmente puede comprender modelos lineales mucho más potentes como la Regresión Logística (RL), que involucra una función de activación no lineal $θ$. Nosotros usaremos este enfoque de MLP como un compendio de múltiples modelos de Regresión Logística organizados en una arquitectura de neuronas interconectadas.\n",
        "\n",
        "MLP esta basado en una Red Neuronal de tipo _feed-forward_, en el que los datos de entrada entran por una capa de entrada y fluye sobre las capas sucesivas ocultas hasta una capa de salida.\n",
        "\n",
        "El uso de diferentes neuronas interconectadas, en el que cada neurona es un modelo de Regresión Logística, es lo que hace que este modelo sea no lineal, ya que podemos usar múltiples modelos RL para combinar sus datos de salida y así poder aumentar la capacidad de clasificación y poder capturar un patrón subyaciente más complejo.\n",
        "\n",
        "La función de predicción $h(\\text{x})$ del MLP está definida por el algoritmo de propagación hacia adelante (_forward propagation_):\n",
        "\n",
        "$$s^{(l)}_j = (\\text{W}^{(l)})^T \\text{x}^{(l-1)}$$\n",
        "\n",
        "donde $\\text{W}^{(l)}$ son todos los pesos en la capa $l$ y $\\text{x}^{(l)}$ es la salida dada por la capa $\\theta(s^{(l)})$\n",
        "\n",
        "Luego, la función de predicción viene dada por aplicar el algoritmo de _forward propagation_ en la última capa $L$\n",
        "\n",
        "$$h(\\text{x}) = \\theta(s^{(L)}) = \\theta((\\text{W}^{(L)})^T \\text{x}^{(L-1)})$$\n",
        "\n",
        "Ahora necesitamos definir la arquitectura de nuestra red que sería lo equivalente a fija una clase de funciones $\\mathcal H_{nn}$. Nosotros usaremos una arquitectura de $L=3$ capas, es decir, una capa de entrada (_input layer_), $2$ capas ocultas (_hidden layer_) y una capa de salida (_output layer_). Cada capa $l$ tiene una dimensión $d(l)$, que quiere decir que en la capa $l$ hay $d(l)+1$ neuronas etiquetadas como $0,1,2,...,d(l)$ (la neurona $0$ es la neurona _bias_o sesgo). Para que nuestra arquitectura esté bien definida debemos de asignar la dimensión a cada capa $l$ de nuestra red, sin embargo, este parámetro puede influir en gran medida, pues a mayor dimensión por capa, estamos aumentando la complejidad de $\\mathcal H_{nn}$ lo que puede resultar en sobreajuste, por tanto, nos sería conveniente tratar $d(l)$ para cada capa $l$ como un hiperparámetro del modelo. Como tenemos aún así que definir $\\mathcal H_{nn}$ podemos establecer un rango de valores para esta dimensión como un rango que varía entre $50$ y $100$, de esta manera definimos un conjunto de hipótesis aproximado.\n",
        "\n",
        "También tenemos que definir, luego de establecer la arquitectura de la red, las funciones de activación $\\theta$ de cada neurona, que son las que definen las _basis functions_ de cada neurona, como MLP aprende estas los parámetros de estas funciones (que son los pesos y el _bias_), tendremos que prefijar estas funciones de activación antes de entrenar nuestro modelo. Nosotros optaremos por la función ReLU (Rectified Linear Unit) $f(\\text{x}) = θ(\\text{w}^T\\phi(\\text{x})) = ReLU(\\text{w}^T\\phi(\\text{x}))$ para cada neurona. Elegimos esta función porque tiene una ventaja a nivel de eficiencia computacional por no usar cálculos exponenciales como en el caso de la sigmoide, y porque activa las neuronas cuyo valor es positivo, por lo que promueve la dispersión de las características en la red y capturar mejor las relaciones no lineales al solo tomar en cuenta las neuronas relevantes, a diferencia de las funciones sigmoide y tangente hiperbólica que toma en cuenta valores negativos que realmente solo dan redundancia en la red."
      ],
      "metadata": {
        "id": "BPBLEnFDl_KL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Función de perdida y métricas de error\n",
        "\n",
        "#### Métricas de error\n",
        "A continuación vamos a definir cuales son las métricas de error a usar en este problema de clasificación así como decir para cada una que información nos aporta.\n",
        "\n",
        "Las métricas que usaremos son por una parte, sacadas de la matriz de confusión, y otras, son específicas para problemas de clasificación multietiqueta. La matriz de confusión es una herramienta muy usada en Machine Learning para evaluar el rendimiento de un modelo de ML. Se suele usar mayoritariamente en problemas de clasificación y tiene una estructura tabular y que compara la frecuencia de clases predichas por el modelo y su valor real.\n",
        "\n",
        "![](https://dataaspirant.com/3_confusion_matrix/)\n",
        "_Figura tomada de https://dataaspirant.com/wp-content/uploads/2020/08/3_confusion_matrix.png_\n",
        "\n",
        "A partir de la matriz de confusión se pueden calcular métricas para evaluar un modelo de clasificación. Entre ellas se encuentran las que usaremos que son:\n",
        "\n",
        "- _Accuracy_ o exactitud: nos permite medir su tasa de clasificación correcta, es decir, la fracción de ejemplos que ha clasificado correctamente (independientemente de su clase). Se calcula como:\n",
        "$$\\frac{TP + TN}{TP + TN + FP + FN}$$\n",
        "- _Specificity_ o especificidad: Mide la fracción de las muestras que han sido clasificadas como negativas y que realmente fueron negativas, es decir, nos da una métrica para medir que tan bien clasifica la clase negativa. Se calcula como:\n",
        "$$\\frac{TN}{TN + FP}$$\n",
        "- F1-Score: Esta métrica combina dos métricas denominadas _Recall_ y _Precision_ en un valor único, y es especialmente útil cuando queremos encontrar un equilibrio entre los falsos positivos y falsos negativos. Se calcula como:\n",
        "$$\\frac{2\\cdot (\\text{Precision}\\cdot \\text{Recall})}{(\\text{Precision}+ \\text{Recall})}$$\n",
        "\n",
        "Como podemos observar, estamos eligiendo las métricas que nos pueden dar una mejor percepción global del rendimiento de un modelo. Si observamos por un lado la _Accuracy_ no engloba la tasa de clasificación correcta de nuestro modelo, es decir, que tanto nuestro modelo acierta en proporción, esta métrica se considera de las más importantes porque es la que más engloba el rendimiento de un clasificador sin importar la clase que esta prediciendo. Sin embargo, es por esta generalidad de la _Accuracy_ que por sí sola no podemos utilizar para evaluar un modelo frente a otros, sobre todo cuando hay clases desbalanceadas, ya que podemos construir un clasificador con _Accuracy_ de un $80\\%$ pero en un conjunto de datos que tiene un $80\\%$ de desbalanceo, luego un clasificador que prediga con la media, consigue la misma _accuracy_.\n",
        "\n",
        "Para abordar el problema de usar solo la _accuracy_ tenemos que evaluar el rendimiento del clasificador tanto con la clase negativa como la positiva. En este caso utilizamos por un lado F1-Score que especialmente útil en estos casos de desbalanceo de etiquetas, ya que se considera un métrica muy robusta que balancea el peso de la clase menos representada realizando la media armónica del _Recall_ y de la _Precision_. Sin embargo, el _Recall_ y la _Precision_ solo tienen en cuenta la clase positiva y ahí es donde entra la última métrica, la _Specificity_ que mide que tan bien clasifica la clase negativa, completando el cálculo del rendimiento de un modelo.\n",
        "\n",
        "Con estas métricas seremos capaces de elegir de forma sensata y con bastante criterio aquel modelo que mejor clasifica una muestra de datos. He de decir, que cada métrica puede ser ponderada de manera que le demos más importancia a una que de otra, esto por supuesto depende del problema concreto a tratar y que estudiaremos más a detalle cuando definamos el _scorer_ que usaremos para realizar el _ranking_ que nos elegirá el mejor modelo.\n",
        "\n",
        "#### Funciones de perdida\n",
        "\n",
        "Nos queda por definir las funciones de perdida para nuestros modelos de clasificación. Empezaremos por la función de perdida para Regresión Logística que será la función de Entropía Cruzada o _cross entropy_ definida por:\n",
        "\n",
        "$$E(\\text{w}) = \\frac{1}{N}\\sum_{n=0}^{N}{\\ln{(1 - e^{-y_n\\text{w}^T\\text{x}_n})}}$$\n",
        "\n",
        "Esta función, también denominada como función de perdida logística, es ampliamente usada por estar basada en la probabilidad de semejanza o _likelihood_ de un ejemplo según la distribución de probabilidad que se captura de la muestra. Definida la función de perdida para Regresión Logística definimos el algoritmo de aprendizaje $\\mathcal A$ que emplearemos para aprender los pesos que minimizan esta función de perdida, usaremos en nuestro caso el algoritmo de _Stochastic Gradient Descent_ o Descenso del Gradiente Estocástico. La elección de este algoritmo viene dado a que es un algoritmo que tiene un buen rendimiento con datasets de gran tamaño, ya que es un algoritmo muy rápido al usar un tamaño de muestra de $1$ ejemplo por cada iteración, además, es un algoritmo muy flexible que da mucho juego en cuanto a parametrización y parametros de regularización (L1, L2, $\\eta$, tamaño de minibatch, etc).\n",
        "\n",
        "La función de perdida que usaremos para el modelo de SVM-soft será la función de perdida de bisagra o _hinge loss_ modificada para la formulación _soft_ de SVM, que es una función que penaliza los errores en clasificación permitiendo un cierto márgen de error y que se define como:\n",
        "\n",
        "$$E(\\text{w}) = \\max{(0, 1-y_n\\text{w}^T\\text{x}_n)} + C\\sum_{n=0}^{N}{\\xi_n}$$\n",
        "\n",
        "donde $C$ es un parámetro de penalización de los errores $\\xi_n$ cometidos por el márgen. La elección de esta función de perdida, además de por ser la más usada para el entrenamiento de clasificadores SVM, es porque es una función que conduce a una mejor presición ya que penaliza los errores de clasificación como hemos dicho y por tanto es ideal por si queremos un clasificador donde podamos controlar márgenes de error de una forma más restrictiva. Definida la función de perdida en SVM, ahora definiremos el algoritmo de aprendizaje $\\mathcal A$ para aprender los pesos que minimizan la función de perdida, la cual será un algoritmo de programación cuadrática que optimiza multiplicadores de Lagrange que definen los vectores soporte que definen el márgen final.\n",
        "\n",
        "En cuanto al modelo MLP, la función de perdida es la media de los errores cometidos por las neuronas:\n",
        "\n",
        "$$E(\\text{w}) = \\frac{1}{N}\\sum_{n=1}^{N}{\\text{e}_n}$$\n",
        "\n",
        "El error de cada neurona depende de la arquitectura de nuestra red, en nuestro caso cada neurona corresponde a un modelo de RL, que sabemos que calcula un valor probabilístico que corresponde a la máxima _semejanza_ o _likelihood_ de que un ejemplo pertenzca a una clase u otra. En efecto estamos tratando de aprender la distribución de probabilidad de la muestra, concretamente dado un conjunto de datos de entrada $\\text{X} = \\{\\text{x}_1, ..., \\text{x}_N\\}$ y sus clases $\\text{y} = \\{y_1, ..., y_N\\}$ la función de _likelihood_ de la muestra es:\n",
        "\n",
        "$$ℙ(\\text{y} | \\text{X}, \\text{w}) = ∏_{n=1}^{N}{ℙ(y_n | \\text{x}_n, \\text{w})}$$\n",
        "\n",
        "A partir de esto, podemos obtener los valores de $\\text{w}$ que maximicen el _likelihood_, para obtener una función de perdida que minimizar, podemos considerar la minimización de la función de suma de cuadrados medio que es equivalente a maximizar el _likelihood_, de esta manera obtenemos la función de perdida para cada neurona se define como\n",
        "$$\\text{e}(h_{RL}, y) = \\frac{1}{N}\\sum_{n=1}^{N}{(y_n - h_{RL}(\\text{w}, \\text{x}))^2}$$\n",
        "\n",
        "siendo $h_{RL}$ la función de predicción del modelo de Regresión Logística que tiene el mismo diseño que el especificado en nuestro modelo lineal de Regresión Logística de nuestro conjunto de modelos para el problema (esta vez usando la función de activación $ReLU(s)$ en vez de la sigmoide).\n",
        "\n",
        "> (1) Bishop, Christopher M. Pattern Recognition and Machine Learning. New York :Springer, 2006\n"
      ],
      "metadata": {
        "id": "ckHhJFjwpFl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtención de los datos\n",
        "\n",
        "Antes de poder empezar a realizar el preprocesamiento de los datos y el aprendizaje de nuestros modelo, primero debemos de obtenerlos."
      ],
      "metadata": {
        "id": "49EYQT7-7gpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los datos originalmente se estructuran como una matriz 32x32 de valores numéricos para cada muestra, que representan todos los píxeles de la imagen."
      ],
      "metadata": {
        "id": "YhOeSjheIBRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load(\"drive/MyDrive/Colab Notebooks/dataset.npz\")\n",
        "X_train_original, Y_train_original = data['X_train'], data['y_train']\n",
        "X_test_original, Y_test_original = data['X_test'], data['y_test']\n",
        "print(\"Forma de vector X de entrenamiento de muestras:\",X_train_original.shape)\n",
        "print(\"Forma de vector Y de entrenamiento de muestras:\",Y_train_original.shape)\n",
        "print(\"Forma de vector X de test de muestras:\",X_test_original.shape)\n",
        "print(\"Forma de vector Y de test de muestras:\",Y_test_original.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b71af8c-5ace-467f-c17b-be740e926627",
        "id": "KC8RHqNrH3wm"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de vector X de entrenamiento de muestras: (78200, 32, 32)\n",
            "Forma de vector Y de entrenamiento de muestras: (78200,)\n",
            "Forma de vector X de test de muestras: (13800, 32, 32)\n",
            "Forma de vector Y de test de muestras: (13800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicialmente la base de datos se separa en un conjunto para entrenamiento (train) y otro para test, entonces vamos a unir todo el conjunto de datos para poder hacer nuestra propia separación en train y test valorando el porcentaje que queremos que tenga cada parte."
      ],
      "metadata": {
        "id": "w0iKHRNXJFpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_original = np.row_stack((X_train_original,X_test_original))\n",
        "Y_original = np.concatenate((Y_train_original,Y_test_original))\n",
        "print(\"Forma de vector X del conjunto total de muestras:\",X_original.shape)\n",
        "print(\"Forma de vector Y del conjunto total de etiquetas:\",Y_original.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mDwEjVBJae7",
        "outputId": "438e29e1-48bc-4780-d9cd-ba5240a61f2a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de vector X del conjunto total de muestras: (92000, 32, 32)\n",
            "Forma de vector Y del conjunto total de etiquetas: (92000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a transformar la forma de los datos de cada muestra de matriz 32x32 a un único vector con todos los píxeles de la muestra."
      ],
      "metadata": {
        "id": "MoOHoWuuIdLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_total = X_original.reshape(len(X_original), -1)\n",
        "Y_total = Y_original.copy()\n",
        "print(\"Forma de vector X del conjunto total de muestras:\",X_total.shape)\n",
        "print(\"Forma de vector Y del conjunto total de etiquetas:\",Y_total.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt3S7iVdIn4Y",
        "outputId": "7c477f78-d359-4695-b22e-3e4164a30964"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de vector X del conjunto total de muestras: (92000, 1024)\n",
            "Forma de vector Y del conjunto total de etiquetas: (92000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a modificar el vector de etiquetas ya que inicialmente cada etiqueta se representa como un número\n",
        "$y_i \\in \\{0, 1, ..., 45\\}$, y por tanto vamos a transformar estas etiquetas al espacio de salida $\\mathcal Y$ donde cada etiqueta $y_i \\in \\mathcal Y$ identifica una clase de nuestro problema $C_{i}$ y es representado por un vecotor de 46 valores binarios donde todos los valores del vector toman el valor 0 excepto el valor en la posición $i$ que toma el valor 1 representando que la etiqueta es la clase $ i \\in \\{0,1,2,3...45\\}$.\n",
        "\n",
        "Para ello aplicamos One-Hot encoding a las etiquetas empleando la clase OneHotEncoder utilizando los siguiente parámetros para crear el objeto codificado:\n",
        "*   categories: se especifica la lista categ que contiene las categorías de cada variable.\n",
        "*   sparse_output=False: se establece en False para obtener una matriz densa en lugar de una matriz dispersa, para obtener una matriz con las columnas de cada nueva variable unificadas para añadirlas directamente al conjunto de datos.\n",
        "*   drop=None: se establece en None para mantener todas las categorías en cada variable.\n",
        "Después se utiliza el método fit_transform del objeto codificador para realizar la codificación One-Hot de las variables categóricas elegidas.\n"
      ],
      "metadata": {
        "id": "FbEtaUL9XWJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En algunos modelos implementados de la libreria `sklearn`, la clase implementa la codificación de las etiquetas internamente como un paso mas del proceso de ajuste del modelo, por lo tanto vamos a guardar el vector de etiquetas como estaba originalmente también para estos casos."
      ],
      "metadata": {
        "id": "CJi040GXfmpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Etiquetas del 0 al 45 incluido\n",
        "categorias =  [np.arange(46)]\n",
        "\n",
        "# Reshape del vector de etiquetas a una matriz columna para aplicar el codificador al vector\n",
        "Y_total_reshaped = Y_total.reshape(-1, 1)\n",
        "\n",
        "#Funcion para codificar\n",
        "encoder = OneHotEncoder(\n",
        "     categories=categorias,  # Categorías de cada variable\n",
        "     sparse_output=False,  # crea una matriz sparse cuando se pone TRUE\n",
        "     drop  = None  #  No quitar categorías en cada variable\n",
        "     )\n",
        "\n",
        "Y_total_OneHot = encoder.fit_transform(Y_total_reshaped) # Aplicar One Hot Encoding al conjunto total\n",
        "print(\"Forma de vector Y del conjunto total de etiquetas:\",Y_total.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46kvuhLWRHTp",
        "outputId": "48f7a9b5-6a83-472b-e8b7-145b9193f290"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de vector Y del conjunto total de etiquetas: (92000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora cada etiqueta se representa como un vector de 46 valores binarios."
      ],
      "metadata": {
        "id": "-vYrweOgZVrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos aplicado esta transformación ya que utilizar valores enteros de 0 a 45 para representar las etiquetas puede causar problemas, ya que los algoritmos pueden interpretar que hay un orden o relación numérica entre las etiquetas. El One Hot Encoding proporciona una representación binaria explícita que evita asociar relaciones entre las clases."
      ],
      "metadata": {
        "id": "klxXMQJRZo3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después de obtener el conjunto total de datos separamos los datos en un conjunto de entrenamiento y otro de test. Realizamos esto lo primero para evitar observar los datos de test y realizar \"Data Snooping\" donde el conjunto de datos podría influenciar nuestra elección sobre el modelo a utilizar para resolver el problema de aprendizaje automático. Para separar las muestras en train y test, dos distribuciones muy comunes en la práctica son 70% de train y 30% de test, y 80% de train y 20% de test. Al utilizar una distribución 70-30 obtendríamos una estimación mejor del error $E_{out}$ a partir del error $E_{test}$ que con la de 80-20, ya que se utilizaría un número mayor de muestras para obtener la estimación, un 30% del total, que en la otra distribución que usaría un 20% del total. Sin embargo, al utilizar una distribución 80-20 obtendríamos un mejor ajuste del problema al entrenar el modelo de aprendizaje con más datos que con la otra distribución, teniendo una mejor generalización en el conjunto de entrenamiento de la función que tratamos de aproximar. En general cuantos más datos se utilicen en test mejor será la estimación del error  $E_{out}$ y cuantos más datos se utilicen en el entrenamiento, el clasificador calculado se ajustará mejor al problema, ya que tiene más datos con los que aprender.\n",
        "En este caso he elegido una distribución de 80% para entrenamiento y 20% de test, teniendo en cuenta que con esta distribución se tiene un número menor de datos para estimar el error  $E_{out}$, pero se tiene un número mayor de datos para entrenar y para utilizar Cross-Validation con un conjunto de datos mayor."
      ],
      "metadata": {
        "id": "qJRxc5lLpbEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainPortion = 0.7 #porcentaje de train, el porcentaje de test será la resta de 1 menos el porcentaje de train\n",
        "\n",
        "#-------------Obtener índices\n",
        "\n",
        "indexesData = np.arange(len(Y_total)) #Indices del conjunto de muestras\n",
        "#-------------Desordenar indices y separar en rain y test\n",
        "\n",
        "np.random.shuffle(indexesData) #Desordenar indices de las muestras\n",
        "numberTrain = round(len(indexesData)*trainPortion) #numero de muestras para train\n",
        "trainIndexes = indexesData[:numberTrain]\n",
        "testIndexes = indexesData[numberTrain:]\n",
        "\n",
        "#-------------Datos desorden:ados para train y test\n",
        "\n",
        "X_train = X_total[trainIndexes]\n",
        "X_test = X_total[testIndexes]\n",
        "Y_train = Y_total[trainIndexes]\n",
        "Y_test = Y_total[testIndexes]\n",
        "\n",
        "#-------------Copia de los datos para mantener datos originales después del preprocesado\n",
        "\n",
        "original_trainX = X_train.copy()\n",
        "original_testX = X_test.copy()\n",
        "original_trainY = Y_train.copy()\n",
        "original_testY = Y_test.copy()\n",
        "\n",
        "#-------------Mostrar resultados\n",
        "\n",
        "print('Muestras totales:  {}'.format(len(Y_train)+len(Y_test)))\n",
        "print('Muestras train:  {}'.format(len(Y_train)))\n",
        "print('Muestras test:  {}'.format(len(Y_test)))\n"
      ],
      "metadata": {
        "id": "6nXUieJWpv2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b37411-cbae-4c8d-a101-9f860c2d3f5c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Muestras totales:  92000\n",
            "Muestras train:  64400\n",
            "Muestras test:  27600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se podría utilizar la función `train_test_split()` de scikit-learn que ofrece un comportamiento similar al código implementado. Como podemos observar, tenemos un total de 92000 muestras, de los cuales 73600 , que representan el 80% del total, serán utilizados para entrenamiento y el resto 18400 (20% del total) para test."
      ],
      "metadata": {
        "id": "pxH0FJXoCkVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformaciones y preprocesado de los datos de entrada\n",
        "\n",
        "Teniendo el problema planteado, pasaremos a realizar un preprocesado inicial de los datos, esto es transformaciones sobre los datos originales $\\text{x}$ que son previos a posterior entrenamiento y validación de los datos."
      ],
      "metadata": {
        "id": "mvpF0aXdUyll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalización/Escalado de los datos de entrada\n",
        "\n",
        "En nuestro caso haremos una primera transformación que se denomina un escalado de los datos o normalización de los datos. El escalado consiste en establecer un mapeo de los valores de cada atributo a un rango de valores concreto y común entre todos los atributos. La normalización de los atributos es una práctica muy común en Machine Learning y en ciencia de datos ya que:\n",
        "- Permite un entrenamiento más estable en el sentido de que al realizar el proceso de optimización o aprendizaje de los pesos, al tener un rango de valores más pequeño restringe el espacio de búsqueda de los pesos lo que puede evitar problemas como un _estancamiento del gradiente_ que esta presente sobre todo en redes neuronales.\n",
        "- Permite un entrenamiento más rápido en converger a una solución, esto se debe a que evita desbordamientos de los valores de los pesos, como puede ser el caso de un dato de entrada que sea muy grande y el peso que pondera este dato (dependiendo de su valor inicial) puede tardar mucho en poder converger con este dato.\n",
        "\n",
        "Aunque en nuestro caso, los valores de los píxeles están en un rango cerrado $[0,255]$, un escalado de los datos nos ayudará a mejorar el rendimiento del aprendizaje. En nuestro caso optaremos por una normalización _Min-Max_ también denominado _reescalado_, que se formula de la siguiente forma:\n",
        "$$z_j = \\frac{x_j - \\min{(x_j)}}{\\max{(x_j) - \\min{(x_j)}}}$$"
      ],
      "metadata": {
        "id": "cHw_4PeeDtNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es importante notar, que el escalado que hagamos en training debe ser el mismo escalado que se hará en test, esto es usar el mismo máximo y el mismo mínimo que en training para test; esto es para que el escalado en test vaya acorde con lo que aprendió el modelo que son valores escalados en training, y no haya una interpretación errónea de los resultados. Sin embargo, esto no es probable que pase, ya que los valores de los píxeles son fijados en un rango concreto $[0,255]$, por tanto, es muy improbable que ocurra que en test no haya un mínimo en $0$ o un máximo en $255$, en todo caso, para estar seguros guardaremos los máximos y los mínimos de los atributos en training como constantes para su posterior uso.\n",
        "\n",
        "> En el caso de que hayan columnas con solo valores $0$, como puede ser las esquinas de las imágenes, entonces le asignamos un valor de cero (ignoramos normalizar estas columnas)"
      ],
      "metadata": {
        "id": "WwNyCPxt9DQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos una función que abstrae este proceso para un conjunto de features\n",
        "# con valores concretos de min y max\n",
        "def min_max_scaling(X, min_vals, max_vals):\n",
        "    # Inicializamos el conjunto normalizado\n",
        "    norm_X = np.zeros(X.shape, dtype=float)\n",
        "\n",
        "    # obtener las columnas con solo ceros\n",
        "    zero_cols = np.where(np.all(X == 0, axis=0))[0]\n",
        "\n",
        "    # Normalizamos cada columna\n",
        "    for i in range(X.shape[1]):\n",
        "        # Mantenemos las columnas originales con solo ceros\n",
        "        if i in zero_cols:\n",
        "            norm_X[:, i] = X[:, i]\n",
        "        # De lo contrario, normalizamos\n",
        "        else:\n",
        "            norm_X[:, i] = (X[:, i] - min_vals[i]) / (max_vals[i] - min_vals[i])\n",
        "\n",
        "    # Devolver el conjunto normalizado\n",
        "    return norm_X"
      ],
      "metadata": {
        "id": "80qbAaCJ8F61"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Datos faltantes\n",
        "\n",
        "Una parte importante y común del preprocesado de datos es el tratamiento de datos faltantes o datos perdidos. Es muy importante que no hayan datos nulos, faltantes o incluso incorrectos en los datos ya que pueden influir negativamente al aprendizaje ya que el modelo puede interpretar esta falta de datos de una manera que no pretendemos que haga.\n",
        "\n",
        "Comprobamos entonces que no hay datos nulos o valores que se salgan del rango $[0,255]$ en primer lugar."
      ],
      "metadata": {
        "id": "xtzE_ZzSNA_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar si hay valores NaN en X_train\n",
        "if pd.isna(X_train).sum(): print(\"Valores nulos\")\n",
        "\n",
        "# Verificar si hay valores NaN en Y_train\n",
        "if pd.isna(Y_train).sum(): print(\"Valores nulos\")\n",
        "\n",
        "# Verificar si hay valores infinitos en X_train\n",
        "if np.isinf(X_train).sum(): print(\"Valores infinitos\")\n",
        "\n",
        "# Verificar si hay valores infinitos en Y_train\n",
        "if np.isinf(Y_train).sum(): print(\"Valores infinitos\")\n",
        "\n",
        "# Verificar si hay valores fuera de [0,255]\n",
        "if X_train[X_train < 0].size: print(\"Datos incorrectos\")\n",
        "if X_train[X_train > 255].size: print(\"Datos incorrectos\")\n"
      ],
      "metadata": {
        "id": "GFRl0sp8soJQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que no existen casos de valores nulos o errores de medidas en los datos.\n",
        "\n",
        "Otro tipo de datos nulos o faltantes pueden ser, por ejemplo, que en la obtención de las imágenes, hayan imágenes que no muestren ningún caracter, una imágen vacía o en blanco. Esto lo podemos comprobar fácilmente verificando que todas las imágenes no tengan un vector de valores únicos de píxeles.\n",
        "\n",
        "Si visualizamos una imágen en concreto, podemos ver el valor de color del fondo."
      ],
      "metadata": {
        "id": "rFNvMvdZwUWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_arr = X_train[33]\n",
        "img = Image.fromarray(img_arr.reshape(32,32).astype(np.uint8))\n",
        "\n",
        "zoom_factor = 5\n",
        "\n",
        "# Resize image\n",
        "zoomed_img = img.resize((img.width * zoom_factor, img.height * zoom_factor))\n",
        "\n",
        "zoomed_img.show()\n",
        "print([key for key, val in map_labels.items() if val == Y_train[33]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYGD690CxW4U",
        "outputId": "9089905d-f4c1-4d73-961e-a997ccec6e59"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['character_20_na']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que el fondo debe ser de color negro, es decir, valor $0$; por tanto, podemos considerar un vector cero de píxeles como un ejemplo faltante o perdido. Comprobamos la existencia de este caso."
      ],
      "metadata": {
        "id": "19RwwDRRzH5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if np.any(np.all(X_train == 0, axis=1)):\n",
        "    print('lost image')\n",
        "else:\n",
        "    print('all images are valid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl5v7vOBzWK0",
        "outputId": "78d61371-5ad6-46a9-bab4-a23b62e9b8a1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all images are valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por tanto, tenemos cierta seguridad de que no hay datos faltantes o datos incorrectos en nuestro dataset de entrenamiento, por lo que no haremos ninguna transformación o procesado al respecto."
      ],
      "metadata": {
        "id": "RyxlDmy8008g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Desequilibrio de clases\n",
        "\n",
        "Una parte importante a tener en cuenta sobre nuestro conjunto de datos es el desequilibrio de las clases presentes en nuestro dataset, esto es el nivel de representación de cada caracter de nuestro conjunto de training. Cuando hay un desbalanceo de una o más clases, ocurre una dominancia de una clase sobre otra, esto quiere decir, que nuestros modelos pueden aprender mucha información sobre un conjunto de clases que está muy representada en los datos y aprender muy poca información de otros más infrarepresentados. Nos interesa que todas las clases estén bien representadas para poder tener un modelo final de clasificación lo más potente y capáz posible en el dominio del problema y así poder tener una capacidad de clasificación sobre todas las clases posibles.\n",
        "\n",
        "En nuestro caso, según la descripción del conjunto de datos, se dispone de $2000$ ejemplos de cada clase en el dataset completo; por tanto, en principio no debería de haber desbalanceo en las clases del conjunto de datos, sin embargo, cuando particionamos en datos de training y test, puede haber cierto desbalanceo que depende de la partición concreta que hemos realizado, esto lo hemos abordado realizando una separación de los datos con previa aleatorización del conjunto entero, de manera que la distribución sea lo más independiente posible de la partición que hemos hecho.\n",
        "\n",
        "Si visualizamos el conteo de todas las etiquetas $y$ para todos los ejemplos del conjunto de training podemos comprobar la distribución de las clases y tener una mejor percepción de este problema."
      ],
      "metadata": {
        "id": "NxgUuLpT2VTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x=Y_train)\n",
        "\n",
        "plt.title('Distribución de clases en Train')\n",
        "plt.xlabel(f'Labels (y)')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "1vj_usVJ6SIQ",
        "outputId": "59324662-34ce-4246-f1f4-9751f9d82bce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar, no hay datos que estén _sobrerepresentados_ o _infrarepresentadas_ en nuestro conjunto de training de una manera muy notable o preocupante, por lo que consideramos que con haber hecho una partición de los datos aleatorizada es suficiente para abordar el problema de clases desbalanceadas y por tanto, no haremos procesamiento en cuanto a esto."
      ],
      "metadata": {
        "id": "UB2puahU8rwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformación del atributo predictor ($y$)\n",
        "\n",
        "En la construcción de nuestros modelos de clasificación es importante notar que es un problema de clasificación multiclase y no un problema de clasificación binaria, por tanto, tener un enfoque diferente para construir nuestros modelos para que puedan clasificar más de una etiqueta dado un ejemplo.\n",
        "\n",
        "En primer lugar, para los clasificadores RL y SVM, que son modelos binarios por defecto, usaremos el enfoque denominado _one vs. rest_ que consiste en:\n",
        "\n",
        "- Para cada etiqueta entrenaremos un modelo (RL y SVM) para predecir de forma binaria si un ejemplo pertenece a tal clase o no; si tenemos $46$ clases entonces comprenderemos $46$ modelos de RL y de SVM.\n",
        "\n",
        "- Cuando querámos clasificar un ejemplo concreto, cada modelo entrenado para clasificar una etiqueta concreta se aplicará al nuevo ejemplo y elegiremos la clase cuyo modelo ha indicado la mayor pertenencia a tal ejemplo, es decir, tomámos el modelo que ha clasificado con mayor \"_confianza_\" el ejemplo y tomar la etiqueta que corresponde con tal modelo.\n",
        "\n",
        "El concepto de pertenencia o _confianza_ en predecir un ejemplo viene dado por el modelo en cuestión; el modelo de RL asigna una probabilidad de _pertenencia_ de un ejemplo a una clase, por tanto podemos usar la misma salida para determinar la mayor pertenencia, esto es, elegir la etiqueta cuyo modelo correspondiente haya dado la mayor probabilidad (el mayor valor $h_i(\\text{x})$). El modelo SVM no obstante, clasifica con una función de predicción que asigna la clase a la que pertenece un ejemplo, aún así podemos definir la pertenencia a una clase con la distancia ortogonal del _data point_ con el hiperplano resultante, de esta manera elegimos la clase cuyo modelo SVM correspondiente tenga la mayor distancia con el hiperplano, puesto a que a mayor distancia este el _data point_ del hiperplano más \"dentro\" esta de la clase a la que pertenece.\n",
        "\n",
        "Por último, para nuestro modelo de Perceptrón Multicapa no hace falta seguir el mismo enfoque que con RL y SVM ya que este modelo puede tratar con problemas de clasificación multiclase simplemente definiendo la dimensión de la capa de salida como $d(L) = k$ siendo $k$ el número de clases de nuestro problema (sabemos que $k = 46$ para nuestro problema concreto).\n",
        "\n",
        "Nótese que debemos de realizar una transformación sobre el atributo objetivo de nuestro conjunto de datos, y es el de \"binarizar\" el atributo, esto es porque nuestros modelos al intentar aprender de nuestros datos, los valores de $y$ que están en el rango $[0,45]$, no tienen una propiedad de orden en ellos; la clase $0$ no es menor que la clase $46$, estos valores de $y_i$ simplemente están para _categorizar_ cada clase $C_i$, por tanto, para poder llevar a cabo el enfoque _one vs. rest_ y definir las etiquetas del MLP, debemos de realizar un tipo de codificación sobre estas categorías. Existen diferentes codificaciones pero nosotros nos valdremos con la de _One Hot Encoding_ que asigna un nuevo atributo por cada categoría (clase); de esta manera nuestro conjunto de etiquetas de training será una matriz $N \\times k$, con $N$ el número de ejemplos. Nótese que ahora podemos entrenar un modelo de clasificación binaria simplemente usando una columna de la matriz u otra, además para el modelo MLP será útil ya que ahora podrá aprender la relación de orden existente entre las clases con la \"activación\" y \"desactivación\" de cada atributo."
      ],
      "metadata": {
        "id": "lNDAm_zA-TU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La implementación de este enfoque viene incluido por defecto en los modelos que implementaremos: `SGDClassifier` y `SVC` soportan multiclase con enfoque _One vs. Rest_ (1); sin embargo, aquí hacemos mención del proceso subyacente.\n",
        "\n",
        "> (1) https://scikit-learn.org/stable/modules/sgd.html#classification"
      ],
      "metadata": {
        "id": "C-uFF0BZX8u3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracción de características (_feature extraction_)\n",
        "\n",
        "#### Problema de la representación de las características $\\text{X}$\n",
        "\n",
        "El último tratamiento sobre los datos que vamos a considerar es acerca del elección y/o extracción de características (_features_) de nuestro conjunto de entrenamiento. Cuando hemos descrito nuestro conjunto de datos de entrada $\\text{X} = \\{\\text{x}_1, \\text{x}_2, ..., \\text{x}_N\\}$, hemos visto que cada vector de características $\\text{x}_n$ estaba definido por el conjunto de píxeles del ejemplo concreto (imágen), y cada píxel tenía un valor en el rango $[0,255]$. El problema de estos datos de entrada es que no es un enfoque muy representativo de lo que puede significar un caracter _Devanagari_ y esto puede dar lugar a problemas a nuestros modelos en cuanto a extraer el patrón subyacente en la asignación de las clases.\n",
        "\n",
        "Por poner un ejemplo, consideremos la clase $C' = \\text{\"na\"}$ que corresponde al caracter _Devanagari_ \" __न__ \". Tomamos de esta clase $3$ ejemplos"
      ],
      "metadata": {
        "id": "E8UvHCzT-s9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener la etiqueta para la clase\n",
        "clas = map_labels['character_20_na']\n",
        "\n",
        "# Tomar 3 ejemplos\n",
        "idx_na = Y_train[Y_train == clas][:3]\n",
        "idx_na = np.argwhere(Y_train == clas).flatten()[:3]\n",
        "\n",
        "img_arrays = X_train[idx_na]\n",
        "\n",
        "images = [Image.fromarray(pixels.reshape(32,32).astype(np.uint8)) for pixels in img_arrays]\n",
        "\n",
        "# PLOT\n",
        "fig, axes = plt.subplots(1, 3, figsize=(8,6))\n",
        "\n",
        "for i in range(3):\n",
        "    # asignar la imagen i al axis i\n",
        "    axes[i].imshow(images[i], cmap='gray')\n",
        "    # removemos el axis original para dejar solo la imagen\n",
        "    axes[i].axis('off')\n",
        "    axes[i].set_title(f\"Ejemplo {i+1}\")\n",
        "\n",
        "# ajustar el espaciado entre las imagenes\n",
        "plt.tight_layout()\n",
        "\n",
        "# mostrar plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "zPrEqCWehYUP",
        "outputId": "f64723f8-a98f-487b-dcc3-a0cd54ce0631"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que para una misma clase, el estilo de escritura de cada imágen puede diferenciarse notablemente de un ejemplo a otro. Si observamos concretamente el Ejemplo 2 y el ejemplo 3 podemos apreciar una diferencia abismal y es la localización del caracter en la imágen; el Ejemplo 2 abarca una porción de imágen muy alta mientras que el Ejemplo 3 es un caracter mucho más pequeño, esto puede resultar en un empeoramiento del aprendizaje de nuestros modelos por el siguiente motivo: el tamaño de los caracteres no es una característica que queremos aprender de los datos. Si el Ejemplo 1 y 2 abarcan una porción grande de la imágen, el modelo puede aprender, por ejemplo, que los píxeles de la parte superior deben ser blancos, pero cuando se encuentre con un caracter como el Ejemplo 3, detectará que todos los píxeles en la parte superior de la imágen son píxeles negros, por tanto, el modelo clasificará mal el Ejemplo 3 en evaluación y en training dificultaría su aprendizaje.\n",
        "\n",
        "Esta claro que tenemos, de alguna manera que extraer características representativas de las clases presentes en las imágenes, este proceso como podemos apreciar, no es trivial y de hecho involucra todo un campo en la extracción de características para muchos problemas de ML, lo que se conoce como _feature engineering_. En nuestro caso que trabajamos con caracteres manuscritos, lo único que queremos obtener o extraer de los caracteres son aquellas formas o trazos comunes entre los caracteres de una clase que los diferencian del resto. Por poner el ejemplo anterior, una característica del caracter \"_na_\" es que \"siempre tiene una especie de 'lazo' en la parte izquierda\". La representación de estas características es un problema que es complejo sobre todo si queremos representarlas de alguna forma numérica, afortunadamente existen técnicas en la literatura que nos permiten obtener estas características, nosotros optaremos por el método de _Histogram of oriented gradients_ o (HOG).\n",
        "\n",
        "#### Histogram of Oriented Gradients - HOG\n",
        "\n",
        "HOG es uno de los muchos descriptores de características para problemas relacionados con Visión por Computador y es usado especialmente para detección de objetos en imágenes.\n",
        "\n",
        "La idea fundamental de HOG es que las formas de los objetos locales en la imágen (en nuestro caso las formas de los caracteres) pueden ser representados o descritos por una distribución (o histograma) de gradientes de intensidad o direcciones de bordes. La imágen se divide en zonas, llamadas celdas, que comprenden un conjunto de píxeles, se computa luego el histograma de gradientes orientados de cada celda de la imágen; el descriptor final es la concatenación de todos los histogramas de la imágen. Los gradientes sobre una celda obtienen información acerca de la dirección y los cambios de constraste de cada píxel en la celda, estos gradientes pueden ser computados por distintos operadores como Sobel para detección de ejes.\n",
        "\n",
        "Podemos visualizar un ejemplo de la imágen resultante de usar HOG sobre un caracter concreto (*).\n",
        "\n",
        "> (*) Este no será la configuración que usaremos, en el ejemplo es solo por motivos ilustrativos y para entender mejor los conceptos."
      ],
      "metadata": {
        "id": "PF_yzl9czhAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar una imagen de ejemplo\n",
        "image = images[0]\n",
        "\n",
        "# Calculamos el descriptor HOG sobre la imágen\n",
        "hog_features, hog_image = feature.hog(image, visualize=True)\n",
        "\n",
        "# Mostrar la imagen original y el resultado del descriptor HOG\n",
        "fig, axes = plt.subplots(1, 2, figsize=(6, 6))\n",
        "\n",
        "axes[0].imshow(image, cmap='gray')\n",
        "axes[0].axis('off')\n",
        "axes[0].set_title('Imagen original')\n",
        "\n",
        "axes[1].imshow(hog_image, cmap='gray')\n",
        "axes[1].axis('off')\n",
        "axes[1].set_title('Descriptor HOG')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "278mj5XITd6T",
        "outputId": "a791ddae-0a22-4b71-da07-f03f86dc02d0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar, el descriptor logra capturar las diferentes propiedades del caracter:\n",
        "- Captura la propiedad o característica \"_tiene un lazo en la parte izquierda_\" y que podemos observar como los gradientes forman un ciclo por la zona izquierda.\n",
        "- Captura la propiedad \"_tiene una barra horizontal superior_\" y que podemos observar como los gradientes se orientan horizontalmente en la parte superior del caracter.\n",
        "\n",
        "En resúmen, HOG nos permite representar características latentes de los caracteres en forma de histogramas de gradientes de intensidad que podemos usar para caracterizar un caracter concreto solo basandonos en estas distribuciones que capturan la esencia del caracter.\n",
        "\n",
        "HOG es especialmente bueno sobre otros descriptores por centrarse en la distribución de los gradientes en la imágen, por lo que reconoce de una forma más precisa los contornos del objeto en cuestión, algo especialmente útil en nuestro problema para detectar las formas de los caracteres como lazos o formas rectangulares.\n",
        "\n",
        "Implementaremos el descriptor haciendo uso de la utilidad de `scikit-learn` para extracción de características `hog`. Esta función acepta los siguientes parámetros para ajustar HOG según nuestras necesidades:\n",
        "- `orientation`: representa la cantidad de orientaciones que tendrá el histograma de gradientes, por tanto, mientras más alto sea el número de orientaciones, será más capaz de capturar contornos más complejos. Aunque puede resultar beneficioso tener un número alto de orientaciones, este aumento también incrementa la dimensión del vector de características resultante, por tanto, es importante encontrar un equilibro para este parámetro; por tanto, asumiremos en un principio el valor por defecto de $9$ orientaciones y ajustaremos el valor según consideremos más adelante.\n",
        "- `pixels_per_cell`: indica el número de píxeles o el tamaño que tendrá cada celda en la que se divide la imágen. Esta vez, si el tamaño es muy pequeño, el histograma será mucho más preciso para capturar detalles finos, pero esto aumenta la dimensionalidad y por tanto un vector de _features_ mucho más grande. Elegiremos en un principio un valor de `(8,8)` al ser divisor del tamaño de la imágen y por ser un tamaño razonable teniendo en cuenta el tamaño de la imágen original. Esto sin embargo, podemos volver a ajustarlo según necesitemos.\n",
        "- `cells_per_block`: determina el tamaño de los bloques en los que se normalizan los histogramas locales. La normalización de los histogramas es importante en casos donde se pretende reconocer objetos en imágenes con iluminación por ejemplo, donde la presencia de este puede afectar en las variaciones que pueden tomar los gradientes, esta normalización haría que el descriptor sea más robusto frente a estas variaciones. Este parámetro puede ser útil cuando queremos capturar detalles finos de forma local, por ejemplo, si en los caracteres, es importante determinar bien los trazos de los lazos entonces tener un tamaño de bloque de normalización más grande puede capturar detalles finos al dividirse en más subregiones (celdas), pero esto aumenta también la dimensionalidad del vector resultante; lo contrario pasa el número de celdas por bloques es más pequeño, obteniendo una representación más global. Nosotros, usaremos un tamaño de `(1,1)`, ya que nos conviene ser capaces de capturar detalles más globales de los caracteres, recordemos que el estilo de escritura influye en gran medida, por lo que capturar detalles finos nos puede perjudicar; además estaremos reduciendo dimensionalidad lo que mejora la probabilidad de una mejor generalización.\n",
        "- `block_norm`: determina el método de normalización que se aplica a cada bloque de normalización de los histogramas. Esto es especialmente relevante cuando las variaciones en la iluminación de las imágenes es muy brusca y por tanto se necesita de un suavizado de estas variaciones para no perjudicar el descriptor. En nuestro caso, como solamente existe una variación monótona en las imágenes, que es cuando se realiza el trazo del caracter, la elección de un método de normalización no es tan relevante, por tanto, nos contentaremos con el valor por defecto `L2-Hys` que simplemente realiza una supresión de los valores atípicos que mejora la invarianza en el contraste.\n",
        "- `visualize`: indica si se quiere devolver también la imágen resultante del vector de características nuevo. Nosotros indicaremos que `True` solo para fines demostrativos pero en la transformación final no será necesario y estableceremos a `False`."
      ],
      "metadata": {
        "id": "fLoOzqcSTcvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_pixels = X_train[idx_na[0]].reshape(32,32)\n",
        "\n",
        "# Calcula el descriptor HOG fd, y devuelve la imagen resultante\n",
        "fd, image_hog = feature.hog(image_pixels, orientations=4, pixels_per_cell=(8, 8), cells_per_block=(1, 1), block_norm='L2-Hys', visualize=True)\n",
        "\n",
        "# Visualiza la imagen original y ##la imagen HOG\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
        "\n",
        "ax1.axis('off')\n",
        "ax1.imshow(image_pixels, cmap=plt.cm.gray)\n",
        "ax1.set_title(f'Imagen original. {image_pixels.size} features')\n",
        "\n",
        "ax2.axis('off')\n",
        "ax2.imshow(image_hog, cmap=plt.cm.gray)\n",
        "ax2.set_title(f'Características HOG. {fd.size} features')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "T7KRFaA0cYnK",
        "outputId": "fe55fc07-5552-4d89-d717-444a84ab1f1f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar, el uso de un tamaño de celdas de $8\\times 8$, un tamaño de bloques de $1\\times 1$ y un número de orientaciones de $4$ resultan en una reducción considerable del número de características resultante y puede representar relativamente bien un caracter. Esta reducción nos conviene positivamente ya que estamos reduciendo la dimensión VC de nuestro problema y por tanto según la cota de generalización, nuestros modelo generalizarán mejor con nuevos datos, así como mejorar el rendimiento en el proceso de aprendizaje y llegar a una convergencia más temprana."
      ],
      "metadata": {
        "id": "aC_HGVacrh9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(X):\n",
        "    # convertir vectores originales en matrices\n",
        "    X_aux = X.reshape(X.shape[0], 32, 32)\n",
        "\n",
        "    # por cada ejemplo, obtenemos su respectivo descriptor HOG\n",
        "    fds = []\n",
        "    for e in X_aux:\n",
        "        fd = feature.hog(e, orientations=4, pixels_per_cell=(8, 8), cells_per_block=(1, 1), block_norm='L2-Hys')\n",
        "        fds.append(fd)\n",
        "\n",
        "    # devolver el nuevo conjunto de train\n",
        "    return np.array(fds)"
      ],
      "metadata": {
        "id": "bnpKWduxsZag"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proceso de selección de modelos (_model selection_)\n",
        "\n",
        "#### S-fold Cross Validation\n",
        "Un aspecto crucial a tener en cuenta y que hemos mencionado antes, es que el conjunto de datos de test $\\mathcal D_{test}$ se __reserva__ para la evaluación del modelo __final__, esto quiere decir que el conjunto de test en ningún momento puede influir en el aprendizaje de nuestro modelo, pues _contaminaría_ los datos e introducirían un sesgo en el modelo; por tanto es importante que no utilicemos estos datos hasta el final del entrenamiento cuando queramos evaluar su rendimiento final, ya que el error en este conjunto de test $E_{test}$ resulta en un buen estimador del error fuera de la muestra $E_{out}$ siempre y cuando los datos se hayan obtenido de una muestra identica e independientemente distribuida para poder aplicar la Inecuación de Hoeffding y garantizar una cota del error de generalización que dependa de $E_{test}$, esta cota es mucho menos suelta que la cota de generalización que depende de $E_{in}$ y por tanto es un buen estimador para validar nuestro modelo siempre que se considere solo la hipótesis final $g$ al final del entrenamiento.\n",
        "\n",
        "Sin embargo, en el ajuste del modelo nos encontraremos en situaciones donde el modelo cambia drásticamente cuando usamos parámetros en los que influye el entrenamiento; estos parámetros son conocidos como _hiperparámetros_ e influyen de una manera significativa el aprendizaje, entre ellos podemos encontrar: el _learning rate_ para el Descenso de Gradiente, el parámetro de penalización o regularización $C$ en el modelo SVM o el parámetro de la intensidad de regularización $\\lambda$. Es por esto que debemos de tener alguna forma de evaluar los modelos correspondientes a la elección de los diferentes valores de estos hiperparámetros y poder optar por el mejor de ellos; a este concepto se le denomina elección del modelo o _model selection_. Se trata de poder evaluar _en entrenamiento_ el rendimiento de una serie de modelos cuando se enfrentan con datos __nuevos__, por esto es que usar el propio conjunto de training no es un buen indicador del rendimiento ante datos no vistos por que el modelo esta justamente sesgado por este conjunto, se dice que los datos están _contaminados_. Esto introduce la necesidad de un nuevo conjunto de datos: el conjunto de _validación_.\n",
        "\n",
        "El conjunto de _validación_ es un conjunto de datos que se extrae realizar un _hold out_ de $\\mathcal D_{train}$ y que denominaremos $\\mathcal D_{val}$ con tamaño $K$ de ejemplares. Este conjunto de validación es el que se usará para medir el rendimiento de varios modelos en el proceso de _model selection_ mientras que el conjunto de datos restantes se usará para el ajuste. Es importante notar que para definir este conjunto de validación, no es trivial el tamaño $K$ que elegiremos, de hecho la elección de un buen $K$ debe satisfacer por un lado que hayan suficientes ejemplares de entrenamiento $N-K$, y que a la vez satisfaga un $K$ suficiente para que $\\mathcal D_{val}$ estime de la mejor manera ek rendimiento fuera de la muestra. Además existe el problema que nos encontramos cuando queriamos separar training y test, que el ajuste depende de la partición concreta del conjunto de datos y puede dar resultados sesgados. Estos problemas los resuelve la técnica que usaremos para poder validar nuestros modelos candidatos, la técnica de validación cruzada en $S$ pliegues o _S-fold cross validation_.\n",
        "\n",
        "La técnica de validación cruzada en $S$ pliegues o S-fold CV consiste en la partición de los datos de entrenamiento $\\mathcal D_{train}$ en $S$ grupos (en nuestro caso nos limitaremos a que los grupos sean del mismo tamaño) y que los $S-1$ groupos se usen para ajustar y el restante se use para validar. Este proceso luego es repetido en todas las $S$ posibles formas de realizar el _hold out_ de $\\mathcal D_{train}$. Finalmente, se obtiene el promedio de las mediciones de rendimiento de cada _fold_ y esa será la medición final que mide el rendimiento del modelo. En la siguiente figura(2) podemos observar un esquema visual de la partición tanto de training y test, y la obtención de $S$ conjuntos de validación.\n",
        "\n",
        "![Esquema de la partición en conjuntos de training, validacion y test](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n",
        "\n",
        "Un aspecto a tener en cuenta en esta técnica de _model selection_ es el parámetro $S$ que define tanto $K$ como el número de _folds_ o ajustes y validación a realizar del modelo. Un caso extremo es cuando $S = N$, que es lo que se conoce como _leave-one-out_, ya que ajustamos en cada _fold_ dejando un ejemplo fuera para validación; esta configuración es especialmente útil cuando los datos disponibles son escasos ya que con _leave-one-out_ se consigue el mejor ajuste posible por tener el máximo $N-K$ para entrenar, sin embargo, resulta muy costoso el proceso puesto que si $N$ es muy grande, entonces el número de _folds_ a realizar será muy grande ($N$ _folds_). No hay regla universal para elegir $S$, y en la práctica se suelen usar $S=\\{5,10\\}$ que son considerados buenas opciones gracias a resultados empíricos(1), nosotros usaremos un $S = 5$ para nuestro problema teniéndo en cuenta que podemos obtener una ganancia de velocidad que si lo hacemos con $S = 10$ que es un aspecto importante ya que estamos usando modelos como MLP que gracias a su arquitectura necesitan mucho tiempo de cómputo para converger.\n",
        "\n",
        "> (1) Page 184, An Introduction to Statistical Learning, 2013.\n",
        ">\n",
        "> (2) https://scikit-learn.org/stable/_images/grid_search_cross_validation.png"
      ],
      "metadata": {
        "id": "xSCMrcrhx7Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_val(model, X, y, folds, score):\n",
        "\n",
        "    # Crear el objeto K-fold\n",
        "    kfold = KFold(\n",
        "        n_splits=folds, # Número de particiones (folds)\n",
        "        random_state=None, # No establecemos semilla para no conservar un estado concreto y\n",
        "                           # tener un estado completamente aleatorio\n",
        "        shuffle=True #Desordenar por clases antes de particionar el conjunto\n",
        "    )\n",
        "\n",
        "    # Realizar validación cruzada y devolver los resultados.\n",
        "    # Especificamos paralelismo de nivel 5 para obtener ganancia en velocidad\n",
        "    return cross_validate(model, X=X, y=y, cv=kfold, scoring=score, n_jobs=5)"
      ],
      "metadata": {
        "id": "6W1wqVe0PTs1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Selección de mejores hiperparámetros - _Grid Search_\n",
        "\n",
        "Ya que tenemos definido la técnica que usaremos para entrenar y evaluar un modelo, pasamos a definir el método que usaremos para elegir la mejor configuración de hiperparámetros para un modelo concreto.\n",
        "\n",
        "Optaremos en nuestro caso por una técnica ampliamente usada para este tipo de selección y es la técnica de _grid search_. _Grid search_ es una de las muchas técnicas para optimizar hiperparámetros de un modelo, lo que también se denomina _hyperparameter tuning_.\n",
        "\n",
        "Esta técnica en su versión más simple consiste en entrenar y evaluar un modelo (en nuestro caso usando _Cross Validation_) con una serie de hiperparámetros  tal que cada hiperparámetro tenga un conjunto de valores previamente seleccionados; luego, mediante una búsqueda exhaustiva, se obtienen las métricas de cada una de las posibles combinaciones de hiperparámetros obteniendo finalmente un _ranking_ donde elegiremos la configuración con mejores métricas.\n",
        "\n",
        "Aunque Grid Search permite obtener la mejor configuración de hiperparámetros, nosotros usaremos _grid search_ de manera individual para cada hiperparámetro, es decir, un proceso de _grid search_ uni-dimensional (_grid_ de solo un hiperparámetro) usando un modelo de base (por ejemplo, usando los hiperparámetros por defecto). De esta manera podemos seleccionar el mejor conjunto de hiperparámetros sin dependencia entre hiperparámetros, es decir, seleccionar los mejores que optimicen un modelo por sí solos."
      ],
      "metadata": {
        "id": "CdTwi09GIfDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def single_grid_search_cv(model, X, y, hyper, values, folds, score):\n",
        "    # Realizamos una copia del modelo para reutilizar el original\n",
        "    m = clone(model)\n",
        "\n",
        "    # Busqueda exhaustiva de los valores del hiperparametro\n",
        "    scores = []\n",
        "    for v in values:\n",
        "        # Establecemos el valor del hiperparametro\n",
        "        params = { hyper: v }\n",
        "        m.set_params(**params)\n",
        "\n",
        "        # Evaluamos el modelo\n",
        "        results = cross_val(m, X, y, folds=folds, score=score)\n",
        "\n",
        "        # marco el valor concreto del hiperparametro\n",
        "        results[hyper] = str(v)\n",
        "\n",
        "        # agregamos los resultados a los globales\n",
        "        scores.append(results)\n",
        "\n",
        "\n",
        "    # Devolver el DataFrame con los resultados\n",
        "    df = pd.DataFrame(scores).drop(columns=['fit_time', 'score_time'])\n",
        "\n",
        "    # Pongo la columna con el valor del hiperparametro al inicio\n",
        "    df = df[[df.columns[-1]] + list(df.columns[:-1])]\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "Ai1uXG-yNa_z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Selección del mejor modelo\n",
        "\n",
        "La selección del mejor modelo es el proceso de selección final donde se escogerá el mejor modelo de clasificación $g$ que usaremos posteriormente para la evaluación con el conjunto de test. Primero se obtienen los tres modelos resultantes de haber optimizado sus mejores hiperparámetros y que hemos definido anteriormente con el método _grid search_, estos tres mejores modelos RL, SVM-soft y MLP son los denominados __modelos finalistas__. A continuación, tomaremos los modelos finalistas y les aplicaremos _Cross Validation_ una vez más, obteniendo sus respectivos puntajes; el modelo con puntaje más alto será nuestro modelo final.\n",
        "\n",
        "El ajuste $g$ final será el resultado de entrenar el mejor modelo con el conjunto de training completo $\\mathcal D_{train}$; el error que obtengamos con este $g$ dentro de la muestra es desconocido, sin embargo, sabemos que debe ser menor que $E_{val}$ al ser entrenado con un número mayor de ejemplos, por lo que esto no afecta a nuestra decisión de selección."
      ],
      "metadata": {
        "id": "LPOGjotdXV1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Modelo de puntaje - _model scoring_\n",
        "\n",
        "El último apunte acerca del enfoque que seguiremos para el proceso de selección de modelos es el puntaje o _scoring_ que usaremos para evaluar y comparar cada modelo, en efecto, definir nuestro criterio de selección.\n",
        "\n",
        "Previamente habíamos definido las métricas relevantes que íbamos a usar para poder medir el rendimiento de un modelo, que eran: el _Accuracy_, el _Hamming Loss_ y el _F1-Score_. Aunque pudieramos comprender las tres para evaluar un modelo, lo cierto es que resulta en una tarea muy poco sistemática y poco controlada y manejable, sin embargo, nosotros optaremos por un _score_ mucho más sencillo y que comprende estas tres métricas y es una suma ponderada de estas tres:\n",
        "$$\\alpha_1 \\cdot Acc + \\alpha_2 \\cdot Spec + \\alpha_3 \\cdot \\text{F1}$$\n",
        "\n",
        "De esta manera, podemos definir los coeficientes $\\alpha_i$ según que métricas resultan más importantes o con más peso a la hora de elegir un modelo u otro. Por tanto definiremos estos coeficientes tomándo en cuenta lo siguiente:\n",
        "- Sabemos que las clases de nuestro conjunto de entrenamiento no tienen algún tipo de desbalanceo importante, por lo que realmente la medición de la _accuracy_ resulta una buena métrica en este caso para comparar los modelos, ya que al estar las clases aproximadamente equitativamente bien representadas entonces un modelo con un _accuracy_ muy alto significa un modelo que está clasificando la mayoría de los ejemplos correctamente y no porque sea una clase mayoritaria. Por tanto, a esta métrica le daremos un peso importante.\n",
        "- Por otro lado, el F1-Score es una métrica que combina el _Precision_ y el _Recall_ en una sola métrica, por tanto, resulta útil cuando queremos evitar la sobreestimación o subestimación de los errores en la clasificación. En nuestro caso, los errores en clasificación de caracteres manuscritos no son tan relevantes como lo son los aciertos, sobre todo en clasificación multietiqueta donde la clasificación de no pertenencia de una clase es casi una forma de comportamiento por defecto, ya que la gran mayoría de clases responderan negativamente a la pertenencia del ejemplo a ellas y solo una responderá positivamente; por lo que nos interesa elegir un modelo a partir de que tan bien clasifica un ejemplo. Por tanto, al F1-Score tendrá un peso más bien bajo.\n",
        "- Finalmente, la especificidad mide que tan bien clasifica los casos negativos, en sí el caso es muy similar al de F1-Score, donde nos interesa más premiar los modelos que acierten mejor, por lo que este tendrá un peso muy similar al F1-Score.\n",
        "\n",
        "Por tanto, podemos asignar unos valores aproximados según las consideraciones de cada métrica con el problema al que nos enfrentamos. Por lo que proporcionamos la siguiente asignación:\n",
        "$$\\text{Score}(h) = 0.7 \\cdot Acc(h) + 0.15 \\cdot Spec(h) + 0.15\\cdot F1(h)$$\n",
        "\n",
        "Implementamos la función para este _score_ usando los _helpers_ de `scikit-learn` y que aceptan estos parámetros:\n",
        "\n",
        "- `y_true`: son los valores de salida reales, es decir que es igual a $f(\\text{x})$\n",
        "- `y_pred`: son los valores de predicción del modelo, es decir, $h_{\\text{w}}(\\text{x})$\n",
        "\n",
        "Sin embargo, el _specificity_ la sacaremos de la matriz de confusión ya que no viene definida en esta librería"
      ],
      "metadata": {
        "id": "RZJSIPRMXaAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una funcion que mida el specificity con la matriz de confusion para clasificacion multietiqueta\n",
        "def specificity_score_multiclass(y_true, y_pred, class_label):\n",
        "    # Calcula la matriz de confusión para la clase específica y las demás clases\n",
        "    true_class = (y_true == class_label)\n",
        "    predicted_class = (y_pred == class_label)\n",
        "    TN, FP, FN, TP = confusion_matrix(true_class, predicted_class).ravel()\n",
        "\n",
        "    # Calcula la especificidad para la clase específica\n",
        "    specificity = TN / (TN + FP)\n",
        "\n",
        "    return specificity\n",
        "\n",
        "def specificity_score(y_true, y_pred, **kwargs):\n",
        "    # Calcula la especificidad promediada para todas las clases\n",
        "    num_classes = len(set(y_true))\n",
        "    specificity_total = 0.0\n",
        "\n",
        "    # Calculamos el promedio de specificity de cada clase\n",
        "    for class_label in range(num_classes):\n",
        "        specificity_total += specificity_score_multiclass(y_true, y_pred, class_label)\n",
        "\n",
        "    specificity_avg = specificity_total / num_classes\n",
        "    return specificity_avg\n",
        "\n",
        "# Creamos una función score customizada\n",
        "def model_score(y_true, y_pred):\n",
        "\treturn 0.7*accuracy_score(y_true, y_pred) + 0.15*specificity_score(y_true, y_pred) + 0.15*f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "# Creamos una instancia de la metrica\n",
        "scorer = make_scorer(model_score)"
      ],
      "metadata": {
        "id": "YJBKGbTWORSh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este puntaje es el que usaremos para poder evaluar con el criterio mostrado los modelos que se nos presenten."
      ],
      "metadata": {
        "id": "azDx52RGPNfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento y evaluación de modelos en training\n",
        "\n",
        "Empezamos entonces a realizar el ajuste, evaluación y comparación de los modelos a disposición para la elección del mejor modelo con el enfoque que hemos descrito anteriormente. El procedimiento lo dividiremos en estos subprocedimientos:\n",
        "- Tratamiento del conjunto de training con la _pipeline_ de transformaciones y preprocesado.\n",
        "- Obtención de los modelos finalistas. Elección de mejores hiperparámetros (_grid search_ con _grid_ uni-dimensional para cada parámetro) y selección de mejor técnica de regularización para cada modelo.\n",
        "- Selección del mejor modelo $g^{*}$. Ajuste final del mejor modelo $g$ con $\\mathcal D_{train}$.\n",
        "- Evaluación del mejor ajuste $g$ con $\\mathcal D_{test}$. Preprocesado del conjunto $\\mathcal D_{test}$. Obtención de del error $E_{out}$ estimado."
      ],
      "metadata": {
        "id": "SLc7zP42-k4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocesado del conjunto de train $\\mathcal D_{train}$\n",
        "\n",
        "Realizamos la siguiente _pipeline_ de transformaciones sobre los datos de train para el entrenamiento: escalado y normalización de los datos, obtención del descriptor de características HOG.\n",
        "\n",
        "La razón por la cual obtendremos los datos normalizados antes de obtener el descriptor HOG es porque, aunque este escalado no se verá reflejado en las _features_ finales, la realidad es que tener un conjunto normalizado de valores hace que la obtención de los gradientes en HOG sea mucho más eficiente y estable, reduciendo la posibilidad de variaciones altas en los valores de las imágenes y dificultando la obtención del descriptor.\n",
        "\n",
        "Nosotros no realizaremos un escalado de los valores posterior a HOG, esto debido a que HOG realiza una normalización específica para cada atributo, por tanto, no es necesario un reescalado de estos atributos."
      ],
      "metadata": {
        "id": "aV4Af6O5CF60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# obtenemos los valores máximos y mínimos de las features en training como constantes\n",
        "MIN_VALUES_TRAIN = X_train.min(axis=0)\n",
        "MAX_VALUES_TRAIN = X_train.max(axis=0)\n",
        "\n",
        "# Normalizamos el conjunto de train\n",
        "X_train_proc = min_max_scaling(X_train, MIN_VALUES_TRAIN, MAX_VALUES_TRAIN)\n",
        "\n",
        "# Obtenemos el descriptor de caracteristicas HOG como nuestro nuevo conjunto de datos\n",
        "X_train_proc = extract_features(X_train_proc)\n",
        "\n",
        "X_train_proc.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43-70rhGD1iO",
        "outputId": "42ade22b-6988-4e2c-acc5-7e42d90eb718"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64400, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Obtención de los modelos finalistas\n",
        "\n",
        "Teniéndo el conjunto preprocesado y listo para poder ajustar, pasamos a elegir los mejores hiperparámetros. Como hemos dicho, usaremos la técnica de _grid search_ para una búsqueda exhaustiva de los mejores hiperparámetros de forma individual basándonos en un modelo base de prueba, que hemos dicho que serían los modelos por defecto de `scikit-learn`. En el proceso de selección de hiperparámetros por modelo definiremos lo siguiente: el algoritmo de aprendizaje $\\mathcal A$ del modelo concreto, regularización a usar y el subconjunto de valores para cada hiperparámetro."
      ],
      "metadata": {
        "id": "tnxLOJSzU2vD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### __Regresión Logística__\n",
        "\n",
        "Para el modelo de RL usaremos el algoritmo de optimización _Stochastic Gradient Descent_ o SGD como el algoritmo de aprendizaje $\\mathcal A_{RL}$. Elegimos este algoritmo ya que se caracteríza por ser un algoritmo muy rápido y que evita el ajuste del modelo a la muestra de entrenamiento por su carácter estocástico, a diferencia de como pasa con el _Batch Gradient Descent_ convencional. Además, al tomar en cuenta un subconjunto menor de ejemplares por cada iteración, es muy adecuado para datasets muy grandes, como es nuestro caso.\n",
        "\n",
        "Ahora definimos la regularización a usar, en el que tenemos dos aproximaciones que ofrecen distintas ventajas sobre la otra. Existen dos grandes tipos de regularización los cuales son L1 y L2. Regularización L1 también denominada LASSO, es un tipo de regularización (Least Absolute Shrinkage and Selection Operator) que consiste en la selección automática de los pesos, es decir, lleva implícito reducción de dimensionalidad lo cual ya hemos visto que mejora la generalización del modelo y por tanto funciona como método de regularización. LASSO se basa en la norma L1 (también llamada norma Manhattan) de los coeficientes (pesos) $||\\text{w}||_1$, la variable de penalización $\\lambda$ implica la reducción de las magnitudes de los coeficientes a $0$, con esto consigue una selección de las características que son importantes para ajustar el modelo; cuando $\\lambda$ es mayor entonces la restricción es más fuerte y tiende a una mayor reducción de los pesos. Este método es usualmente elegido cuando la dimensionalidad del problema es muy alto y se requiere de una selección de características para reducir dimensionalidad.\n",
        "$$\\sum_{q=0}^{Q}{|w_q|} \\le C$$\n",
        "\n",
        "Por otro lado, la regularización L2 se basa en la norma L2 también denominada norma Euclídea, que son las sumas de los pesos al cuadrado $||\\text{w}||_2$, el detalle del que sea al cuadrado que al aplicar el término de penalización $\\lambda$ se penalicen más los coeficientes que son mayores, por lo que consigue lo mismo que L1, que es reducir la dimensionalidad pero de una manera más suave, no tratando todos los coeficientes por igual sino penalizando los que son más altos, esto reduce la complejidad del problema ya que valores altos de $w$ tienden a una clase de funciones $\\mathcal H$ más amplia, mientras que si restringimos a valores de $w$ más bajos la clase de funciones se restringe resultando en un $\\mathcal H$ mucho más sencillo, además, al priorizar los pesos con menos magnitud se consiguen ajustes muy suaves que evitan el ajuste de ruido (Overfitting). Esta técnica es usada cuando la dimensionalidad del problema no es grave y se sabe que todas las las características son importantes (_feature selection_ menos acusada).\n",
        "$$\\sum_{q=0}^{Q}{w_q^2} \\le C$$\n",
        "\n",
        "En conclusión, L1 (LASSO) es útil cuando se desea realizar una reducción de dimensionalidad porque se sabe (o se sospecha) que hay características irrelevantes. Mientras que L2 es útil para obtener una mejor generalización y se quiere reducir lo máximo posible el Overfitting del modelo mientras se mantienen todas las características (poca reducción). En nuestro caso, el caso de reducir características nos perjudica ya que estaríamos eliminando información importante de un conjunto de atributos que previamente se han extraído mediante un proceso de extracción de características (HOG en nuestro caso), por tanto no tiene mucho sentido usar regularización L1 que sirve mejor cuando se quiere realizar una extracción o selección de características. Por tanto optaremos por usar una regularización L2 (Ridge) que realiza una reducción mucho más suave mientras se consigue la mejor generalización posible.\n",
        "\n",
        "En cuanto a los hiperparámetros a considerar así como el subconjunto de valores (_grid_) que consideraremos son los que comentaremos a continuación junto con la implementación del clasificador que usaremos. El clasificador que usaremos será la clase de `scikit-learn` `SGDClassifier` que toma los siguientes parámetros e hiperparámetros:\n",
        "- `eta0` ($\\eta_0$): es la tasa de aprendizaje inicial usada en la ecuación general del descenso del gradiente estocástico. Las medidas más usuales para este parámetro son valores menores o iguales que $1$ los cuales podemos considerar $(0.001, 0.01, 0.1)$, estos valores de _learning rate_ suelen ser los más usuales por tener un rendimiento en la práctica muy bueno. Nosotros en este experimento nos limitaremos a que el learning rate sea __constante__ y no dinámico, es decir, $\\eta=\\eta_0$, por simplicidad en la elección de los distintos parámetros del _grid_ aunque podría ser una opción de cambio si observamos que la función de perdida tiene una forma no convexa más caótica y por tanto requeriríamos de una tasa mucho más compleja.\n",
        "- `alpha`: es el término de regularización, en nuestro caso L2, y es el parámetro que controla la intensidad de la regularización en el ajuste. En la literatura se le suele denominar $\\lambda$. Nosotros usaremos los valores de $(0.01, 0.001, 0.0001)$ ya que valores de $λ$ mayores suelen empeorar la generalización del modelo (1), por tanto consideraremos valores más bien bajos.\n",
        "- `max_iter`: es el máximo de iteraciones que SGD puede realizar en el entrenamiento. En este caso depende mucho de la cantidad de ejemplos a disposición, como SGD opera aleatoriamente sobre todo el dataset, tenemos que garantizar de alguna manera que se puedan considerar todos los ejemplos. A priori pondremos un solo valor de $20$ iteraciones que podemos ir graduando a nuestro gusto hasta un límite como puede ser, que se cumpla el criterio de parada y no consuma todas las iteraciones, aunque esto será necesario solo si no conseguimos un buen ajuste. La razón de un máximo de épocas tan bajo es por la dimensión de la muestra que contiene un $N$ muy elevado y puede tardar mucho en dar una solución.\n",
        "- `tol`: es la tolerancia del criterio de parada, es decir, cuando considera el algoritmo que ha convergido; el valor depende del problema en cuestión, si `tol` es muy grande entonces el algoritmo terminará mucho antes mientras que si es muy pequeño, durará más en converger y se necesitará más precisión del algoritmo para que converja. En nuestro caso optarémos por una tolerancia de $10^{-3}$ que parece un valor razonable para poder garantizar cierta precisión en la convergencia del algoritmo.\n",
        "-`epsilon`: es el umbral de error mínimo. En este caso podemos optar por una error un poco impaciente al principio de $0.1$ y lo iremos bajando hasta que veamos que ya no converge si es necesario, aunque un error aproximadamente de esta magnitud suele ser lo usual.\n",
        "- `penalty`: indica el tipo de regularización que usaremos, usaremos regularización `'l2'` como hemos dicho antes.\n",
        "- `loss`: indica la función de perdida. Este parámetro define el modelo concreto de clasificación que usaremos, nosotros especificamos la función de perdida `'log_loss'` que es la función de _Cross Entropy_ que hemos definido anteriormente para RL.\n",
        "- `shuffle`: Indica si se quiere realizar una aleatorización del conjunto de datos por cada época, para aprovechar las características positivas de la aleatorización en SGD como habíamos comentado, indicaremos un valor de `True` para este parámetro.\n",
        "\n",
        "> (1) Yaser S. Abu-Mostafa, Malik Magdon-Ismail, and Hsuan-Tien Lin. 2012. Learning From Data. AMLBook. pag 134."
      ],
      "metadata": {
        "id": "jHQ8QQyaBJVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos los hiperparametros y sus valores así como los parámetros fijos a usar\n",
        "lrs = [0.001, 0.01, 0.1]\n",
        "alphas = [0.0001, 0.001, 0.01]\n",
        "max_iter = 20\n",
        "tol = 1e-3\n",
        "epsilon = 0.1\n",
        "\n",
        "# Definimos un modelo base de RL con valores de hiperparametros por defecto\n",
        "base_model = SGDClassifier(\n",
        "    loss='log_loss',\n",
        "    penalty='l2',\n",
        "    max_iter=max_iter,\n",
        "    shuffle=True,\n",
        "    learning_rate='constant', # Determinar que el learning rate es constante\n",
        "    tol=tol,\n",
        "    epsilon=epsilon\n",
        ")\n",
        "\n",
        "# Definimos las metricas que usaremos: Accuracy, Specificity, F1-Score, Metrica ponderada\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'specificity': make_scorer(specificity_score, average='macro'),\n",
        "    'f1': make_scorer(f1_score, average='macro'), # utilizo la opción average='macro' ya que estamos ante un problema\n",
        "                                                  # de clasificacion multiclase donde las clases estan aprox. equilibradas\n",
        "                                                  # por lo que se calcula un promedio global sobre las clases sin tener en cuenta\n",
        "                                                  # el desequilibrio\n",
        "    'rank_score': scorer\n",
        "}\n",
        "\n",
        "# ejecutamos grid search sobre el learning rate inicial\n",
        "scores = single_grid_search_cv(model=base_model, X=X_train_proc, y=Y_train, hyper='eta0', values=lrs, folds=5, score=scoring)\n",
        "\n",
        "# obtengo las medias de los resultados\n",
        "scores_arr = scores.to_numpy()\n",
        "scores_arr_means = np.array([np.mean(x) for x in scores_arr[:, 1:].flatten()]).reshape(len(lrs),4)\n",
        "np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means))\n",
        "scores = pd.DataFrame(np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means)), columns=scores.columns, index=scores.index)\n",
        "\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "9e3BD7XJOIlu",
        "outputId": "d4aeb178-51b5-4ed3-bd69-a6270f3c305a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    eta0 test_accuracy test_specificity   test_f1 test_rank_score\n",
              "0  0.001      0.671568         0.992702  0.668881        0.719335\n",
              "1   0.01      0.699596         0.993325  0.697757         0.74338\n",
              "2    0.1      0.669627          0.99266  0.667082          0.7177"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85da2662-6ac8-4f4f-925f-289ab81956d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eta0</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_specificity</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>test_rank_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.671568</td>\n",
              "      <td>0.992702</td>\n",
              "      <td>0.668881</td>\n",
              "      <td>0.719335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.699596</td>\n",
              "      <td>0.993325</td>\n",
              "      <td>0.697757</td>\n",
              "      <td>0.74338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.669627</td>\n",
              "      <td>0.99266</td>\n",
              "      <td>0.667082</td>\n",
              "      <td>0.7177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85da2662-6ac8-4f4f-925f-289ab81956d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85da2662-6ac8-4f4f-925f-289ab81956d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85da2662-6ac8-4f4f-925f-289ab81956d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b2c19368-1901-4ccb-98b0-ec0259184beb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2c19368-1901-4ccb-98b0-ec0259184beb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b2c19368-1901-4ccb-98b0-ec0259184beb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar que el _learning rate_ con mejor puntaje es $\\eta = 0.01$. Podemos ver también que en cuanto a la especificidad, en todos los casos se tienen valores muy altos, aquí podemos comprobar lo que decíamos acerca de la clasificación negativa de las clases, en el que al ser un problema de clasificación multiclase los verdaderos negativos serán muy altos ya que un ejemplo solo pertenece a una de las $46$ clases existentes. En cuanto al F1-Score podemos observar que obtenemos en la mayoría de los casos un puntaje bueno siendo el mayor aproximadamente $0.7$ de score, esto nos indica que en general estamos obteniendo un modelo con buena precisión y buena exhaustividad (_recall_). Finalmente en cuanto al _accuracy_, en general estamos obteniendo buenas predicciones de nuestro modelo, con casi un $70\\%$ de ejemplos bien clasificados en el caso del mejor.\n",
        "\n",
        "En cuanto al mejor _learning rate_ concluimos que tenemos $0.01$ como mejor tasa de aprendizaje para RL por tener mejor puntaje según nuestro criterio establecido."
      ],
      "metadata": {
        "id": "nOIttsHd5Uym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos el mismo experimento pero ahora queriéndo conseguir el mejor término de regularización $λ$. En este caso tenemos que optar por el valor por defecto del _learning rate_, ya que si es constante, debemos de especificar uno concreto, así que dejamos el valor por defecto para que no sea dependiente de un _learning rate_ concreto."
      ],
      "metadata": {
        "id": "_bW2Otfq7mAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un modelo base de RL con valores de hiperparametros por defecto\n",
        "base_model = SGDClassifier(\n",
        "    loss='log_loss',\n",
        "    penalty='l2',\n",
        "    max_iter=max_iter,\n",
        "    shuffle=True,\n",
        "    tol=tol,\n",
        "    epsilon=epsilon\n",
        ")\n",
        "\n",
        "# ejecutamos grid search sobre el término de regularización\n",
        "scores = single_grid_search_cv(model=base_model, X=X_train_proc, y=Y_train, hyper='alpha', values=alphas, folds=5, score=scoring)\n",
        "\n",
        "# obtengo las medias de los resultados\n",
        "scores_arr = scores.to_numpy()\n",
        "scores_arr_means = np.array([np.mean(x) for x in scores_arr[:, 1:].flatten()]).reshape(len(alphas),4)\n",
        "np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means))\n",
        "scores = pd.DataFrame(np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means)), columns=scores.columns, index=scores.index)\n",
        "\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "HuU2h8YR8T2p",
        "outputId": "fb78bf58-6115-40e8-84fb-3f5a6a92e713"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    alpha test_accuracy test_specificity   test_f1 test_rank_score\n",
              "0  0.0001      0.713789          0.99364  0.711689        0.755451\n",
              "1   0.001      0.684938         0.992999  0.681238        0.730592\n",
              "2    0.01      0.585745         0.990795  0.566104        0.643557"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f3e3919-4135-40bc-a814-2e9ecaac6cea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alpha</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_specificity</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>test_rank_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.713789</td>\n",
              "      <td>0.99364</td>\n",
              "      <td>0.711689</td>\n",
              "      <td>0.755451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.684938</td>\n",
              "      <td>0.992999</td>\n",
              "      <td>0.681238</td>\n",
              "      <td>0.730592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.585745</td>\n",
              "      <td>0.990795</td>\n",
              "      <td>0.566104</td>\n",
              "      <td>0.643557</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f3e3919-4135-40bc-a814-2e9ecaac6cea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f3e3919-4135-40bc-a814-2e9ecaac6cea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f3e3919-4135-40bc-a814-2e9ecaac6cea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b849a71b-63f7-4f3e-ab29-6a7e96e8d5a4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b849a71b-63f7-4f3e-ab29-6a7e96e8d5a4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b849a71b-63f7-4f3e-ab29-6a7e96e8d5a4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar en los resultados, el $\\lambda$ más bajo obtiene una tasa considerablemente mayor de clasificación, esto tiene sentido ya que el error aumentado establece que menores valores de $\\lambda$ corresponden a un suavizado de la restricción sobre los pesos\n",
        "$$E_{aug} = E_{in} + \\lambda \\text{w}^T\\text{w}$$\n",
        "\n",
        "Por tanto, es esperable que obtenga un error menor si reducimos la intensidad de regularización. Por lo que al mejor $\\lambda$ respecta elegiremos el que mayor _rank score_ ha sacado, que es $λ=0.0001$."
      ],
      "metadata": {
        "id": "cd63AwJYGKGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### __SVM-soft__\n",
        "\n",
        "Ahora evaluaremos y elegiremos los mejores hiperparámetros para el modelo de SVM. Primero definiremos al igual que en RL, el algoritmo de aprendizaje $\\mathcal A_{SVM}$ que usaremos; optaremos por usar el algoritmo de programación cuadrática o (QP) que calcula los vectores soporte $\\alpha$ que definen el márgen máximo del hiperplano óptimo. Hemos optado por usar este algoritmo por ser menos sensible a la elección de hiperparámetros (como lo es SGD) y por proporcionar una solución exacta para los vectores soportes, a diferencia de nuevo con SGD, el cual es un algoritmo que aproxima a una solución que no se garantiza que sea óptima.\n",
        "\n",
        "En cuanto al tipo de regularización, al igual que con RL usaremos regularización de tipo L2 (Ridge) por los mismos motivos que con RL, puesto que en este caso queremos realizar una reducción suave y no tan brusca como lo hace L1 ya que consideramos que todos los atributos obtenidos en la extracción de características son igual de importantes. El parámetro de regularización por tanto es la restricción $C$, donde la fuerza o intensidad de regularización es inversamente proporcional a este parámetro. Este parámetro representa la cantidad de errores de clasificación que el ajuste es capaz de tolerar (formulación _soft_) y es el único hiperparámetro que consideraremos para este modelo.\n",
        "\n",
        "Para la implementación de este modelo usaremos la clase de `scikit-learn` `SVC` (_Support Vector Classifier_), que incluye la regularización L2 y que acepta los siguientes parámetros:\n",
        "\n",
        "- `C`: es el parametro de penalización o regularización. Nosotros usaremos una lista de estos parámetros razonables para este parámetros que someteremos a una búsqueda _grid search_ $\\{0.1, 1.0, 10\\}$. A diferencia de SGD donde el parametro de regularización lo manteniamos bajo, en este nos conviene variar entre valor altos y bajos ya que queremos explorar la flexibilidad de nuestro modelo frente a fuertes y flojas restricciones, en este caso, la penalización por error de clasificación. Este será el único hiperparámetro que vamos a tunear con _grid search_.\n",
        "- `kernel`: especifíca el _kernel_ que usaremos en el algoritmo. El _kernel_ es una función que nos ayuda en la obtención de productos escalares necesarios para la optimización de programación cuadrática desde otro espacio de las muestras, lo que nos permite encontrar un hiperplano más complejo que un simple hiperplano recto. En nuestro caso, estamos considerando a este un modelo no lineal, por tanto elegiremos un _kernel_ radial (RBF) por su capacidad de tratar con problemas de alta dimensionalidad al transformar los datos con NLT, que es muy idóneo para nuestro caso en la que tenemos una gran catidad de dimensiones.\n",
        "- `gamma`: en nuestro caso que utilizamos un _kernel_ RBF, `gamma` es el parámetro que controla el alcance del _kernel_ al calcular la distancia entre pares vecinos cuando se calculan las RBFs, nosotros optaremos por un valor de autoescala `gamma='scale'` que calcula $\\frac{1}{\\text{n_features} \\times \\sigma}$.\n",
        "- `tol`: es el criterio de parada, similar a caso de SGD en RL, usaremos el valor por defecto de $10^{-3}$\n",
        "- `class_weights`: podemos asignar pesos a las clases si estas están desbalanceadas; nuestro caso es el contrario, hay un buen balance entre las clases de nuestro conjunto de training, por lo que asignamos un valor de `None`.\n",
        "- `max_iter`: establece el máximo número de iteraciones del algoritmo. El algoritmo de SVC es un algoritmo muy lento de optimización, por lo que nos convendría, al menos en la selección de hiperparámetros, tener un límite. Por tanto, nosotros usaremos en _grid search_ un valor razonable de `20` iteraciones para elegir el mejor hiperparámetro $C$ y un valor de `-1` para el ajuste del modelo finalista.\n",
        "- `decision_function_shape`: establece la política de decisión sobre la clasificación de un ejemplo en problemas multiclase. En nuestro caso usaremos la política `One vs Rest` que hemos definido anteriormente.\n",
        "- `break_ties`: se utiliza para indicar si se quiere \"romper empates\" entre dos o más clases, en nuestro caso, lo establecemos a `True` para que pueda romper empates usando la función de decisión correspondiente al nivel de confianza en la pertenencia a una clase."
      ],
      "metadata": {
        "id": "fNH3Q9QzfWKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos los hiperparametros y sus valores así como los parámetros fijos a usar\n",
        "C_s = [0.1, 1.0, 10]\n",
        "max_iter = 20\n",
        "tol = 1e-3\n",
        "\n",
        "# Definimos las metricas que usaremos: Accuracy, Specificity, F1-Score, Metrica ponderada\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'specificity': make_scorer(specificity_score, average='macro'),\n",
        "    'f1': make_scorer(f1_score, average='macro'), # utilizo la opción average='macro' ya que estamos ante un problema\n",
        "                                                  # de clasificacion multiclase donde las clases estan aprox. equilibradas\n",
        "                                                  # por lo que se calcula un promedio global sobre las clases sin tener en cuenta\n",
        "                                                  # el desequilibrio\n",
        "    'rank_score': scorer\n",
        "}\n",
        "\n",
        "# Definimos un modelo base de SVC con valores de hiperparametros por defecto\n",
        "base_model = SVC(\n",
        "    kernel='rbf',\n",
        "    gamma='scale',\n",
        "    tol=tol,\n",
        "    class_weight=None,\n",
        "    max_iter=max_iter,\n",
        "    decision_function_shape='ovr',\n",
        "    break_ties=True\n",
        ")\n",
        "\n",
        "# ejecutamos grid search sobre el término C\n",
        "scores = single_grid_search_cv(model=base_model, X=X_train_proc, y=Y_train, hyper='C', values=C_s, folds=5, score=scoring)\n",
        "\n",
        "# obtengo las medias de los resultados\n",
        "scores_arr = scores.to_numpy()\n",
        "scores_arr_means = np.array([np.mean(x) for x in scores_arr[:, 1:].flatten()]).reshape(len(C_s),4)\n",
        "np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means))\n",
        "scores = pd.DataFrame(np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means)), columns=scores.columns, index=scores.index)\n",
        "\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "HliI6DhKlUuU",
        "outputId": "3bbbe3e1-45f9-42a0-9abc-0b8cd71874fc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     C test_accuracy test_specificity   test_f1 test_rank_score\n",
              "0  0.1       0.60837         0.991297  0.604645         0.66525\n",
              "1  1.0      0.712081         0.993602  0.709465        0.753916\n",
              "2   10      0.741817         0.994263  0.737055        0.778969"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0ca9a9e-fc3e-4f3b-8d42-481e6d739016\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_specificity</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>test_rank_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.60837</td>\n",
              "      <td>0.991297</td>\n",
              "      <td>0.604645</td>\n",
              "      <td>0.66525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.712081</td>\n",
              "      <td>0.993602</td>\n",
              "      <td>0.709465</td>\n",
              "      <td>0.753916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>0.741817</td>\n",
              "      <td>0.994263</td>\n",
              "      <td>0.737055</td>\n",
              "      <td>0.778969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0ca9a9e-fc3e-4f3b-8d42-481e6d739016')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e0ca9a9e-fc3e-4f3b-8d42-481e6d739016 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e0ca9a9e-fc3e-4f3b-8d42-481e6d739016');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-481eb32e-4f65-4c76-b045-978ab505046f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-481eb32e-4f65-4c76-b045-978ab505046f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-481eb32e-4f65-4c76-b045-978ab505046f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# obtengo las medias de los resultados\n",
        "scores_arr = scores.to_numpy()\n",
        "scores_arr_means = np.array([np.mean(x) for x in scores_arr[:, 1:].flatten()]).reshape(len(C_s),4)\n",
        "np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means))\n",
        "scores = pd.DataFrame(np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means)), columns=scores.columns, index=scores.index)\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "rrPskQlIQSS6",
        "outputId": "e358b6dd-ef4c-4d9a-99c2-63ef851f8691"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     C test_accuracy test_specificity   test_f1 test_rank_score\n",
              "0  0.1       0.60837         0.991297  0.604645         0.66525\n",
              "1  1.0      0.712081         0.993602  0.709465        0.753916\n",
              "2   10      0.741817         0.994263  0.737055        0.778969"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f72cd48-fa55-4244-b2ac-5c4886b8951b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_specificity</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>test_rank_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.60837</td>\n",
              "      <td>0.991297</td>\n",
              "      <td>0.604645</td>\n",
              "      <td>0.66525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.712081</td>\n",
              "      <td>0.993602</td>\n",
              "      <td>0.709465</td>\n",
              "      <td>0.753916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>0.741817</td>\n",
              "      <td>0.994263</td>\n",
              "      <td>0.737055</td>\n",
              "      <td>0.778969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f72cd48-fa55-4244-b2ac-5c4886b8951b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6f72cd48-fa55-4244-b2ac-5c4886b8951b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6f72cd48-fa55-4244-b2ac-5c4886b8951b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e7e7f82f-9c0c-4134-a32e-c903aa739347\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e7e7f82f-9c0c-4134-a32e-c903aa739347')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e7e7f82f-9c0c-4134-a32e-c903aa739347 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar, un parámetro $C$ mayor es evidentemente más preciso a la hora de clasificar en train. Esto se debe a que al imponer menos restricción (mayor $C$) estamos permitiendo un ajuste menos regularizado, lo que puede ser un signo de Overfitting, sin embargo, al estar usando el error de validación cruzada, tenemos una estimación relativamente buena de $E_{out}$ aunque tiene cierto grado de contaminación, por tanto, como además se indica que $C=10$ es mejor en todas las métricas que los otros parámetros, elegiremos este último como mejor parámetro teniéndo la garantía de que $E_{val} ≈ E_{out}$."
      ],
      "metadata": {
        "id": "N3dlEDclOX0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### __Perceptrón Multicapa__\n",
        "\n",
        "Por último vamos a definir los elementos de MLP para el proceso de selección de modelos. En primer lugar, el algoritmo de aprendizaje que usaremos $\\mathcal A_{MLP}$ será el algoritmo de Backpropagation con _solver_ SGD, este algoritmo de Backpropagation lo hemos elegido por ser un algoritmo muy usado en el entrenamiento de redes neuronales y ser uno de los algoritmos de aprendizaje de redes neuronales más eficientes por su enfoque \"hacia atrás\" que ha marcado un antes y un después en el desarrollo de estos modelos universales. La hibridación con el algoritmo SGD se refiere a que hace uso de un algoritmo de optimización, en este caso SGD, para optimizar los pesos de la red, mientras que Backpropagation indica las neuronas que más contribuyen al error. Elegimos SGD por las propiedades que hemos explicado en RL que gana en velocidad y generalización.\n",
        "\n",
        "En cuanto al tipo de regularización, seguiremos optando por la regularización L2 por el mismo motivo de mantener en la medida de lo posible las _features_ que hemos consideradas todas igualmente importantes mientras se consigue una buena generalización. El término de regularización será el mismo que con RL, el parámetro $\\lambda$ que indica la intensidad de la regularización de manera proporcional. También utilizaremos una técnica de regularización muy usada en el entrenamiento de redes neuronales que es la técnica de _early stopping_, que consiste, en esencia, controlar el empeoramiento del $E_{out}$ estimado parando el algoritmo cuando se detecta el empeoramiento.\n",
        "\n",
        "En cuanto a la implementación usaremos la clase de `scikit-learn` `MLPClassifier` que implementa este algoritmo de Backpropagation con diversos algoritmos de optimización. Esta clase acepta los siguientes hiperparámetros:\n",
        "- `hidden_layer_size`: indica la dimensión de cada capa $d(l)$ de nuestra red, es decir, el número de neuronas por capas. Este parámetro será un hiperparámetro que tendremos que elegir mediante _grid search_ en la cual consideraremos el siguiente subconjunto de valores: $(50, 75, 100)$, donde cada valor indica la dimensión $d(l_i)$ de cada capa.\n",
        "- `activation`: indica la función de activación de cada neurona; como hemos comentado en la definición de la clase de funciones, usaremos la función de activación ReLU, por tanto especificamos el valor `'relu'` como función de activación.\n",
        "- `solver`: indica el algoritmo de optimización a usar. Como hemos dicho anteriormente, usaremos el algoritmo o _solver_ SGD para nuestro modelo, por tanto, indicamos el valor `'sgd'`.\n",
        "- `alpha`: indica el parámetro de regularización que hemos denominado $λ$, este lo consideraremos, al igual que RL, un hiperparámetro que elegiremos mediante _grid search_ y cuyo valores que consideraremos son iguales a los considerados en RL: $(0.01, 0.001, 0.0001)$.\n",
        "- `batch_size`: indica el tamaño de minibatch que usará el algoritmo de optimización. Esto puede resultar en una ganancia de velocidad al considerar batches de cierto tamaño en vez de ir un ejemplo a la vez. Nosotros usaremos la opción que viene por defecto `auto` que calcula el tamaño como `batch_size=min(200, num_examples)`, que eligirá $200$ ejemplos por minibatch, un tamaño muy razonable para nuestro problema que no penaliza en un ajuste pobre y que ayuda aportando un poco de velocidad al proceso.\n",
        "- `learning_rate_init`: indica el _learning rate_ inicial, usado en los algoritmos ADAM y SGD. En nuestro caso nosotros consideraremos este parámetro como un hiperparámetro cuyos valores serán los mismo que los que usamos con RL: $(0.1, 0.01, 0.001)$.\n",
        "- `max_iter`: indica el máximo de épocas o iteraciones en el algoritmo. Al igual que en RL, al ser un dataset de gran dimensionalidad, optaremos por un máximo de iteraciones de $20$ que dan un buen balance con el tiempo de ejecución.\n",
        "- `shuffle`: indica si se quiere aleatorizar el conjunto de datos por cada época, nosotros indicamos que sí para poder aprovechar las ventajas que provee la estocásticidad en el aprendizaje.\n",
        "- `random_state`: indica la semilla de números aleatorios. Nosotros no vemos conveniente usar o mantener un estado concreto de randomización, por tanto, especificamos que no.\n",
        "- `tol`: es el criterio de parada, similar a caso de SGD en RL, usaremos el valor por defecto de $10^{-3}$\n",
        "- `early_stopping`: indica si se quiere utilizar regularización mediante _early stopping_, como hemos dicho antes lo queremos utilizar, por tanto indicamos que sí.\n",
        "- `validation_fraction`: indica el tamaño del conjunto de validación para estimar $E_{out}$ en _early stopping_ para determinar el empeoramiento del error fuera de la muestra estimado. Como no queremos perjudicar el aprendizaje quitando muchos ejemplos de entrenamiento, indicaremos una fracción del $10\\%$ de los datos (fracción de `0.1`).\n",
        "- `n_iter_no_change`: indica el máximo número de épocas en la que hay mejora en la tolerancia, esto es un criterio de parada para determinar si se ha convergido finalmente a una solución. Vemos razonable usar un número de $5$ épocas debido al tamaño del dataset en cuestión, la probabilidad de mejora por eṕoca es mayor, por tanto, no es necesario en principio tener este valor muy alto, además de que ganamos en velocidad.\n",
        "\n",
        "Adicionalmente comentar que la arquitectura que usaremos para nuestra red será una red neuronal de $3$ capas contando la capa de salida, en la implementación mostramos solamente $2$ ya que `MLPClassifier` toma la dimensión de la capa de salida automáticamente del espacio de salida $\\mathcal Y$."
      ],
      "metadata": {
        "id": "Hsg6JTPGR2G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos los hiperparametros y sus valores así como los parámetros fijos a usar\n",
        "hidden_layers = [(50, 50), (75, 75), (100, 100)]\n",
        "lrs = [0.1, 0.01, 0.001]\n",
        "alphas = [0.01, 0.001, 0.0001]\n",
        "\n",
        "activation = 'relu'\n",
        "solver = 'sgd'\n",
        "batch_size = 'auto'\n",
        "max_iter = 20\n",
        "tol = 1e-3\n",
        "validation_fraction = 0.1\n",
        "n_iter_no_change = 5\n",
        "\n",
        "# Definimos las metricas que usaremos: Accuracy, Specificity, F1-Score, Metrica ponderada\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'specificity': make_scorer(specificity_score, average='macro'),\n",
        "    'f1': make_scorer(f1_score, average='macro'), # utilizo la opción average='macro' ya que estamos ante un problema\n",
        "                                                  # de clasificacion multiclase donde las clases estan aprox. equilibradas\n",
        "                                                  # por lo que se calcula un promedio global sobre las clases sin tener en cuenta\n",
        "                                                  # el desequilibrio\n",
        "    'rank_score': scorer\n",
        "}\n",
        "\n",
        "# Definimos un modelo base de MLP con valores de hiperparametros por defecto\n",
        "base_model = MLPClassifier(\n",
        "    activation=activation,\n",
        "    solver=solver,\n",
        "    batch_size=batch_size,\n",
        "    max_iter=max_iter,\n",
        "    tol=tol,\n",
        "    validation_fraction=validation_fraction,\n",
        "    n_iter_no_change=n_iter_no_change,\n",
        "    shuffle=True,\n",
        "    early_stopping=True,\n",
        "    random_state=None\n",
        ")\n",
        "\n",
        "# ejecutamos grid search sobre el learning rate inicial\n",
        "scores = single_grid_search_cv(model=base_model, X=X_train_proc, y=Y_train, hyper='learning_rate_init', values=lrs, folds=5, score=scoring)\n",
        "\n",
        "# obtengo las medias de los resultados\n",
        "scores_arr = scores.to_numpy()\n",
        "scores_arr_means = np.array([np.mean(x) for x in scores_arr[:, 1:].flatten()]).reshape(len(lrs),4)\n",
        "np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means))\n",
        "scores = pd.DataFrame(np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means)), columns=scores.columns, index=scores.index)\n",
        "\n",
        "scores"
      ],
      "metadata": {
        "id": "oibChub8i10I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "5095c5fb-594a-4634-cdc2-2bb0d635797c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  learning_rate_init test_accuracy test_specificity   test_f1 test_rank_score\n",
              "0                0.1      0.801879         0.995598  0.801372        0.830861\n",
              "1               0.01       0.72368          0.99386  0.721992        0.763954\n",
              "2              0.001      0.523323         0.989408  0.505197        0.590517"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad01a1ce-8f4a-4150-a82f-6c1088aaf3fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learning_rate_init</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_specificity</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>test_rank_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.801879</td>\n",
              "      <td>0.995598</td>\n",
              "      <td>0.801372</td>\n",
              "      <td>0.830861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.72368</td>\n",
              "      <td>0.99386</td>\n",
              "      <td>0.721992</td>\n",
              "      <td>0.763954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.523323</td>\n",
              "      <td>0.989408</td>\n",
              "      <td>0.505197</td>\n",
              "      <td>0.590517</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad01a1ce-8f4a-4150-a82f-6c1088aaf3fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad01a1ce-8f4a-4150-a82f-6c1088aaf3fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad01a1ce-8f4a-4150-a82f-6c1088aaf3fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5aedd605-54fd-419d-b57f-54735866e45e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5aedd605-54fd-419d-b57f-54735866e45e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5aedd605-54fd-419d-b57f-54735866e45e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos con la evaluación del _learning rate_ inicial, que al igual que con RL, la mejor tasa de aprendizaje sigue siendo el $\\eta=0.01$, además con métricas muy similares a las de RL; esto tiene sentido ya que ambos modelos hacen uso de la misma función de perdida, la _Cross Entropy_, luego es lógico que obtienen el mismo espacio de búsqueda y por eso se asemejan tanto. Por tanto, al igual que con RL elegimos como tasa de aprendizaje $\\eta=0.01$ que es el que mayor _rank score_ obtiene."
      ],
      "metadata": {
        "id": "fnj7RBTBqWPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ejecutamos grid search sobre el termino de regularización\n",
        "scores = single_grid_search_cv(model=base_model, X=X_train_proc, y=Y_train, hyper='alpha', values=alphas, folds=5, score=scoring)\n",
        "\n",
        "# obtengo las medias de los resultados\n",
        "scores_arr = scores.to_numpy()\n",
        "scores_arr_means = np.array([np.mean(x) for x in scores_arr[:, 1:].flatten()]).reshape(len(alphas),4)\n",
        "np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means))\n",
        "scores = pd.DataFrame(np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means)), columns=scores.columns, index=scores.index)\n",
        "\n",
        "scores"
      ],
      "metadata": {
        "id": "6APL3Kb2k-Gs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "6891d8c9-3462-4484-b257-9f53cf781c69"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    alpha test_accuracy test_specificity   test_f1 test_rank_score\n",
              "0    0.01      0.518711         0.989305  0.499378          0.5864\n",
              "1   0.001      0.512811         0.989174  0.492962        0.581288\n",
              "2  0.0001      0.521599         0.989369  0.504166         0.58915"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1057eb53-d741-4d08-9a06-a24be14b6fc6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alpha</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_specificity</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>test_rank_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.518711</td>\n",
              "      <td>0.989305</td>\n",
              "      <td>0.499378</td>\n",
              "      <td>0.5864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.512811</td>\n",
              "      <td>0.989174</td>\n",
              "      <td>0.492962</td>\n",
              "      <td>0.581288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.521599</td>\n",
              "      <td>0.989369</td>\n",
              "      <td>0.504166</td>\n",
              "      <td>0.58915</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1057eb53-d741-4d08-9a06-a24be14b6fc6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1057eb53-d741-4d08-9a06-a24be14b6fc6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1057eb53-d741-4d08-9a06-a24be14b6fc6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f7778da5-b23b-460c-afc9-140dab22045f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7778da5-b23b-460c-afc9-140dab22045f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f7778da5-b23b-460c-afc9-140dab22045f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En cuanto al término de regularización, vemos que los valores son muy similares entre sí, veamos que ocurre si usamos valores mas extremos en cambio para determinar si es que el modelo es insensible a estos cambios o tenemos que aumentar el espacio de búsqueda."
      ],
      "metadata": {
        "id": "Ne5XsKivrdIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ejecutamos grid search sobre el termino de regularización\n",
        "alphas = [0.00001, 0.1, 1]\n",
        "scores = single_grid_search_cv(model=base_model, X=X_train_proc, y=Y_train, hyper='alpha', values=alphas, folds=5, score=scoring)\n",
        "\n",
        "# obtengo las medias de los resultados\n",
        "scores_arr = scores.to_numpy()\n",
        "scores_arr_means = np.array([np.mean(x) for x in scores_arr[:, 1:].flatten()]).reshape(len(alphas),4)\n",
        "np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means))\n",
        "scores = pd.DataFrame(np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means)), columns=scores.columns, index=scores.index)\n",
        "\n",
        "scores"
      ],
      "metadata": {
        "id": "1jKHwya5tmvJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "03190383-cdbc-424e-b344-728e459ed9f9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   alpha test_accuracy test_specificity   test_f1 test_rank_score\n",
              "0  1e-05      0.523975         0.989422  0.505739        0.591057\n",
              "1    0.1      0.516165         0.989249  0.497064        0.584262\n",
              "2      1      0.491165         0.988693  0.465422        0.561933"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9cb79d6-f3f7-4bce-92cb-084a18dcfec5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alpha</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_specificity</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>test_rank_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1e-05</td>\n",
              "      <td>0.523975</td>\n",
              "      <td>0.989422</td>\n",
              "      <td>0.505739</td>\n",
              "      <td>0.591057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.516165</td>\n",
              "      <td>0.989249</td>\n",
              "      <td>0.497064</td>\n",
              "      <td>0.584262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.491165</td>\n",
              "      <td>0.988693</td>\n",
              "      <td>0.465422</td>\n",
              "      <td>0.561933</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9cb79d6-f3f7-4bce-92cb-084a18dcfec5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d9cb79d6-f3f7-4bce-92cb-084a18dcfec5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d9cb79d6-f3f7-4bce-92cb-084a18dcfec5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ad1c5744-77bd-4b13-9a28-ebb5894b5542\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ad1c5744-77bd-4b13-9a28-ebb5894b5542')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ad1c5744-77bd-4b13-9a28-ebb5894b5542 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que cuando empezamos a incrementar los valores de $\\lambda$ tenemos peor _rank score_, mientras que pasa al revés cuando decrementamos. Esto se debe a que cuando aumentamos el $\\lambda$ estamos restringiendo más los valores de los pesos y por tanto regulariza más, mientras que si decrementamos $\\lambda$ estamos dando mucha más libertad a estos valores. Sin embargo, es interesante notar que si decrementamos el valor de $\\lambda$ en un factor de $10$, tenemos resultados muy similares a cuando no decrementabamos, en este caso $Score(\\lambda = 0.0001) \\approx Score(\\lambda=0.00001)$, esto puede ser un signo de convergencia. En este caso optamos por el valor más alto de regularización que es $\\lambda = 0.0001$."
      ],
      "metadata": {
        "id": "XgYIX-bNv9Z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ejecutamos grid search sobre las dimensiones de las capas\n",
        "scores = single_grid_search_cv(model=base_model, X=X_train_proc, y=Y_train, hyper='hidden_layer_sizes', values=hidden_layers, folds=5, score=scoring)\n",
        "\n",
        "# obtengo las medias de los resultados\n",
        "scores_arr = scores.to_numpy()\n",
        "scores_arr_means = np.array([np.mean(x) for x in scores_arr[:, 1:].flatten()]).reshape(len(hidden_layers),4)\n",
        "np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means))\n",
        "scores = pd.DataFrame(np.hstack((scores_arr[:, 0].reshape(-1,1), scores_arr_means)), columns=scores.columns, index=scores.index)\n",
        "\n",
        "scores"
      ],
      "metadata": {
        "id": "itiDaIXMlQ2O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "50fc3e04-0683-41b0-a022-a98d7309c1e6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  hidden_layer_sizes test_accuracy test_specificity   test_f1 test_rank_score\n",
              "0           (50, 50)      0.484037         0.988535  0.468447        0.557373\n",
              "1           (75, 75)      0.539829         0.989774  0.531337        0.606047\n",
              "2         (100, 100)      0.567081          0.99038  0.559106        0.629379"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78c1098b-2aed-40cd-8842-4a588777390b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hidden_layer_sizes</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>test_specificity</th>\n",
              "      <th>test_f1</th>\n",
              "      <th>test_rank_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(50, 50)</td>\n",
              "      <td>0.484037</td>\n",
              "      <td>0.988535</td>\n",
              "      <td>0.468447</td>\n",
              "      <td>0.557373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(75, 75)</td>\n",
              "      <td>0.539829</td>\n",
              "      <td>0.989774</td>\n",
              "      <td>0.531337</td>\n",
              "      <td>0.606047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(100, 100)</td>\n",
              "      <td>0.567081</td>\n",
              "      <td>0.99038</td>\n",
              "      <td>0.559106</td>\n",
              "      <td>0.629379</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78c1098b-2aed-40cd-8842-4a588777390b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78c1098b-2aed-40cd-8842-4a588777390b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78c1098b-2aed-40cd-8842-4a588777390b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8bc83ac6-a746-4cd2-a09a-6c730a110fef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8bc83ac6-a746-4cd2-a09a-6c730a110fef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8bc83ac6-a746-4cd2-a09a-6c730a110fef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, la evaluación de las dimensiones de cada capa de la red que hemos considerado, podemos ver que cuando aumentamos la dimensión de las capas se obtiene una mejora con respecto a una dimensión mucho más simple; esto se debe a que, al agregar más neuronas por capa, la red es capaz de capturar propiedades no lineales más complejas. Por tanto, optamos por elegir una dimensión por capa oculta de $d(l_i) = 100,\\ \\ i = \\{1, 2\\}$."
      ],
      "metadata": {
        "id": "WjpPWTz8wQDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Obtención del mejor modelo $g$\n",
        "\n",
        "Teniéndo los modelos finalistas resultantes de elegir los mejores hiperparámetros elegidos mediante _grid search_, elegiremos el mejor modelo evaluando cada finalista y obteniendo sus _rank scores_."
      ],
      "metadata": {
        "id": "qHudWFO07Z2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tol = 1e-3\n",
        "# Definimos los finalistas\n",
        "best_rl = SGDClassifier(\n",
        "    eta0=0.01,\n",
        "    alpha=0.0001,\n",
        "    loss='log_loss',\n",
        "    penalty='l2',\n",
        "    max_iter=20,\n",
        "    shuffle=True,\n",
        "    learning_rate='constant', # Determinar que el learning rate es constante\n",
        "    tol=tol,\n",
        "    epsilon=0.1,\n",
        "    random_state=33\n",
        ")\n",
        "best_svm = SVC(\n",
        "    C=10,\n",
        "    kernel='rbf',\n",
        "    gamma='scale',\n",
        "    tol=tol,\n",
        "    class_weight=None,\n",
        "    max_iter=20,\n",
        "    decision_function_shape='ovr',\n",
        "    break_ties=True\n",
        ")\n",
        "best_mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(100,100),\n",
        "    learning_rate_init=0.1,\n",
        "    alpha=0.0001,\n",
        "    activation=activation,\n",
        "    solver=solver,\n",
        "    batch_size=batch_size,\n",
        "    max_iter=50,\n",
        "    tol=tol,\n",
        "    validation_fraction=validation_fraction,\n",
        "    n_iter_no_change=n_iter_no_change,\n",
        "    shuffle=True,\n",
        "    early_stopping=True,\n",
        "    random_state=33\n",
        ")"
      ],
      "metadata": {
        "id": "F-5afb4l92g3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos los modelos y obtenemos sus métricas\n",
        "scores_rl = cross_val(best_rl, X_train_proc, Y_train, 5, scoring)\n",
        "scores_svm = cross_val(best_svm, X_train_proc, Y_train, 5, scoring)\n",
        "scores_mlp = cross_val(best_mlp, X_train_proc, Y_train, 5, scoring)\n",
        "\n",
        "print('RL Rank Score:', scores_rl['test_rank_score'])\n",
        "print('SVM Rank Score:', scores_svm['test_rank_score'])\n",
        "print('MLP Rank Score:', scores_mlp['test_rank_score'])\n"
      ],
      "metadata": {
        "id": "Itq8GSkpBklh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4204e030-c097-460c-ed71-150cbf9dd4c2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RL Rank Score: [0.74802375 0.73708461 0.74366926 0.74072947 0.75132299]\n",
            "SVM Rank Score: [0.77833834 0.77382447 0.77950218 0.78065884 0.77757346]\n",
            "MLP Rank Score: [0.84597653 0.84650869 0.84574352 0.84475282 0.83443229]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('RL Rank Score:', scores_rl['test_rank_score'].mean())\n",
        "print('SVM Rank Score:', scores_svm['test_rank_score'].mean())\n",
        "print('MLP Rank Score:', scores_mlp['test_rank_score'].mean())"
      ],
      "metadata": {
        "id": "WRPTSXEYFP9Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4522a6-f557-4cee-ff7a-b9870f500a83"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RL Rank Score: 0.7441660157653729\n",
            "SVM Rank Score: 0.7779794588213709\n",
            "MLP Rank Score: 0.8434827687379289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar, el modelo que ha obtenido mejor _rank score_ ha sido el modelo del Perceptrón Multicapa con un puntaje medio de $0.84$, por tanto, según nuestro criterio de selección nuestro mejor modelo $g^*$ es el de MLP para nuestro problema de clasificación de dígitos.\n",
        "\n",
        "A continuación, realizamos un ajuste final sobre todo el conjunto de training para obtener el ajuste de la mejor hipótesis $g$ al problema."
      ],
      "metadata": {
        "id": "v84TVmsdEIrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = best_mlp\n",
        "best_model.fit(X_train_proc, Y_train)"
      ],
      "metadata": {
        "id": "hNqLLRsRGLNO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "511492eb-1f01-4ab8-a12b-3587e23cb2b7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 100),\n",
              "              learning_rate_init=0.1, max_iter=50, n_iter_no_change=5,\n",
              "              random_state=33, solver='sgd', tol=0.001)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 100),\n",
              "              learning_rate_init=0.1, max_iter=50, n_iter_no_change=5,\n",
              "              random_state=33, solver=&#x27;sgd&#x27;, tol=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(100, 100),\n",
              "              learning_rate_init=0.1, max_iter=50, n_iter_no_change=5,\n",
              "              random_state=33, solver=&#x27;sgd&#x27;, tol=0.001)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluación del Modelo Final"
      ],
      "metadata": {
        "id": "xCM9J3v7ya18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación pasaremos a evaluar nuestro ajuste $g$ con el conjunto que hemos reservado de test. Procederemos primero a transformar el conjunto de test con las mismas transformaciones que hicimos para el de train."
      ],
      "metadata": {
        "id": "MkiMEbRqGRe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizamos el conjunto de train\n",
        "X_test_proc = min_max_scaling(X_test, MIN_VALUES_TRAIN, MAX_VALUES_TRAIN)\n",
        "\n",
        "# Obtenemos el descriptor de caracteristicas HOG como nuestro nuevo conjunto de datos\n",
        "X_test_proc = extract_features(X_test_proc)\n",
        "\n",
        "X_test_proc.shape"
      ],
      "metadata": {
        "id": "PtRdP5_kGa1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43d2355-5abf-4e68-b71b-0ceb6241b7af"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27600, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora sí procedemos a evaluar nuestro modelo con el conjunto de test preprocesado y obtenemos sus métricas así como el error $E_{test}$ que estima $E_{out}$."
      ],
      "metadata": {
        "id": "lIy64Er1InDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model.predict(X_test_proc)\n",
        "\n",
        "# Creamos los scorers para adaptarlos a multiclase\n",
        "spec_scorer = make_scorer(specificity_score, average='macro')\n",
        "\n",
        "acc = accuracy_score(y_true=Y_test, y_pred=y_pred)\n",
        "spec = specificity_score(y_true=Y_test, y_pred=y_pred)\n",
        "f1 = f1_score(y_true=Y_test, y_pred=y_pred, average='macro')\n",
        "\n",
        "y_pred_proba = best_model.predict_proba(X_test_proc)\n",
        "loss = log_loss(Y_test, y_pred_proba)\n",
        "\n",
        "print('Acc_test:', acc)\n",
        "print('Spec_test:', spec)\n",
        "print('F1_test:', f1)\n",
        "print('Error de test (Función de Pérdida Loss_test):', loss)\n"
      ],
      "metadata": {
        "id": "CYWP26-RIhzc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea0ab77-06d2-4048-d565-cf238f3920bc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc_test: 0.822463768115942\n",
            "Spec_test: 0.9960542216038847\n",
            "F1_test: 0.8223799883976881\n",
            "Error de test (Función de Pérdida Loss_test): 0.6169379768818682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar, la solución final ha obtenido un buen error en test y buenos resultados en las metricas por lo que podemos afirmar que hemos obtenido un buen clasificador y unos buenos resultados (sin provocar overfitting por parte del modelo no lineal)"
      ],
      "metadata": {
        "id": "aiAo_zDZWq8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Curvas de aprendizaje"
      ],
      "metadata": {
        "id": "hl9YkDqcNkRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a crear las curvas de aprendizaje del modelo elegido separando de nuevo el conjunto de entrenamiento en un nuevo conjunto de validación del 20% y otro conjunto de entrenamiento del 80%, de forma parecida a como se hizo con el conjunto total de datos. Después voy a entrenar el modelo con un conjunto de datos inicialmente pequeño y obtengo el error de validación junto con el de entrenamiento, y cada iteración repito lo mismo pero con un subconjunto de datos mayor obtenido del conjunto de entrenamiento hasta utilizar el conjunto de datos total. Finalmente se crean las curvas de los errores $E_{in}$ de entrenamiento y $E_{out}$ estimado a partir del error obtenido del conjunto de validación."
      ],
      "metadata": {
        "id": "qOqnF4BBNkRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debido al alto coste computacional de entrenar varias veces el modelo con conjuntos de entrenamiento distintos, hemos utilizado un número bajo de entrenamientos y particiones del conjunto de entrenamiento para que no tarde en exceso en caclular las curvas de aprendizaje, entonces las curvas tienen poca desnidad de puntos, pero si se aumenta el numero de particiones (la variable `numiters` en el código), se consiguen curvas de aprendizaje con más densidad de puntos."
      ],
      "metadata": {
        "id": "zM0bcWGG_4dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "trainPortion = 0.8 #porcentaje de train, el porcentaje de validacion será la resta de 1 menos el porcentaje de train\n",
        "indexesData = np.arange(len(Y_train)) #Indices del conjunto de muestras\n",
        "np.random.shuffle(indexesData) #Desordenar indices de las muestras\n",
        "numberTrain = round(len(indexesData)*trainPortion) #numero de muestras para train\n",
        "trainIndexes = indexesData[:numberTrain]\n",
        "valIndexes = indexesData[numberTrain:]\n",
        "\n",
        "E_in = []\n",
        "E_out = []\n",
        "ejeX = []\n",
        "numiters = 10\n",
        "for i in range(1,numiters):\n",
        "  ejeX.append(i*len(trainIndexes)//numiters)\n",
        "  # Entrenar el modelo con los datos de entrenamiento\n",
        "  best_model.fit(X_train_proc[trainIndexes[:i*len(trainIndexes)//numiters]], Y_train[trainIndexes[:i*len(trainIndexes)//numiters]])\n",
        "  # Obtener error en entrenamiento\n",
        "  y_pred_proba = best_model.predict_proba(X_train_proc[trainIndexes[:i*len(trainIndexes)//numiters]])\n",
        "  E_in.append(log_loss(Y_train[trainIndexes[:i*len(trainIndexes)//numiters]], y_pred_proba))\n",
        "  # Obtener error en validación\n",
        "  y_pred_proba = best_model.predict_proba(X_train_proc[valIndexes])\n",
        "  E_out.append(log_loss(Y_train[valIndexes], y_pred_proba))\n",
        "\n",
        "# Mostrar plot con ambas curvas\n",
        "plt.figure()\n",
        "plt.title(\"Curvas de Aprendizaje\")\n",
        "plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
        "plt.ylabel(\"Error (función de pérdida de MLP)\")\n",
        "plt.plot(ejeX, E_out, 'r',label=r'$E_{out}$')\n",
        "plt.plot(ejeX, E_in, 'b',label=r'$E_{in}$')\n",
        "\n",
        "plt.legend(fontsize = 12) # poner el tamaño de la leyenda como en el resultado dado\n",
        "plt.grid(visible=True,linewidth=0.2) # poner la cuadricula con el grosor del resultado dado\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wrkCk-MINkRZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "71a8ba15-f444-49d8-f7d7-8dd122555f9f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACA6ElEQVR4nO3dd1hTZxsG8DtskCEuEIuiuHDjXnWi1FrXp3XvatVqtXVrnbV11C5rravOurVqbXHvUetGHIjirANxISDKyvv98ZZAZJhgwknC/buuXCTnnJw8ycshD+9UCSEEiIiIiCyEldIBEBERERkSkxsiIiKyKExuiIiIyKIwuSEiIiKLwuSGiIiILAqTGyIiIrIoTG6IiIjIojC5ISIiIovC5IaIiIgsCpMbIspxvXv3ho+Pj9JhmIUpU6ZApVJpbfPx8UHv3r2N8nrLly+HSqXCrVu3jHJ+opzA5IYoh1y/fh0DBgxAiRIl4ODgAFdXV9SrVw9z5szBy5cvlQ7PYowePRoqlQqdOnVSOhQiUoiN0gEQ5QZBQUH48MMPYW9vj549e6JChQpISEjA0aNHMWrUKFy6dAmLFi1SOkyzJ4TA2rVr4ePjgz///BMxMTFwcXFROiyDCwsLg5WVcf437dGjBzp37gx7e3ujnJ8oJzC5ITKymzdvonPnzihWrBj279+PwoULa/YNHjwY4eHhCAoKMshrvXjxAnny5DHIuczRwYMHcffuXezfvx+BgYHYvHkzevXqZdDXiIuLg5OTk0HPqS9jJh7W1tawtrY22vmJcgKbpYiM7JtvvkFsbCyWLFmildikKFmyJIYNGwYAuHXrFlQqFZYvX57uOJVKhSlTpmgep/TFuHz5Mrp27Qp3d3fUr18f3377LVQqFW7fvp3uHOPGjYOdnR2ePXsGADhy5Ag+/PBDFC1aFPb29vD29sbnn3+erpksIiICffr0wTvvvAN7e3sULlwYbdq00alfxtatW1GhQgU4ODigQoUK2LJlS4bHqdVq/PjjjyhfvjwcHBzg4eGBAQMGaGLVxerVq1GuXDk0btwYAQEBWL16dbpjDh48CJVKhfXr12P8+PHw9PREnjx50Lp1a/z7779axzZq1AgVKlTAmTNn0KBBAzg5OWH8+PEAgPj4eEyePBklS5bUfHajR49GfHy81jlUKhWGDBmi+Rzs7e1Rvnx57Ny5M11sR48eRY0aNeDg4ABfX18sXLgww/f5ep8blUqV6S2ljEJCQtC7d29Ns6inpyf69u2LJ0+eaJ07sz43O3bswLvvvos8efLAxcUFLVu2xKVLlzKMj0hprLkhMrI///wTJUqUQN26dY1y/g8//BClSpXC9OnTIYTABx98gNGjR2PDhg0YNWqU1rEbNmxA8+bN4e7uDgDYuHEj4uLiMGjQIOTPnx8nT57E3LlzcffuXWzcuFHzvPbt2+PSpUv49NNP4ePjg8jISOzZswd37tzJsmPw7t270b59e5QrVw4zZszAkydPNEnS6wYMGIDly5ejT58+GDp0KG7evImff/4Z586dw7Fjx2Bra5vl5xAfH4/ff/8dI0aMAAB06dIFffr0QUREBDw9PdMd//XXX0OlUmHMmDGIjIzEjz/+iICAAAQHB8PR0VFz3JMnT9CiRQt07twZ3bt3h4eHB9RqNVq3bo2jR4/i448/hp+fHy5cuIAffvgBV69exdatW7Ve6+jRo9i8eTM++eQTuLi44KeffkL79u1x584d5M+fHwBw4cIFNG/eHAULFsSUKVOQlJSEyZMnw8PDI8v3DQC//fZbum0TJkxAZGQknJ2dAQB79uzBjRs30KdPH3h6emqaQi9duoR//vknXafl18/fq1cvBAYGYtasWYiLi8P8+fNRv359nDt3jp3DyfQIIjKa58+fCwCiTZs2Oh1/8+ZNAUAsW7Ys3T4AYvLkyZrHkydPFgBEly5d0h1bp04dUa1aNa1tJ0+eFADEypUrNdvi4uLSPXfGjBlCpVKJ27dvCyGEePbsmQAgZs+erdN7SKtKlSqicOHCIioqSrNt9+7dAoAoVqyYZtuRI0cEALF69Wqt5+/cuTPD7RnZtGmTACCuXbsmhBAiOjpaODg4iB9++EHruAMHDggAokiRIiI6OlqzfcOGDQKAmDNnjmZbw4YNBQCxYMECrXP89ttvwsrKShw5ckRr+4IFCwQAcezYMc02AMLOzk6Eh4drtp0/f14AEHPnztVsa9u2rXBwcNB87kIIcfnyZWFtbS1e/1NdrFgx0atXr0w/i2+++Uansl67dq0AIA4fPqzZtmzZMgFA3Lx5UwghRExMjMibN6/o37+/1nMjIiKEm5tbuu1EpoDNUkRGFB0dDQBG7dQ6cODAdNs6deqEM2fO4Pr165pt69evh729Pdq0aaPZlraG4sWLF3j8+DHq1q0LIQTOnTunOcbOzg4HDx7Uq4nowYMHCA4ORq9eveDm5qbZ3qxZM5QrV07r2I0bN8LNzQ3NmjXD48ePNbdq1arB2dkZBw4ceOPrrV69GtWrV0fJkiUBQNN0klHTFAD07NlTq1w6dOiAwoULY/v27VrH2dvbo0+fPuni9fPzQ9myZbXibdKkCQCkizcgIAC+vr6ax5UqVYKrqytu3LgBAEhOTsauXbvQtm1bFC1aVHOcn58fAgMD3/je0zpw4ADGjRuHTz/9FD169NBsT1vWr169wuPHj1G7dm0AwNmzZzM93549exAVFYUuXbpovVdra2vUqlVLp7IhymlMboiMyNXVFQAQExNjtNcoXrx4um0ffvghrKyssH79egByFNHGjRvRokULTUwAcOfOHfTu3Rv58uWDs7MzChYsiIYNGwIAnj9/DkB+uc+aNQs7duyAh4cHGjRogG+++QYRERFZxpXS56dUqVLp9pUpU0br8bVr1/D8+XMUKlQIBQsW1LrFxsYiMjIyy9eKiorC9u3b0bBhQ4SHh2tu9erVw+nTp3H16tV0z3k9LpVKhZIlS6bra1KkSBHY2dmli/fSpUvpYi1dujQApIs3bcKSwt3dXZMsPnr0CC9fvtTps8rK3bt30alTJ9SrVw/ff/+91r6nT59i2LBh8PDwgKOjIwoWLKj53Ukp64xcu3YNANCkSZN073f37t1vLBsiJbDPDZERubq6wsvLCxcvXtTp+Mz6PSQnJ2f6nLT/kafw8vLCu+++iw0bNmD8+PH4559/cOfOHcyaNUvrnM2aNcPTp08xZswYlC1bFnny5MG9e/fQu3dvqNVqzbGfffYZWrVqha1bt2LXrl2YOHEiZsyYgf3798Pf31+n95YVtVqNQoUKZVrLUrBgwSyfv3HjRsTHx+O7777Dd999l27/6tWrMXXq1GzFltHnq1arUbFixXQJRApvb2+tx5mNPhJCZCumjCQkJKBDhw6wt7fHhg0bYGOj/ee9Y8eO+PvvvzFq1ChUqVIFzs7OUKvVeO+997TK+nUp+3777bcM+y69/jpEpoC/lURG9sEHH2DRokU4fvw46tSpk+WxKR19o6KitLZnNPLpTTp16oRPPvkEYWFhWL9+PZycnNCqVSvN/gsXLuDq1atYsWIFevbsqdm+Z8+eDM/n6+uLESNGYMSIEbh27RqqVKmC7777DqtWrcrw+GLFigFI/c8/rbCwsHTn3rt3L+rVq5dhMvEmq1evRoUKFTB58uR0+xYuXIg1a9akS25ej0sIgfDwcFSqVOmNr+fr64vz58+jadOmWXbE1VXBggXh6Oio02eVmaFDhyI4OBiHDx9O1wn52bNn2LdvH6ZOnYpJkyZptmf0eq9LaU4rVKgQAgICdIqFSGlsliIystGjRyNPnjzo168fHj58mG7/9evXMWfOHACypqdAgQI4fPiw1jG//PKL3q/bvn17WFtbY+3atdi4cSM++OADrTlwUmoT0tYeCCE0saSIi4vDq1evtLb5+vrCxcUl3bDntAoXLowqVapgxYoVWs0ee/bsweXLl7WO7dixI5KTkzFt2rR050lKSkqX7KX177//4vDhw+jYsSM6dOiQ7tanTx+Eh4fjxIkTWs9buXKlVnPhpk2b8ODBA7Ro0SLT10ob771797B48eJ0+16+fIkXL1688RxpWVtbIzAwEFu3bsWdO3c020NDQ7Fr1643Pn/ZsmVYuHAh5s2bh5o1a2Z4fiB9TdGPP/74xnMHBgbC1dUV06dPR2JiYrr9jx49euM5iHIaa26IjMzX1xdr1qxBp06d4OfnpzVD8d9//42NGzdqzVnSr18/zJw5E/369UP16tVx+PDhDPuMvEmhQoXQuHFjfP/994iJiUm3HEHZsmXh6+uLkSNH4t69e3B1dcXvv/+ertPw1atX0bRpU3Ts2BHlypWDjY0NtmzZgocPH6Jz585ZxjBjxgy0bNkS9evXR9++ffH06VPMnTsX5cuXR2xsrOa4hg0bYsCAAZgxYwaCg4PRvHlz2Nra4tq1a9i4cSPmzJmDDh06ZPgaa9asgRACrVu3znD/+++/DxsbG6xevRq1atXSbM+XLx/q16+PPn364OHDh/jxxx9RsmRJ9O/fP8v3BMhZfDds2ICBAwfiwIEDqFevHpKTk3HlyhVs2LABu3btQvXq1d94nrSmTp2KnTt34t1338Unn3yCpKQkzWcVEhKS6fMeP36MTz75BOXKlYO9vX26mrR27drB1dVV01cqMTERRYoUwe7du3Hz5s03xuXq6or58+ejR48eqFq1Kjp37oyCBQvizp07CAoKQr169fDzzz/r9V6JjE65gVpEucvVq1dF//79hY+Pj7CzsxMuLi6iXr16Yu7cueLVq1ea4+Li4sRHH30k3NzchIuLi+jYsaOIjIzMdCj4o0ePMn3NxYsXCwDCxcVFvHz5Mt3+y5cvi4CAAOHs7CwKFCgg+vfvrxmmnDIc/fHjx2Lw4MGibNmyIk+ePMLNzU3UqlVLbNiwQaf3/fvvvws/Pz9hb28vypUrJzZv3ix69eqlNRQ8xaJFi0S1atWEo6OjcHFxERUrVhSjR48W9+/fz/T8FStWFEWLFs0yhkaNGolChQqJxMREzVDwtWvXinHjxolChQoJR0dH0bJlS61h2ELIoeDly5fP8JwJCQli1qxZonz58sLe3l64u7uLatWqialTp4rnz59rjgMgBg8enO75GQ3nPnTokKhWrZqws7MTJUqUEAsWLNCUc2bPTZk+ILNbypDuu3fvinbt2om8efMKNzc38eGHH4r79++n+716fSh4igMHDojAwEDh5uYmHBwchK+vr+jdu7c4ffp0Fp88kTJUQhiwRxsRkYk7ePAgGjdujI0bN2ZaG5SbLVmyBP369cO///6b4WSLROaAfW6IiEjjwYMHUKlUyJcvn9KhEGUb+9wQEREePnyITZs2YcGCBahTp47ii4MSvQ3W3BAREUJDQzFq1CiULFkyw4VbicwJ+9wQERGRRWHNDREREVkUJjdERERkUXJlh2K1Wo379+/DxcXFIFOnExERkfEJIRATEwMvLy9YWWVeP5Mrk5v79++nW9iOiIiIzMOb5mHKlcmNi4sLAPnhuLq6KhyNaUuZIt/Z2VnhSEgfLDfzwzIzTyy3nBUdHQ1vb2/N93hmcmVyk9IU5erqyuTmDVKq/XjhmheWm/lhmZknlpsy3tSlhB2KiYiIyKIwuSEiIiKLwuSGiIiILAqTGyIiIrIoubJDMRERkb6Sk5ORmJiotS0+Ph4AYGPDr9O3YWtrC2tra4Odj6VBRESUBSEEIiIi8Pz5c7y+HKNarQaALCeUozdTqVRwc3ODp6enQSbXZXJDRESUhefPnyMqKgoFCxZEnjx5tL58k5OTAcCgtQ65jRACL168wKNHj+Do6Ii8efO+9TmZ3BAREWVCCIHIyEi4urqiQIEC6fYzuTEMR0dHxMfHIzIyEm5ubm9de8N6NCIiokwkJycjOTmZE77mAFdXV83n/baY3BAREWUiKSkJADsM54SUzzjlM38bTG6IiIjewBCdXClrhvyMmdwQERGRRWFyY0hqNbBzJ/DaUEEiIiLKOUxuDEWtBmrXBlq0AHbvVjoaIiKiXIvJjaFYWQH168v7U6aw9oaIiMzCrl27oFKpMr2tXLlS6RD1xu7fhjR6NDB/PvDPP8CePUDz5kpHRERElKXz588DAH766Se4u7un2x8YGJjTIb01JjeG5OkJDBwI/PijrL1p1gxgD3siIjJhISEhcHNzw5AhQyxmVBibpQxt9GjAwQE4fhzYu1fpaIiIiLJ0/vx5+Pv7W0xiAzC5MbzChYEBA+R99r0hIiITlpCQgLCwMJQtWxaPHz9Od3t9FXRzwWYpYxg9GliwAPj7b2DfPiAgQOmIiIjIUIQA4uLk/ZSlApReW8rJKVvdIC5fvozExEQsWLAACxYsSLc/LCwMpUuXNkSEOYrJjTF4ecnam59+krU3TZuy7w0RkaWIiwOcnQEAJrNcZmwskCeP3k8LCQkBACxfvhxFihRJt79UqVJvHZoSmNwYy5gxwMKFwLFjwP79MsEhIiIyIefPn4eNjQ26dOkCOzs7o7yGEAIuLi64ceMGChUqZJTXeB2TG2Px8gI+/hiYO1fW3jRpwtobIiJL4OQka0oAzQrW1qbQLJUNISEhKF68uNESGwC4efMmnJycciyxAdih2LjGjAHs7ICjR4EDB5SOhoiIDEGlkk1ApnTL5j/PISEh8PPze+NxSUlJmDhxIry8vFCgQAEMHz4c4r8BM59++immTZumOTYoKAgNGzYEAISGhqJcuXJ49uwZnJ2dUaNGjWzFqS8mN8ZUpIisvQE4coqIiExKREQEIiMjUbZs2TceO2LECFy6dAmXLl3CtWvXsHfvXmzcuBGATJAqVaqkOfbChQuax35+fpg8eTIGDRqE2NhYnDp1yjhv5jVsljK2MWOARYuAI0eAgweBxo2VjoiIiEgzM/GjR4+watWqdPsrV66MihUr4u7du1i5ciVu3boFNzc3AECLFi1w5swZdOzYUSuZAWRyk1JzA8jkp0mTJkZ+N9qY3BjbO+8A/fsD8+bJ2hsmN0REZAJSRkotW7YMy5YtS7d/5cqVqFixIg4fPoxatWppEhsAePr0Kfz8/HD37l0kJSXBx8dHs+/ChQsYMmSI1ut89tlnRnsfGWGzVE4YO1b2vTl8WNbeEBERKWzUqFEQQmR669GjBwDgyZMnyJs3r+Z5iYmJ2LVrF2rXro3Lly+jfPnymtmNIyIicPnyZVSoUAGAnCTw2rVrmsc5hclNTnjnHaBfP3l/yhRFQyEiItJHtWrVcPjwYdy7dw9RUVEYMGAAqlSpgrp160KlUiEmJgZqtRqvXr3C4MGD4e3tDRcXFwBATEwMAJnk5CQmNzklpfbm0CHW3hARkdmoW7cuBg4cCH9/f/j6+sLOzg5r164FADRs2BBFihSBn58f2rRpAx8fH1SsWFHz3Pz586NLly4oWrQoateunWMxq4TIfUN4oqOj4ebmhufPn8PV1TXnXviTT4D584FGjcxmaHjsf3M5OP83GyeZB5ab+WGZmaZXr17h5s2bKF68OBwcHNLtN5l5bizAmz5rQPfvb9bc5KRx4wBbW1lzc+iQ0tEQERFZJCY3OcnbG/joI3l/6lRlYyEiIrJQTG5yWkrtzYEDcvQUERERGRSTm5xWtCjQt6+8z9obIiIig2Nyo4SU2pv9++XMxURERGQwTG6UUKwY0KePvM/aGyIiIoNicqOU8eMBGxtg3z65ajgREREZBJMbpbD2hoiIyCiY3CgppfZm717g2DGloyEiIrIITG6U5OMD9O4t77P2hoiIyCCY3CgtpfZmzx7g77+VjoaIiMjsMblRWvHiQK9e8j5rb4iIiN4akxtTkFJ7s3s3cPy40tEQEVEusmvXLqhUqkxvK1euVDpEvdkoHQABKFEC6NkTWLpU1t7s3Kl0RERElEucP38eAPDTTz/B3d093f7AwMCcDumtMbkxFV98AaxYAezaBfzzD1C7ttIRERFRLhASEgI3NzcMGTIEKpVK6XAMgs1SpiKl9gZg3xsiIsox58+fh7+/v8UkNgCTG9PyxReAtbVsljpxQuloiIjIwiUkJCAsLAxly5bF48eP090SExOVDjFb2CxlSnx9gR49gOXLZe3N9u1KR0RERK8RAoiLk/eTk+VPa2vl4gEAJycgOxUvly9fRmJiIhYsWIAFCxak2x8WFobSpUsbIMKcxeTG1HzxBfDbb8COHcDJk0DNmkpHREREacTFAc7OKY8Uzmr+ExsL5Mmj//NCQkIAAMuXL0eRIkXS7S9VqhQAID4+HkWLFsW1a9fg6ur6VrHmBCY3pqZkSaB7d9m5eOpUIChI6YiIiMhCnT9/HjY2NujSpQvs7OwyPc7e3h4PHz7MwcjeDpMbUzRhArBqlWyWYu0NEZFJcXKSNSUAkPxfu5S1wu1STk7Ze15ISAiKFy+eZWJjjpjcmKKSJYFu3YCVK4EvvwT++kvpiIiI6D8qVWoTkKn0ucmukJAQ1NZh6pE5c+YgJCQES5YswXfffYdTp07B1tYW27ZtQ5EiRfDnn3/C19c3ByLWDUdLmaoJEwArK9ksdeqU0tEQEZGFiYiIQGRkJMqWLfvGY0NCQlCpUiUAwIULF/D3339jyJAhePr0KSpUqIClS5caO1y9KJ7cHD58GK1atYKXlxdUKhW2bt2a5fGbN29Gs2bNULBgQbi6uqJOnTrYtWtXzgSbk0qVkrU3gKy9ISIiMqCUmYkfPXqEVatWpbtduHBBc+zryc2UKVNQq1YtWFtbo1SpUhBCKPIeMqN4cvPixQtUrlwZ8+bN0+n4w4cPo1mzZti+fTvOnDmDxo0bo1WrVjh37pyRI1VASu3NX38Bp08rHQ0REVmQlJFSy5YtQ48ePdLdgoODAQBqtRqXL19GpUqVkJycjMuXL6NFixaa81y6dEmn2p+cpBImlG6pVCps2bIFbdu21et55cuXR6dOnTBp0iSdjo+OjoabmxueP39u+kPaevaUQ8NbtQK2bcvxl4/9r9ecc+q4RzIDLDfzwzIzTa9evcLNmzdRvHhxODg4pNtvKh2Kjenq1ato1KgR7t+/j7CwMDRo0EBr5FSJEiWwefNmVKlS5a1e502fNaD797fZdyhWq9WIiYlBvnz5Mj0mPj4e8fHxmsfR0dEA5B8TKyvFK6+ypPr8czitXg3Vn38i7sgRqP39c/T141JmqiKzwnIzPywz0xQfHw+1Wo3k5GRNIpOWWq1WIKqcFRwcjIoVKyI5ORnnz5/X1OAAQExMDO7du4cyZcpk+PnoIzk5GWq1Gi9evEBSUlKGx6T8E/Ampv3NroNvv/0WsbGx6NixY6bHzJgxA25ubpqbt7d3Dkb4dkSpUkj6773ZzZypcDRERJTbXLhwARUrVtTcT+l7AwAXL15E6dKlTW4ouVk3S61Zswb9+/fHH3/8gYCAgEyPy6jmxtvb2zyapQAgLAwoVw5Qq4EzZ4CqVXPspVlVbp5YbuaHZWaa2CyVcwzZLGW2NTfr1q1Dv379sGHDhiwTG0DOrOjq6qp1MytlygBdusj7HDlFRESUJbNMbtauXYs+ffpg7dq1aNmypdLh5IwJE+TMUX/8AVjiyDAiIiIDUTy5iY2NRXBwsGbI2c2bNxEcHIw7d+4AAMaNG4eePXtqjl+zZg169uyJ7777DrVq1UJERAQiIiLw/PlzJcLPOWXLsvaGiIhIB4onN6dPn4a/vz/8/xsFNHz4cPj7+2uGdT948ECT6ADAokWLkJSUhMGDB6Nw4cKa27BhwxSJP0el1N5s3Qr8lwwSERGRNsWHgjdq1CjLmQ2XL1+u9fjgwYPGDciU+fkBnTsDa9fK2pvNm5WOiIgoVzChsTcWy5CfseI1N6SniRNl7c2WLcB/U2cTEZFx2NraAuA8RDkh5TNO+czfhuI1N6QnPz+gUydg3TpZe/P770pHRERksaytrZE3b15ERkYCAJycnKBSqTT7ORT87QkhEBcXh8jISOTNm9cgn6VeyU1UVBS2bNmCI0eO4Pbt24iLi0PBggXh7++PwMBA1K1b960DIh1MnAisXy+bpUJCgDQTKhERkWF5enoCgCbBSStlhmJTn+3eHOTNm1fzWb8tnSbxu3//PiZNmoTVq1fDy8sLNWvWhJeXFxwdHfH06VNcvHgRZ86cQbFixTB58mR06tTJIMEZi1mtLZWZzp1lgtO+PbBpk9FehhOLmSeWm/lhmZm+5ORkJCYmam178eIFACBPnjxKhGQxbG1tdaqxMejaUv7+/ujVqxfOnDmDcuXKZXjMy5cvsXXrVvz444/4999/MXLkSF1OTdk1cSKwYYNslmLtDRGR0VlbW6f7Ak5ZAymzGXVJGTrV3Dx58gT58+fX+aT6Hp/TLKLmBpB9bzZsADp0ADZuNMpL8L9J88RyMz8sM/PEcstZBl1+IW2iEh8fr6mG0+V4MqKJE+XPTZuACxeUjYWIiMhE6NwD6tGjR2jRogWcnZ3h6uqK2rVrIzw83Jix0ZtUqAB8+KG8P22asrEQERGZCJ2TmzFjxiA4OBhffvklvv32W0RFRaF///7GjI10kVJ7s3EjcPGisrEQERGZAJ2Hgu/ZswfLly9HYGAgAOCDDz6An58f4uPjYW9vb7QA6Q0qVpR9bjZtkrU369crHREREZGidK65uX//PipXrqx5XKpUKdjb2+PBgwdGCYz08N86XNi4Ebh0SdlYiIiIFKbXrEOvD4GztrbmehumoGJFOd+NEOx7Q0REuZ7OyY0QAqVLl0a+fPk0t9jYWPj7+2ttI4Wk1N5s2ABcvqxsLERERArSuc/NsmXLjBkHva1KlYD//U8uyTBtmlw5nIiIKBfSaRI/XSQlJSEyMhJeXl6GOJ1RWcwkfq87fx6oUkWuGn7xIpDJbNL64ARV5onlZn5YZuaJ5ZazDDqJny4uXboEb29vQ52OsqNyZaBdO9n35quvlI6GiIhIEVzG1NKk9L1Ztw4IDVU2FiIiIgUwubE0VaoAbduy9oaIiHItJjeWKKX2Zu1a4MoVZWMhIiLKYTqPlgoJCclyf1hY2FsHQwbi7w+0aQP88YesvVm1SumIiIiIcozOo6WsrKygUqkynLQvZbtKpUJycrLBgzQ0ix0tlda5c0DVqoCVlZz3pkyZbJ2GIwHME8vN/LDMzBPLLWfp+v2tc83NzZs3DRIY5RB/f6B1a2DbNll789tvSkdERESUIww2z405yRU1NwBw9ixQrZqsvQkNBUqX1vsU/K/EPLHczA/LzDyx3HKWwWtu7ty5o9NxRYsW1fWUZGxVqwKtWgF//ilrb1auVDoiIiIio9M5uSlevLjmfkplj0ql0tpmLn1ucpXJk2Vys3o1MGFCtmpviIiIzInOyY1KpcI777yD3r17o1WrVrCx0fmppKRq1YAPPgD++gv4+mtgxQqlIyIiIjIqnee5uXv3LgYNGoR169ahZcuW+O2332BnZ4fKlStr3cgETZ4sf65aBVy7pmwsRERERqZzcuPp6YkxY8bgypUr2LRpE549e4ZatWqhdu3aWLx4MdRqtTHjpLdRvTrQsiWgVsvaGyIiIguWrRmK69evjyVLluDatWtwcnLCwIEDERUVZeDQyKDS1t6EhysbCxERkRFlK7n5+++/0a9fP5QuXRqxsbGYN28e8ubNa+DQyKBq1ADefx9ITmbtDRERWTSdk5sHDx5g1qxZKFu2LNq1awdXV1ccO3YMJ0+exMCBA2FlxWWqTF5K7c1vvwHXrysbCxERkZHoPOSpaNGiKFKkCHr16oXWrVvD1tYWarU63ZpTlSpVMniQZCA1awItWgA7dsjam6VLlY6IiIjI4PRaW0rzpP/mt3n9qeYyz02umaE4IydOALVrA9bWQFgY4Oub5eGcfdM8sdzMD8vMPLHcchbXlqKM1aoFvPcesHMnMH06sGSJ0hEREREZlM7JTbFixYwZB+WkyZNlcrNiBfDFF0CJEkpHREREZDDsBZwb1a4NBAbKkVPTpysdDRERkUExucmtUkZOrVgB3LihbCxEREQGxOQmt6pTB2jeHEhKYu0NERFZFCY3uVna2ht2GCciIguRreQmKSkJe/fuxcKFCxETEwMAuH//vmZIHJmJunWBZs1Ye0NERBZF7+Tm9u3bqFixItq0aYPBgwfj0aNHAIBZs2Zh5MiRBg+QjCyl9mb5cuDWLSUjISIiMgi9k5thw4ahevXqePbsGRwdHTXb27Vrh3379hk0OMoB9eoBAQGsvSEiIouhd3Jz5MgRTJgwAXZ2dlrbfXx8cO/ePYMFRjkopfZm2TLg9m1lYyEiInpLeic3arU6wyUW7t69CxcXF4MERTmsfn2gaVPW3hARkUXQO7lp3rw5fvzxR81jlUqF2NhYTJ48Ge+//74hY6OcxNobIiKyEHonN9999x2OHTuGcuXK4dWrV+jataumSWrWrFnGiJFywrvvAk2aAImJwIwZSkdDRESUbTqvCp5WUlIS1q1bh5CQEMTGxqJq1aro1q2bVgdjU5arVwXPyuHDQMOGgK0tEB4OFC3KFW/NFMvN/LDMzBPLLWcZfFVwrSfZ2KB79+7ZDo5MVIMGsvZm/35ZezN/vtIRERER6U2n5Gbbtm06n7B169bZDoZMwOTJMrlZsgQYPx5wd1c6IiIiIr3olNy0bdtW67FKpcLrrVkqlQoAMhxJRWakQQOgcWPgwAFZe/PNN0pHREREpBedOhSr1WrNbffu3ahSpQp27NiBqKgoREVFYceOHahatSp27txp7HgpJ6SMnFqyBKq7d5WNhYiISE9697n57LPPsGDBAtSvX1+zLTAwEE5OTvj4448RGhpq0ABJAQ0bAo0aAQcPwvb775Hw/fdKR0RERKQzvYeCX79+HXnz5k233c3NDbe4NpHl+K/2xnbFCqg48zQREZkRvZObGjVqYPjw4Xj48KFm28OHDzFq1CjUrFnToMGRgho1Aho2hCohAbasuSEiIjOid3KzdOlSPHjwAEWLFkXJkiVRsmRJFC1aFPfu3cOSJUuMESMpJaX2ZvlygLU3RERkJvTuc1OyZEmEhIRgz549uHLlCgDAz88PAQEBmhFTZCEaNUJyvXqwPnYMmDkTmDtX6YiIiIjeSO+aG0AO+27evDmGDh2KoUOHolmzZtlObA4fPoxWrVrBy8sLKpUKW7dufeNzDh48iKpVq8Le3h4lS5bE8uXLs/Xa9AYqFRLGjZP3Fy9m7Q0REZmFbCU3hvTixQtUrlwZ8+bN0+n4mzdvomXLlmjcuDGCg4Px2WefoV+/fti1a5eRI82dkhs0QHLdukB8PMC1w4iIyAxka20pY1GpVNiyZUu6SQPTGjNmDIKCgnDx4kXNts6dOyMqKkrneXa4tpTuYmNjYX3wIBxbtQLs7YEbNwAvL6XDojfgejfmh2VmnlhuOUvX72/Fa270dfz4cQQEBGhtCwwMxPHjxxWKyPIlN2wI1K/P2hsiIjIL2Vo4U0kRERHw8PDQ2ubh4YHo6Gi8fPkyw5XJ4+PjER8fr3kcHR0NQGbcVlZml9/lqLi4OACA9ejRcDx6FGLRIsR9+imEp6fCkVFWUsqNzAfLzDyx3HJWSk3Zm7zVN/urV68QHR2tdTNFM2bMgJubm+bm7e2tdEhmJ7lRIyTXrg3Vq1ewGz8e4BpiRERkovSuuYmLi8Po0aOxYcMGPHnyJN1+Yy+c6enpqTWBICAnEXR1dc2w1gYAxo0bh+HDh2seR0dHw9vbG87Ozmwn1ZGzs7McDt64MWw3boRtcjKwejXg4KB0aJQF/n6bH5aZeWK55Qy1Wq3TcXrX3IwaNQr79+/H/PnzYW9vj19//RVTp06Fl5cXVq5cqXeg+qpTpw727duntW3Pnj2oU6dOps+xt7eHq6ur1o2yoWFDYMMGwM4O2LwZaNECeP5c6aiIiIi06J3c/Pnnn/jll1/Qvn172NjY4N1338WECRMwffp0rF69Wu8AYmNjERwcjODgYAByqHdwcDDu3LkDQNa69OzZU3P8wIEDcePGDYwePRpXrlzBL7/8gg0bNuDzzz/X+7UpGzp0AHbuBFxcgIMHZcITEaF0VERERBp6JzdPnz5FiRIlAACurq54+vQpAKB+/fo4fPiw3gGcPn0a/v7+8Pf3BwAMHz4c/v7+mDRpEgDgwYMHmkQHAIoXL46goCDs2bMHlStXxnfffYdff/0VgYGBer82ZVPjxsChQ4CHB3D+PFCvHhAernRUREREALLR56ZEiRK4efMmihYtirJly2LDhg2oWbMm/vzzzwxXC3+TRo0aIaupdjKafbhRo0Y4d+6c3q9FBuTvDxw7BgQGAtevywRnxw6galWlIyMiolxO75qbPn364Pz58wCAsWPHYt68eXBwcMDnn3+OUaNGGTxAMmG+vjLB8fcHIiNlE9Vr/aGIiIhy2lvPUHz79m2cOXMGJUuWRKVKlQwVl1FxhmLd6TT7ZnQ00K4dsH+/7Gy8ahXw4Yc5FCFlhLOmmh+WmXliueUsXb+/33oSv2LFiqFYsWJvexoyZ66uwPbtQPfuwKZNQKdOwKNHwCefKB0ZERHlQjolNz/99JPOJxw6dGi2gyEzZm8PrFsHDB0K/PILMHiwHEU1dSqQzRXjiYiIskOn5OaHH37Qevzo0SPExcVpOhBHRUXByckJhQoVYnKTm1lbAz//LEdRTZ4MTJsGPHwokx1ra6WjIyKiXEKnDsU3b97U3L7++mtUqVIFoaGhePr0KZ4+fYrQ0FBUrVoV06ZNM3a8ZOpUKmDSJGDBAsDKCli0SPa/efVK6ciIiCiX0LtDsa+vLzZt2qSZlybFmTNn0KFDB9y8edOgARoDOxTr7q06y23eDHTpAiQkyJFUf/wBuLkZOELKCDs5mh+WmXliueUsXb+/9R4K/uDBAyQlJaXbnpycnG7NJ8rl/vc/YNcu2eH40CGZ4Dx4oHRURERk4fRObpo2bYoBAwbg7Nmzmm1nzpzBoEGDEBAQYNDgyAI0apR+NuNr15SOioiILJjeyc3SpUvh6emJ6tWrw97eHvb29qhZsyY8PDzw66+/GiNGMndVqgB//y0n/bt5UyY4Z84oHRUREVkovee5KViwILZv346rV6/iypUrAICyZcuidOnSBg+OLEiJEnI24/ffB86elTU6W7YArO0jIiIDy/YkfqVLl2ZCQ/rx8AAOHJB9cfbtk4nOqlVAx45KR0ZERBZEp+Rm+PDhmDZtGvLkyYPhw4dneez3339vkMDIQrm6AkFBQM+ewIYNQOfOcl2qIUOUjoyIiCyETsnNuXPnkJiYqLmfGRVnoiVd2NsDa9YABQsC8+YBn34qJ/v78kvOZkxERG9Np+TmwIEDGd4nyjZra2DuXMDTE5g4Efjqq9TZjG3eeskzIiLKxfQeLUVkMCoVMGGCnMXYygpYvJizGRMR0VvT6V/k//3vfzqfcPPmzdkOhnKp/v2BAgXkbMZbtwKBgXI24//WLiMiItKHTjU3bm5umpurqyv27duH06dPa/afOXMG+/btgxun1qfsatcudTbjw4eBBg2A+/eVjoqIiMyQTjU3y5Yt09wfM2YMOnbsiAULFsD6v5Wek5OT8cknn3CdJno7DRvKxOa994ALF+Rkf7t2AZxygIiI9JCtGYpHjhypSWwAwNraGsOHD8fSpUsNGhzlQpUry9mMS5YEbt0C6tcH0tQSEhERvYneyU1SUpJmZuK0rly5ArVabZCgKJcrXlzOZlytGvDoEdC4MbBnj9JRERGRmdB7zG2fPn3w0Ucf4fr166hZsyYA4MSJE5g5cyb69Olj8AAplypUSM5m3K6dnM24ZUtg5Uo56R8REVEW9E5uvv32W3h6euK7777DgwcPAACFCxfGqFGjMGLECIMHSLmYi4uczbhXL2D9ejmaKjISGDpU6ciIiMiE6ZXcJCUlYc2aNejVqxdGjx6N6OhoAGBHYjKelNmMCxWSk/4NGyYTnGnTOJsxERFlSK8+NzY2Nhg4cCBe/TfJmqurKxMbMj4rK2DOHDmLMQB8/bWcGycpSdm4iIjIJOndobhmzZpZri9FZBQqFfDFF6mzGS9ZAnToALx8qXRkRERkYvTuc/PJJ59gxIgRuHv3LqpVq4Y8efJo7a9UqZLBgiNKp39/ueBm585yFuPmzYFt2wB3d6UjIyIiE6ESQgh9nmBllb6yR6VSQQgBlUqF5ORkgwVnLNHR0XBzc8Pz58/ZrPYGsbGxAABnZ2eFI3nN4cNA69bA8+dAhQpysj8vL6WjMhkmW26UKZaZeWK55Sxdv7/1rrm5efPmWwVGZBANGqTOZnzxIlC3LrB7N2czJiIi/ZObYsWKGSMOIv1VqiQn+wsMBK5dk8s1bN8O1KihdGRERKQgvTsUA8Bvv/2GevXqwcvLC7dv3wYA/Pjjj/jjjz8MGhzRG6XMZly9OvD4sZzNePdupaMiIiIFvTG52bVrF54/f655PH/+fAwfPhzvv/8+oqKiNH1s8ubNix9//NFogRJlqmBBYP9+oFkz4MULOZvx2rVKR0VERAp5Y3ITERGBevXq4e7duwCAuXPnYvHixfjiiy+0Fs+sXr06Lly4YLxIibLi4gL89ZccRZWUBHTtKufGISKiXOeNfW569eoFZ2dnBAYG4tKlS7h58yb8/f3THWdvb48XL14YJUgindjZAatXy5qcuXOBzz4DHj6Uk/5xNmMiolxDpz437du3x7Zt2wAAxYsXR3BwcLpjdu7cCT8/P4MGR6S3lNmMp0+Xj2fMAPr142zGRES5iM6jpXx9fQEAw4cPx+DBg/Hq1SsIIXDy5EmsXbsWM2bMwK+//mq0QIl0plIB48bJ9ag+/hhYulR2Nl63DnB0VDo6IiIyMr2Hgvfr1w+Ojo6YMGEC4uLi0LVrV3h5eWHOnDno3LmzMWIkyp6PPgIKFJD9cLZt42zGRES5hN4zFKcVFxeH2NhYFCpUyJAxGR1nKNadRcy+eeQI0KpV6mzGO3cCRYooHZVRWUS55TIsM/PEcstZun5/Z2ueGwCIjIzEmTNnEBYWhkePHmX3NETG9+67MsEpXDh1NuMrV5SOioiIjETv5CYmJgY9evSAl5cXGjZsiIYNG8LLywvdu3fXmg+HyKRUrAj8/bdcnuHOHaB+feDkSaWjIiIiI9A7uenXrx9OnDiBoKAgREVFISoqCn/99RdOnz6NAQMGGCNGIsPw8QGOHpXLMzx5Imcz3rVL6aiIiMjA9O5zkydPHuzatQv169fX2n7kyBG89957ZjHXDfvc6M4i25NjY4H27eUyDTY2wPLlQLduSkdlUBZZbhaOZWaeWG45y2h9bvLnzw83N7d0293c3ODOUShkDpydgT//BLp0kfPfdO8OcOkQIiKLoXdyM2HCBAwfPhwRERGabRERERg1ahQmTpxo0OCIjMbODli1Chg2TD7+/HNg7Fgg+4MHiYjIROg9z838+fMRHh6OokWLomjRogCAO3fuwN7eHo8ePcLChQs1x549e9ZwkRIZmpUV8MMPgKennPRv1iwgMhJYtEg2VxERkVnS+y9427ZtjRAGkUJUKlljU6gQ0L8/sGwZcP060KcP0KIF4OGhdIRERKSnt5rEz1yxQ7HuclVnuW3bgE6dgFevUrfVqAG0bAl88AHg7y9re8xArio3C8EyM08st5xl9En8iCxO69ZAcDAwcSJQtarcduoUMGUKUL26nNX4o4+AzZuBmBglIyUioiyw5oY1N1nK1f+V3L8P7NgB/PUXsGcPkHaaA1tboGFDWavTsiVQqpRycWYgV5ebmWKZmSeWW87S9fubyQ2Tmyzxwv1PfDxw+DAQFCRv4eHa+0uVSm2+evddORpLQSw388MyM08st5zF5CYLTG50xws3E1evyhqdoCCZ9CQlpe5zcQGaNZPJzvvvy9FYOYzlZn5YZuaJ5ZazjJ7cJCQk4ObNm/D19YWNmQ2bZXKjO164OoiOls1WKbU6kZHa+6tXT22+qlYtRzols9zMD8vMPLHccpbROhTHxcXho48+gpOTE8qXL487d+4AAD799FPMnDkz+xETmStXV7mcw9KlwIMHckHOyZNlUgMAp08DU6cCNWsCXl5ymPnvv8ukiIiIDE7v5GbcuHE4f/48Dh48CAcHB832gIAArF+/3qDBEZkdKys5fHzKFDnS6sEDmfT8739y2YeHD+VaVh06AAUKAE2bAt9/L5u5iIjIIPRulipWrBjWr1+P2rVrw8XFBefPn0eJEiUQHh6OqlWrItoM/htls5TuWOVqQAkJwJEjqc1Xryc0JUumNl81aADY22f7pVhu5odlZp5YbjnLaM1Sjx49QqFChdJtf/HiBVQqlb6nI8o97OxSa2rCwmRy88MPQECAHFoeHg7MmQM0by5rddq1A379VQ5JJyIinemd3FSvXh1BQUGaxykJza+//oo6deoYLjIiS1eqFPDZZ7Iz8pMncnLAvn3l6KrYWGDrVrkkRJEisiPypEnAiROAWq105EREJk3v5Gb69OkYP348Bg0ahKSkJMyZMwfNmzfHsmXL8PXXX2criHnz5sHHxwcODg6oVasWTp48meXxP/74I8qUKQNHR0d4e3vj888/x6u0U+YTmRsXF1lTs2QJcO+edidklQo4exaYNg2oXRsoXBjo3RvYuBF4/lzpyImITI7eyU39+vURHByMpKQkVKxYEbt370ahQoVw/PhxVKtWTe8A1q9fj+HDh2Py5Mk4e/YsKleujMDAQES+Ppz2P2vWrMHYsWMxefJkhIaGYsmSJVi/fj3Gjx+v92sTmSQrK+2amgcP5IKeHTrIkVmRkcCKFUDHjrL5qnFj4NtvgStXgNw3bRURUTqKT+JXq1Yt1KhRAz///DMAQK1Ww9vbG59++inGjh2b7vghQ4YgNDQU+/bt02wbMWIETpw4gaNHj+r0muxQrDt2ljMxiYnA0aOpnZKvXNHeX6IE0LIlXjZpguT69eFcoIAycZLeeK2ZJ5ZbztL1+1un2ff0GQGlT7KQkJCAM2fOYNy4cZptVlZWCAgIwPHjxzN8Tt26dbFq1SqcPHkSNWvWxI0bN7B9+3b06NEj09eJj49HfHy85nHK+4mNjYWVmazyrJS4uDilQ6DX1aihGW6uunEDNrt2wXrXLlgfOQLVjRvA3LlwnDsXwtERSU2aICkwEMmBgRBeXkpHTlngtWaeWG45KyWZfBOdkpu8efPqPBIqOTlZp+MA4PHjx0hOToaHh4fWdg8PD1x5/T/S/3Tt2hWPHz9G/fr1IYRAUlISBg4cmGWz1IwZMzB16lSd4yIyF6JECSQOGoTEQYOA2FhYHzwIm507YbVrF6wjImATFASb/wYAJFeqhOTAQCS99x7UNWrIvjxERBZIp+TmwIEDmvu3bt3C2LFj0bt3b83oqOPHj2PFihWYMWOGcaJM4+DBg5g+fTp++eUX1KpVC+Hh4Rg2bBimTZuGiRMnZviccePGYfjw4ZrH0dHR8Pb2hrOzM6sSdcTPyQw4OwOdOwOdOyM2JgZWISFwOnBANl+dOAHrkBBYh4TAbvZsoHRp4OOPgV69ZL8dMhm81swTyy1nqHUcLap3n5umTZuiX79+6NKli9b2NWvWYNGiRTh48KDO50pISICTkxM2bdqEtm3barb36tULUVFR+OOPP9I9591330Xt2rUxe/ZszbZVq1bh448/1rmZiX1udMf2ZPOUrtwePQJ27Ejtq/PihdxuZydnT/74Y6BRI9bmKIjXmnliueUso03id/z4cVRPWTMnjerVq79xCPfr7OzsUK1aNa3OwWq1Gvv27ct0zpy4uLh0CYy1tTUAIBcucE6km4IFgZ49gfXr5eirRYvk2lcJCcC6dUCTJkCZMsDs2ekX/iQiMjN6Jzfe3t5YvHhxuu2//vorvL299Q5g+PDhWLx4MVasWIHQ0FAMGjQIL168QJ8+fQAAPXv21Opw3KpVK8yfPx/r1q3DzZs3sWfPHkycOBGtWrXSJDlElAUXFzk54KlTwJkzwMCBctu1a8Do0cA77wCdOgH79nHCQCIySzr1uUnrhx9+QPv27bFjxw7UqlULAHDy5Elcu3YNv//+u94BdOrUCY8ePcKkSZMQERGBKlWqYOfOnZpOxnfu3NGqqZkwYQJUKhUmTJiAe/fuoWDBgmjVqlW2JxAkytWqVgXmz5c1NuvXyxqdkyeBDRvkzddXJkK9ewOvdfwnIjJV2Zrn5u7du5g/fz5CQ0MBAH5+fhg4cGC2am6UwD43umN7snl6q3ILDgYWLwZWrQJSpoGwsQHatpV9c5o2lRMNkkHxWjNPLLecpev3t+KT+CmByY3ueOGaJ4OU24sXsvZm0SLgn39StxcvLmtz+vSR62CRQfBaM08st5xltA7FRJRL5MkjE5jjx4Hz54EhQwA3N+DmTWD8eMDbG2jfHti1i31ziMikMLkhojerVAmYOxe4fx9YvhyoWxdISpIrmb/3nlz24auv5H4iIoUxuSEi3Tk5yYn/jh0DLlwAhg4F8uYFbt8GJk4EihaVfXO2bwf0mK2ciMiQmNwQUfZUqADMmSNra1auBOrXlwnNH38ALVvK2pwvvwTu3lU6UiLKZZjcENHbcXQEevQAjhwBLl0CPvsMcHcH7twBJk8GihUDWrcG/vqLtTlElCP0Tm4ePnyIHj16wMvLCzY2NrC2tta6EVEuVq4c8MMPsjZn1SqgQQPZ2fjPP4FWrQAfH2DKFODff5WOlIgsmN5DwVu0aIE7d+5gyJAhKFy4cLrVwtu0aWPQAI2BQ8F1x2GO5smkyu3KFeDXX2VH5CdP5DYrK6BFCzlvzvvvy3l0cjmTKjPSGcstZxltnhsXFxccOXIEVapUedsYFcPkRne8cM2TSZZbfDywZQuwcCGQdoFdLy/go4/krVgxxcJTms5lFhUlFzh1czN+UPRGJnmtWTCjzXPj7e3NBSqJSH/29kDnzsCBA0BYGDBqFFCggGzCmjZNTg74/vvA1q1AYqLS0SonIUGu87V7N7BggVzv68MPgWrVgHz5ZH+mfPmAZs2ApUuBZ8+UjpjI5Ohdc7N792589913WLhwIXx8fIwUlnGx5kZ3/K/EPJlNucXHy9FVixbJhTpTFC4M9O0L9Osn++lYEiGAiAg5GeKNG5qfyeHhUN26Bat79+QxurK1lXMNde4sO26beplbGLO51iyE0Zql3N3dERcXh6SkJDg5OcHW1lZr/9OnT7MXcQ5icqM7XrjmySzLLTxc9s1ZtgyIjJTbVCqgeXPZN6dVK/lFbg5iYmTS8loCo9n28mXWz3dykjVZJUqk/+njAzx8KBc6XbdOzjeUwtFRfk6dO8s+TQ4ORn2bZKbXmhkzWnKzYsWKLPf36tVLn9MpgsmN7njhmiezLreEBGDbNlmbs2dP6nYPj9TanBIllIsPkLMz//uvduKS9v7jx1k/38pKLl+RJnF55eUFdbFicKpQAShUSCZ2urh0SSY6a9fKBDGFiwvQrp1MdAICzCcxNDNmfa2ZIS6cmQUmN7rjhWueLKbcrl8HliyRfUsePkzd3qyZrM1p3RqwszP86wohE5SMEpebN+UcPm+asydfvoxrXkqUkInNa3G/dZkJAZw9K2tz1q/XHm6fP79cB6xLF+DddwFO22EwFnOtmQmjJjfJycnYunUrQkNDAQDly5dH69atzWaeGyY3uuOFa54srtwSE+VcOYsWyY62KX+2ChWSi3v26weULKnfOePigFu30icuKT//+wwzZW8vm4hSEpa0SUzx4nqPZjJomanVcsHTdevkyu4pzXyA7M/UsaOs0alVS/caIsqQxV1rJs5gyc3Tp0+RL18+zePw8HC8//77uHfvHsqUKQMACAsLg7e3N4KCguDr62ugt2A8TG50xwvXPFl0ud28KWtzliyRHXNTNG0qa3PatpW1IsnJwL17GScuN25oPzczRYpo17ikTWAKF5bNSwZitDJLSgIOHZLNVr//LoeSp/DxkUlO585ycVQmOnqz6GvNBBksufnyyy8BAJMmTQIAvP/++xBCYPXq1Zqk58mTJ+jevTusrKwQFBRkqPdgNExudMcL1zzlinJLTASCgmRtzs6dqbU5BQqkLub5piHlrq4ZJy4lSsg5d3KwQ26OlFlCgqz5WrdODrl/8SJ1X9myqYnOf/+40pvlimvNhBgsuXny5IlmuYVff/0VefLkwT///IOKFStqHXf+/HnUq1dPU9CmjMmN7njhmqdcV263b6fW5ty/n7rdxkbWTmQ28sjd3WRqK3K8zOLiZHK4bp38GR+fuq9KFdk/p1OnXD2xoi5y3bWmMF2/v98453n+/Pmxfft2TJ8+HQBgb2+PmJiYdMfFxsbCzhgd+4iI3qRYMbkC+aRJcgFPlUomL0WKsPNsZpyc5OSAH34IREfL+YbWrZM1O8HB8jZmDFCnjqzN+fBD2RRHZAb07lDcs2dPnD17FkuWLEHNmjUBACdOnED//v1RrVo1LF++3BhxGhRrbnTH/0rME8vN/JhMmT15AmzeLBOdAwdSm/tUKqBRI5notG8vR2CR6ZRbLmG05Rd++ukn+Pr6ok6dOnBwcICDgwPq1auHkiVLYs6cOW8VNBERKSx/fqB/fzlj9L17wJw5svZGCJnsDBgAeHoCLVsCv/0ma32ITEy257m5du0arly5AgDw8/NDSX2HYSqINTe6438l5onlZn5Mvsxu3ZLDyteulU1WKeztZaLTpYtcG8zJSakIFWHy5WZhOIlfFpjc6I4XrnliuZkfsyqzK1dSZ0UOC0vd7uwMtGkjm66aNzfOBIsmxqzKzQIYNLkZPnw4pk2bhjx58mD48OFZHvv999/rH20OY3KjO1645onlZn7MssyEAEJCZP+cdetk7U4Kd3fgf/+TNTqNGllsx26zLDczZrDRUgBw7tw5JP43X8S5c+cyPU5lIkMqiYgoB6hUQOXK8jZ9OnDiROqsyA8epA7P9/CQo606d5b9dww4+SFRRtgsxZqbLPG/EvPEcjM/FlVmyclySP66dcCmTXIEVgpvbzl/TufOQNWqJjPPUHZZVLmZAaONlnr+/DmePn2abvvTp08RzV7zRERkbS2bohYskDU4O3YAPXvKlcr//Rf49lugenU5E/KkScDly0pHTBZG7+Smc+fOWLduXbrtGzZsQOfOnQ0SFBERWQhbW+C994AVK+QCnps3y4U7HR2Ba9eAadOA8uXl2lbTp8uV4Inekt7NUvny5cOxY8fg5+entf3KlSuoV68enqStfjRRbJbSHatczRPLzfzkujKLjQW2bZNNVzt3aq8DVrWqnHXa2Vm3m4uL9mNb2xx8G7ms3BRm0A7FacXHxyMpKSnd9sTERLx8+VLf0xERUW7k7Ax07Spvz54BW7bIRGffPuDsWXnLLjs73RMjXW8ODmbfPyg30Tu5qVmzJhYtWoS5c+dqbV+wYAGqVatmsMCIiCiXcHcH+vaVt4cP5UzIUVGydkfXW0yMXPUckD+fPpU3Q7G2zjDpcXBwgHB2livR65MsubvLCRDJKPRObr766isEBATg/PnzaNq0KQBg3759OHXqFHbv3m3wAImIKBfx8JAjqbIjIQF48UK/pOhNt7g4ee7kZOD5c3lLQ+8v0bTc3ICCBYFChbRvGW3Ln99i5woyBr3LpV69ejh+/Dhmz56NDRs2wNHREZUqVcKSJUtQqlQpY8RIJiIuDvjpJ6BJE+C/NVOJiEyHnZ28ubsb7pzJyfKPXybJz6vHj6GKjYV9YqJ+SZMQqclSePib41CpZILzetKTWTLk5parm9E4zw07FGcpbWe5UaPkCE4HB+CPP+Ts6mSa2MnR/LDMzFO2yk0I2ewWGSlvjx6l3k97S9n+5Enq6uy6srXVvVaoYEEgTx79zq8Qo3UoBgC1Wo3w8HBERkZCrVZr7WvQoEF2Tkkm7s4dIKWb1atXQOvWMsEJDFQ2LiIis6NSydold3c518+bJCXJBEfXZCg6Wo4+u39f3nTh5KR7IlSwoMmvG6Z3cvPPP/+ga9euuH37Nl6v9FGpVEhOTjZYcGQ6Jk0C4uOBBg2AfPmArVvl+nhbtgAtWigdHRGRBbOxkX2RPDx0O/7VK+0EKKtk6OFD+cc9Lk6uDZZ2fbCs5M375kSoUiX5haEAvZulqlSpgtKlS2Pq1KkoXLhwuvWk3NzcDBqgMbBZSnexsbG4eNEKdes6QQi5dEyVKrK/35YtMnnfsgV4/32lI6W02MRhflhm5snsy00I2QcooxqgjG6PH8t+SLrYtg1o1cqg4RqtWeratWvYtGkTSpYs+VYBkvmYPNkOQsh171I6Eq9fLxf7/f13oF07Oeloy5bKxklERHpSqeQkiC4ugK/vm49Xq+W8RJk1iaW9eXkZP/5M6J3c1KpVC+Hh4UxuconDh62xe7cNbGyAr79O3W5rC6xdK+ff2rRJJji//27wJJ2IiEyJlZUctZU/P/DaSgWmRO/k5tNPP8WIESMQERGBihUrwva1aa4rVapksOBIWUIAEyfKTmMffwy8PtLf1hZYs0Ym/hs3Au3by0SndWsFgiUiIvqP3n1urKzSr7WpUqkghDCbDsXsc6ObDRuATp0AZ2eB8HBVpn3ZkpKA7t1lU5WtrXxe27Y5Giq9xuz7AeRCLDPzxHLLWUbrc3Pz5s23CozMQ0ICMH68vD90aAI8PDKfJtzGBli1StbgrFsn++Zs2CCbqoiIiHKa3slNsWLFjBEHmZhFi4Dr14GCBdX49NNEAFmvgWJjA/z2m2yOXbMG6NhRJjrt2+dMvERERCn0Tm5WrlyZ5f6ePXtmOxgyDdHRwJdfyvvjxiVA19pWGxtg5UqZ4KxaJZu01q0DOnQwXqxERESv0zu5GTZsmNbjxMRExMXFwc7ODk5OTkxuLMB338lRfaVKAb17J+n1XGtrYPly2UT1229yPpy1a2VTFRERUU5I3zv4DZ49e6Z1i42NRVhYGOrXr4+1a9caI0bKQRERMrkBgOnTZQdhfVlbA8uWAb16ybmeunSRnY2JiIhygt7JTUZKlSqFmTNnpqvVIfMzdSrw4gVQq9bb9ZextgaWLAF695YJTteusgaHiIjI2AyS3ACAjY0N7uu6QBeZpLAwYPFief+bb2TT0ttISXD69pWTWnbvLjsbExERGZPefW62bdum9VgIgQcPHuDnn39GvXr1DBYY5bzx42UtywcfyAUyDcHKSiZMVlbAr78CPXrIyQG7dTPM+YmIiF6nd3LT9rXZ2VQqFQoWLIgmTZrgu5TOGmR2jh+X60NZWQEzZhj23FZWwMKFsiZo8WKgZ09Zk9Ojh2Ffh4iICNAxuYmOjtbMBKhWq40aEOU8IYAxY+T9Xr2AChUM/xpWVsCCBamJTq9eMsHp1cvwr0VERLmbTn1u3N3dERkZCQBo0qQJoqKijBkT5bC//gKOHAEcHFLntzEGKyvgl1+AQYNkQtWnjxw2TkREZEg6JTfOzs548uQJAODgwYNITEw0alCUc5KSgLFj5f1hw4B33jHu61lZAfPmAZ98IhOcvn2BpUuN+5pERJS76NQsFRAQgMaNG8Pvv+XN27VrBzs7uwyP3b9/v+GiI6NbsQK4fBnIly81yTE2lQr4+WeZ6Pz8M/DRRzLR+eijnHl9IiKybDolN6tWrcKKFStw/fp1HDp0COXLl4eTk5OxYyMji4sDJk2S97/4AsibN+deW6UCfvpJJjg//QT06yf74PTvn3MxEBGRZdIpuXF0dMTAgQMBAKdPn8asWbOQNye/CckofvoJuH8fKFpUNhPlNJUK+PFH+XPOHODjj2UNzscf53wsRERkOfSexO/AgQMGT2zmzZsHHx8fODg4oFatWjh58mSWx0dFRWHw4MEoXLgw7O3tUbp0aWzfvt2gMVm6J0+AmTPl/a++kp2JlaBSAT/8AHz+uXw8YIAcVUVERJRdOiU3M2fORFxcnE4nPHHiBIKCgnQOYP369Rg+fDgmT56Ms2fPonLlyggMDNSMznpdQkICmjVrhlu3bmHTpk0ICwvD4sWLUaRIEZ1fk4CvvwaePwcqV1Z+Qj2VSq5nNWKEfDxokBxVRURElB06NUtdvnwZxYoVw4cffohWrVqhevXqKFiwIAAgKSkJly9fxtGjR7Fq1Srcv38fK1eu1DmA77//Hv3790efPn0AAAsWLEBQUBCWLl2KsRn0cF26dCmePn2Kv//+G7b/rero4+Oj8+sRcOuWHLEEALNmyX4vSlOpgNmz5c9vvwUGD5Z9cIYMUToyIiIyNzp9ra1cuRJ79+5FYmIiunbtCk9PT9jZ2cHFxQX29vbw9/fH0qVL0bNnT1y5cgUNdJy7PyEhAWfOnEFAQEBqQFZWCAgIwPHjxzN8zrZt21CnTh0MHjwYHh4eqFChAqZPn47k5GSdXpOACROAhASgaVOgeXOlo0mlUsk1rUaPlo8//RSYO1fZmIiIyPzovPxC5cqVsXjxYixcuBAhISG4ffs2Xr58iQIFCqBKlSooUKCA3i/++PFjJCcnw8PDQ2u7h4cHrly5kuFzbty4gf3796Nbt27Yvn07wsPD8cknnyAxMRGTJ0/O8Dnx8fGIj4/XPI6OjgYAxMbGwsoUqi1y0PnzVli9Wo50mzw5Di9eZD3jtK7NkYY0YQKQlGSH77+3w9ChwMuX8fjkE86tpA8lyo3eDsvMPLHcclZsbKxOx+m9tpSVlRWqVKmCKlWq6PtUg1Cr1ShUqBAWLVoEa2trVKtWDffu3cPs2bMzTW5mzJiBqVOn5nCkpmnyZDk/UYcOifD3N82lNFQqYMqUBFhZAd9+a4cxY+z/a6JigkNERG+md3JjSAUKFIC1tTUePnyotf3hw4fw9PTM8DmFCxeGra0trK2tNdv8/PwQERGBhISEDCcXHDduHIYPH655HB0dDW9vbzg7O8PZ2dlA78b07d0L7NsH2NoCs2bZwtnZVufnKvE5ffONHMX11VfAuHH2sLOzR5piJB3kpt9vS8EyM08st5yh6/qWirbJ2NnZoVq1ati3b59mm1qtxr59+1CnTp0Mn1OvXj2Eh4drvcGrV6+icOHCmc6abG9vD1dXV61bbqNWp/ZlGTQIKFFC2Xh0oVLJta5SJhocMUJ2NiYiIsqK4h1Ohg8fjsWLF2PFihUIDQ3FoEGD8OLFC83oqZ49e2LcuHGa4wcNGoSnT59i2LBhuHr1KoKCgjB9+nQMHjxYqbdgFtatA86dA1xcZJ8Wc6FSAVOnAiktjqNGyRodIiKizCjaLAUAnTp1wqNHjzBp0iRERESgSpUq2Llzp6aT8Z07d7Q6/Xp7e2PXrl34/PPPUalSJRQpUgTDhg3DmDFjlHoLJi8+Xi6vAABjxgD/jeI3K1OmpPTFke9Brc65tbCIiMi8qIQQQteDExMT4ejoiODgYFSoUMGYcRlVdHQ03Nzc8Pz581zRRDVnDvDZZ0DhwsC1a0CePLo/N6Vnuqm0J0+bltpMNX06kKZSj9IwtXKjN2OZmSeWW87S9ftbr2YpW1tbFC1alHPKmJHnz2VCAMhaD30SG1M0caLsYAwA48fLmZaJiIjS0rvPzRdffIHx48fj6dOnxoiHDOybb+Q6UmXLAn37Kh2NYXzxhay1AWT/oZTkjYiICMhGn5uff/4Z4eHh8PLyQrFixZDntaqAs2fPGiw4ejv37slFKQFgxgzARvEeVoYzbpxcNmLsWNlMpVandjomIqLcTe+vu7Zt2xohDDKGKVOAly+BunWBNm2UjsbwxoyRCc7o0fK9CiF/EhFR7qZ3cpPZLMBkWkJDgaVL5f1vvpEjjSzRqFHyvY0aJYeMpyQ4lvp+iYjozbLdUHHmzBmEhoYCAMqXLw9/f3+DBUVvb9w42VTTpg1Qr57S0RjXyJGyBmfECDnpn1otfzLBISLKnfRObiIjI9G5c2ccPHgQefPmBQBERUWhcePGWLduHQqa4yQqFubYMeCPP+QX/owZSkeTM4YPl+/388/laCq1Wv5kgkNElPvoPVrq008/RUxMDC5duoSnT5/i6dOnuHjxIqKjozF06FBjxEh6EEI20QDARx8Bfn7KxpOTPvtMzukDyNFU48fLz4OIiHIXvWtudu7cib1798IvzbdmuXLlMG/ePDRv3tygwZH+tm4Fjh8HHB1zZ+faoUNlDc6nnwIzZ8oanJkzWYNDRJSb6F1zo1arYWubfjVpW1tbnVfrJONISkqdsXf4cMDLS9l4lDJkCPDzz/L+N9/I0VSswSEiyj30Tm6aNGmCYcOG4f79+5pt9+7dw+eff46mTZsaNDjSz9KlQFgYkD9/atNUbjV4MDBvnrz/7bfy82CCQ0SUO+id3Pz888+Ijo6Gj48PfH194evri+LFiyM6Ohpz5841RoykgxcvUiexmzgRcHNTNh5T8MknwPz58v5338nRVExwiIgsn959bry9vXH27Fns3bsXV65cAQD4+fkhICDA4MGR7n74AYiIAIoXBwYOVDoa0zFwoOyDM2CA/IzUavmTfXCIiCyXXslN2lXBmzVrhmbNmhkrLtLDo0eybwkgF5K0t1c2HlPz8ccywenfX46mUqvlTyY4RESWiauCW4Bp04CYGKBaNaBTJ6WjMU39+gFLlsiEZu5cOZqKTVRERJaJq4KbuevXgQUL5P1Zs2QNBWWsb9/UBGfePDmqigkOEZHl4argZm7CBCAxEWjeHOBgtTfr00cmN337Ar/8IpObn39mUkhEZEm4KrgZO30aWLdOflnPmqV0NOajd2+ZzPTuLUdTqdUy0WGCQ0RkGfRKbpKSkqBSqdC3b1+88847xoqJdCAEMGaMvN+tG1CliqLhmJ2ePWUy06sXsHChTHAWLGCCQ0RkCfT6U25jY4PZs2cjKSnJWPGQjnbtAvbvB+zsZIdi0l/37sDKlTKhWbxYjqriJNtEROYvWzMUHzp0yBixkI6Sk1NrbYYMAXx8FA3HrHXrBqxaJROcJUvkqComOERE5k3vPjctWrTA2LFjceHCBVSrVi1dh+LWrVsbLDjK2Jo1QEiInIV4/HilozF/XbrIfkvdugHLlgGvXsmJ/jw8lI6MiIiyQyWEfoNhrbLolKBSqcxiDpzo6Gi4ubnh+fPncHV1VTocvbx6BZQpA9y5A8yYAYwda9zXi42NBQA4Ozsb94VMwPr1MsFJTparqn/yiVyTyhyTnNxUbpaCZWaeWG45S9fv72ytCp7ZzRwSG3M3b55MbIoUAYYNUzoay9KpE7B3L1CrFvDypVyPqnhxYORI4OFDpaMjIiJdcWyIGXn2TC6vAABffilrF8iwGjUCjh8HduxIn+SMGgVERiodIRERvYnOyc3777+P58+fax7PnDkTUVFRmsdPnjxBuXLlDBocaZs5UyY45cvLIcxkHCoV8N57qUlOzZoyyfn2W9l5m0kOEZFp0zm52bVrF+Lj4zWPp0+frrUEQ1JSEsLCwgwbHWn8+69c7BGQSY61tbLx5AYpSc4//wDbtzPJISIyFzonN6/3O9azHzK9pcmTgfh44N13gZYtlY4md1GpgBYtMk5y2FxFRGR62OfGDFy8CKxYIe9/8438sqWcl1GSExfHJIeIyNTonNyoVCqoXvtWff0xGcfYsXJiufbtgdq1lY6G3pTkjB7NJIeISEk6T+InhEDv3r1hb28PAHj16hUGDhyomcQvbX8cMpxDh4CgINnHZvp0paOhtFKSnPfeA3buBKZMAU6eBGbPlkP2Bw+Ww8gLFVI6UiKi3EXnmptevXqhUKFCcHNzg5ubG7p37w4vLy/N40KFCqFnz57GjDXXEULWAgBy3aPSpZWNhzL2ek1OjRqyJmf2bNbkEBEpQe8Zii2BucxQvGkT8OGHQJ48QHg44OmZ8zFw9k39CSGHkE+ZApw6Jbc5OeVsTQ7LzfywzMwTyy1nGW2GYsoZiYmp60aNGKFMYkPZo1IB778PnDghmxRZk0NElLOY3JioxYuBa9fkf/kjRyodDWXHm5KcMWOAR4+UjpKIyPIwuTFBMTHA1Kny/qRJgIuLsvHQ28ksyfnmGzkZIJMcIiLDYnJjgr77TjZblCwpOxKTZXg9yalenUkOEZExMLkxMQ8fyvlSADn029ZW2XjI8FKSnJMngb/+YpJDRGRoTG5MzJdfAi9eyKaLDh2UjoaMSaWSS2lklOQULy4nb2SSQ0SkPyY3JuTaNWDRInmfyyzkHhklOS9eALNmMcmh3CMpCdi1C+jRA/D1Bbp1k823iYlKR0bmiMmNCRk/Xl7g778PNGqkdDSU05jkUG4jBHD6NPDZZ8A778jZvletAm7cANasAT74QE6DMXAgcPiwXIaGSBecxM9EJvE7cUKuG6VSAefPAxUrKh2RxAmqlCOEnPF4yhT5BQDICR2HDJFzHxUsmPlzWW7mJzeVWUrysmoVEBaWuj1/fqBzZ6BZM2D/fmD9etkPMcU77wBdushblSqmUbudm8rNFOj6/c3kxgSSGyFkTc3hw0Dv3sCyZUpHlIoXrvKEkNXzU6YAZ87IbSlJzsiRQIEC6Z/DcjM/ll5mT54AGzbIhObvv1O3OzgAbdvKZqjAQO1BFElJwMGDMhH6/XcgOjp1X9myQNeuMtEpWTKn3kV6ll5upobJTRZMLbkJCpLVr/b2st+Nt7fSEaXihWs6MktyPv1U1uSkTXJYbubHEsvs5Uvgzz9lQrNjh0xWAMDKCmjaVCY07doBuvwZfvVK1mSuXSvPmXat5ho1ZKLTqRNQuLBx3ktmLLHcTBmTmyyYUnKTnCyrVy9eBEaNkh2JTQkvXNOjS5LDcjM/llJmycmytmX1ark+XkxM6j5/f6B7d9n05OWV/dd4/hzYulXW6Ozdm9oXx8oKaNxY1ub873+Au/vbvBPdWEq5mQsmN1kwpeRm2TKgb195EV6/njMXoz544ZqurJKcAQNiUaAAy82cmPO1JoTsK7h6tUw47t9P3VesmKyh6dYNKFfO8K/98CGwcaN83ePHU7fb2cnBGV27yppxR0fDvzZg3uVmjpjcZMFUkpuXL4HSpYG7d+V6Q6a4hhQvXNOXcZIjMGBAIsaNs8uwTw6ZHnO81u7cSe0YfOlS6nZ3d+DDD2UtTb16skYlJ9y4AaxbJ2NKG4+zs2z+6tpVNocZcnJUcyw3c8bkJgumktzMmiWH9xYtKkcMODgoFkqmeOGaDyHkEPIpU4CzZ+W2zPrkmDIhZP+KuDh5e/ky9X5Wt5TjXr6U11TNmrIvRv78Sr8j3ZjLtfbsmWxuWr0aOHQodbu9vawh6d4daNFCPlbShQsyyVm7Frh9O3V7wYIy8eraFahT5+0TL3MpN0vB5CYLppDcPH0KlCgh245XrAB69lQkjDfihWt+hAA2bnyJGTPsEBxsDUD+5/rpp8Dw4dlPcoSQnTj1TTayc4wh+frKRCfl5u9vvCaKt2HK11p8vOzMu2qVTKATElL3NWokE5r27YG8eZWKMHNCyOaqNWvkaK20c0UVKyb753Ttmv3pN0y53CwRk5ssmEJyM3KkXCCzYkXg3DnA2lqRMN6IF655io2NhRDAwYPOWjU5zs5Av35AvnzZS0hy+q+FrS3g5JTxzdEx4+12dsDVq3LuqGvX0p/TxkZed2kTHj8/5a9BU7vW1Grg6FGZ0GzcCERFpe6rUEEmNF26yFoyc5GYCOzbJ2tzNm8G/vvIAQDly6cOLS9eXPdzmlq5WTomN1lQOrm5fVv2tUlIkP8NtWiR4yHojBeueUpbbhk1V72tlKQjswTjTQmIrs+1sXm7OJ8+lRMgnjyZeks7KVyKPHnkjNBpEx5v75ydJM5UrrVLl2RCs2aN7FOTokgR+eXfvTtQqZJy8RnKy5fyulizRv4dTlsbVaeOTHI6dgQ8PLI+j6mUW27B5CYLSic3PXsCv/0mhyzu22cas2xmhheuecqo3ISQ84Ns2yaThuwmII6O5rtavRDAv/9qJzunT8tlLl7n4aGd7NSoYdzRjEpea/fvy9qMVauA4ODU7a6ucgHfbt2Ahg2Vr90ylqgoWZOzZo2cGTnlW9HKCggIkEldZvPx8G9kzmJykwUlk5vz52WbvxDAqVPyv0VTxgvXPLHcdJecDISGaic8ISFy++tKldJOeKpUMdxAgJwus+ho+YW+apX2F7qtrRxC3a2bcYdQm6oHD2TfnDVr5O9CipQO0127ys8npdx5reUsJjdZUDK5adEC2LlTzqS5bl2OvnS28MI1Tyy3t/PypewLlzbhuX49/XG2trKJpmZNoFYt+bNMmeyNwMmJMktIkCtvr1ola/BevUrdV6+ebHL68EPzGWFmbOHhskZrzRrgypXU7a6usgN1ly5AjRqxsLHhtZZTmNxkQankZv9+OceCjY28UHx9c+yls41fkuaJ5WZ4T57I2ta0CU9Gq7S7uMgmrLQ1PEWKvPn8xiqzlNFCq1fLhSifPEndV6YM0KOHrI3QpxNtbpMySWHK0PK7d1P3FSqkRvv2SejVyw41a5p2NwNLwOQmC0okN2q1/CN35oxc8HDu3Bx52bfGL0nzxHIzPiHk4IC0yc6ZMxkPZffy0k52qlcH3Ny0jzF0mYWFyYRm9Wo5uV0KDw9Z49C9O1C1Kr+M9ZUyimztWtl89fRp6r4SJVKHlhtjNmZicpMlJZKbdevkL72zs6zeLlQoR172rfFL0jyx3JSRlARcvqyd8Fy4kLr2UVply2onPCVKxMLe/u3K7OFD+bdm1SrZUTpFnjxyraXu3YEmTd5+FBpJCQnAtm0vsXGjDf76y1Yrsa1cWSY5nTub13B5U2dWyc28efMwe/ZsREREoHLlypg7dy5q1qz5xuetW7cOXbp0QZs2bbB161adXy+nk5uEBDmPxo0bwJdfAhMnGv0lDYZfkuaJ5WY6XrxI33/n5s30x9nZCVSqpEbt2taahKdUqTf334mNlYtIrl4N7NmT2hHa2hoIDJQJTevWMsEhw0u51lQqZ/z5p2y62rlTzqmTon59meh8+KH5zBRuqswmuVm/fj169uyJBQsWoFatWvjxxx+xceNGhIWFoVAW1Ru3bt1C/fr1UaJECeTLl8+kk5u5c4GhQwFPT9lBzZz+yPBL0jyx3Ezbo0fp+++k7QuTws0tff+dwoVlDdHevbKGZssW7aawWrXkSKdOncynhticZXStPX0K/P67THQOHUodiWZjAzRrJhOdtm1lTT7px2ySm1q1aqFGjRr4+eefAQBqtRre3t749NNPMXbs2Ayfk5ycjAYNGqBv3744cuQIoqKiTDa5iY6WHYcfPwYWLAAGDDDqyxkcvyTNE8vNvAgBXLz4AmfOWCMkxEHTfyftaKYU77wja4MjI1O3+frKGppu3WRtD+WcN11rd+/Kjtxr16YubAvIjufduwODBmV/6YfcyCySm4SEBDg5OWHTpk1o27atZnuvXr0QFRWFP/74I8PnTZ48GSEhIdiyZQt69+79xuQmPj4e8fHxmsfR0dHw9vbGvXv3jJ7cTJtmh2++sUPJkmqcPBlndpOfxf33L6GTk5PCkZA+WG7m5/UyS0wEQkOtcPq0FU6ftsaZM1YIDbWCELIHcP78Ah06JKJjxyTUqKFmx2CF6HOtXb2qwqZNttiwwQbXr6e2N9aunYyPPkpE27ZJJrmAsimJjo5GkSJF3pjcKNqt7PHjx0hOTobHa/Nbe3h44EraSQXSOHr0KJYsWYLgtNNovsGMGTMwderUtwk1WyIiVPj5Z5nNTJkSb3aJDREpR86ho0alSmr07ZsEAIiJAc6ft0JSkgr16iXzb4qZKV1aYPz4BIwbl4BDh6yxZIkt/vrLGv/8I29jxgj06JGIvn0TUaKE4t1hzZpZ9ZmPiYlBjx49sHjxYhTQo1fWuHHjMHz4cM3jlJobZ2dno1bbz54t28Lr1AG6dnU06/+s2Lxhnlhu5ierMnN2ln1uyPToe6198IG8PXgA/PorsGgRcPeuCnPm2GHOHDs0by6brD74gKPb0lJnNPQwA4p+ZAUKFIC1tTUevraS3cOHD+Hp6Znu+OvXr+PWrVto1aqVZlvKG7WxsUFYWBh8M5gZz97eHvb29gaOPmtXrgBLlsj733zDuSSIiCi9woXlCNpx4+QCnvPny1mkd++WtyJFgP79gX79dJsMkqRsTBJuOHZ2dqhWrRr27dun2aZWq7Fv3z7UqVMn3fFly5bFhQsXEBwcrLm1bt0ajRs3RnBwMLy9vXMy/CyNHy+HZLZuLYcBEhERZcbGRn5f7NghR9WOGSOHjd+7B0yZAhQrJpd82LMn43mTSJuiyQ0ADB8+HIsXL8aKFSsQGhqKQYMG4cWLF+jTpw8AoGfPnhg3bhwAwMHBARUqVNC65c2bFy4uLqhQoQLs7OyUfCsaf/8th2daWQEzZigdDRERmZMSJYCZM+VIqzVrgHfflf8sb94MNG8ul8347ruMpw8gSfHkplOnTvj2228xadIkVKlSBcHBwdi5c6emk/GdO3fw4MEDhaPUnRDA6NHyfp8+nIKbiIiyx95ezmx/+LCc6XrIELloZ3g4MHKkbKbq2VP+Q638dLymRfF5bpRgzHlu/vhDTs7k6Ahcu2b+baScL8U8sdzMD8vMPOV0ucXGyjlz5s+XM1+nqFRJdkDu1k3OoWOpdP3+VrzmxpIkJQEp8w5+9pn5JzZERGRanJ1lB+MzZ4ATJ4DevQEHByAkRCY3Xl7yZ0iI0pEqi8mNAS1fLkdJ5c8vO4MREREZg0oll+NYtkx2Ov7hB9kXJzZWzoZfuTJQty7w228Zz3Rt6ZjcGEhyMvD11/L+hAlyTRgiIiJjy5dPthaEhgL79skFOm1sgOPHZZ+cd94BRo2SfXVyCyY3BmJtLReyGzJEVgkSERHlJJUKaNIE2LABuHMHmDYN8PaWo6q+/VauO9a8uRzNm5SkdLTGxeTGgHx95QrgOTxfIBERkZbChWUrws2bwLZtQIsWMvnZswf43//kvDlTpsgmLUvE5IaIiMhCWVsDrVrJ2Y+vX5eDXgoWBO7fB6ZOlUlOu3ZyNmRLmhyQyQ0REVEuULy4nFj233/lcPIGDWR/0a1bgcBAoHRpuSbi48dKR/r2mNwQERHlIvb2QOfOwKFDwMWLwKefyskBr1+Xk9AWKQJ07w4cO2a+kwMyuSEiIsqlypcHfvpJNlMtXgxUrQokJACrV8t1EStXBn75BYiOVjpS/TC5ISIiyuXy5JErj585A5w8KZcPcnSUyz4MHixrcwYOBM6fVzpS3TC5ISIiIo0aNYClS+VIqh9/BMqWlZMDLlwIVKkC1KkDrFwJvHypdKSZY3JDRERE6bi7A8OGAZcvAwcOAB07yskB//kH6NVLTg44YoRcR9HUMLkhIiKiTKlUQKNGwPr1cqTVV18BRYsCT58C338vR1k1awb8/juQmKh0tBKTGyIiItKJpyfwxRfAjRvAn38C778vk5+9e4EOHeS8OZMnA3fvKhsnkxsiIiLSi7U18MEHQFCQTHTGjQMKFQIePAC+/FImOStWKBcfkxsiIiLKNh8fYPp02WS1bh3QsKGcH6dBA+ViYnJDREREb83ODujUCTh4ELh9W86IrBQmN0RERGRQ3t7Kvj6TGyIiIrIoTG6IiIjIojC5ISIiIovC5IaIiIgsCpMbIiIisihMboiIiMiiMLkhIiIii8LkhoiIiCwKkxsiIiKyKExuiIiIyKIwuSEiIiKLwuSGiIiILAqTGyIiIrIoNkoHoAQhBAAgOjpa4UhMX2xsLABArVYrHAnpg+Vmflhm5onllrNSvrdTvsczkyuTm5iYGACAt9JrshMREZHeYmJi4Obmlul+lXhT+mOB1Go17t+/DxcXF6hUKqXDMWnR0dHw9vbGv//+C1dXV6XDIR2x3MwPy8w8sdxylhACMTEx8PLygpVV5j1rcmXNjZWVFd555x2lwzArrq6uvHDNEMvN/LDMzBPLLedkVWOTgh2KiYiIyKIwuSEiIiKLwuSGsmRvb4/JkyfD3t5e6VBIDyw388MyM08sN9OUKzsUExERkeVizQ0RERFZFCY3REREZFGY3BAREZFFYXJDREREFoXJjQU6fPgwWrVqBS8vL6hUKmzdulVrvxACkyZNQuHCheHo6IiAgABcu3ZN65inT5+iW7ducHV1Rd68efHRRx9p1lBJERISgnfffRcODg7w9vbGN998ky6WjRs3omzZsnBwcEDFihWxfft2g79fSzBjxgzUqFEDLi4uKFSoENq2bYuwsDCtY169eoXBgwcjf/78cHZ2Rvv27fHw4UOtY+7cuYOWLVvCyckJhQoVwqhRo5CUlKR1zMGDB1G1alXY29ujZMmSWL58ebp45s2bBx8fHzg4OKBWrVo4efKkwd+zuZs/fz4qVaqkmbytTp062LFjh2Y/y8v0zZw5EyqVCp999plmG8vNQgiyONu3bxdffPGF2Lx5swAgtmzZorV/5syZws3NTWzdulWcP39etG7dWhQvXly8fPlSc8x7770nKleuLP755x9x5MgRUbJkSdGlSxfN/ufPnwsPDw/RrVs3cfHiRbF27Vrh6OgoFi5cqDnm2LFjwtraWnzzzTfi8uXLYsKECcLW1lZcuHDB6J+BuQkMDBTLli0TFy9eFMHBweL9998XRYsWFbGxsZpjBg4cKLy9vcW+ffvE6dOnRe3atUXdunU1+5OSkkSFChVEQECAOHfunNi+fbsoUKCAGDdunOaYGzduCCcnJzF8+HBx+fJlMXfuXGFtbS127typOWbdunXCzs5OLF26VFy6dEn0799f5M2bVzx8+DBnPgwzsW3bNhEUFCSuXr0qwsLCxPjx44Wtra24ePGiEILlZepOnjwpfHx8RKVKlcSwYcM021luloHJjYV7PblRq9XC09NTzJ49W7MtKipK2Nvbi7Vr1wohhLh8+bIAIE6dOqU5ZseOHUKlUol79+4JIYT45ZdfhLu7u4iPj9ccM2bMGFGmTBnN444dO4qWLVtqxVOrVi0xYMAAg75HSxQZGSkAiEOHDgkhZBnZ2tqKjRs3ao4JDQ0VAMTx48eFEDKptbKyEhEREZpj5s+fL1xdXTXlNHr0aFG+fHmt1+rUqZMIDAzUPK5Zs6YYPHiw5nFycrLw8vISM2bMMPwbtTDu7u7i119/ZXmZuJiYGFGqVCmxZ88e0bBhQ01yw3KzHGyWymVu3ryJiIgIBAQEaLa5ubmhVq1aOH78OADg+PHjyJs3L6pXr645JiAgAFZWVjhx4oTmmAYNGsDOzk5zTGBgIMLCwvDs2TPNMWlfJ+WYlNehzD1//hwAkC9fPgDAmTNnkJiYqPV5li1bFkWLFtUqt4oVK8LDw0NzTGBgIKKjo3Hp0iXNMVmVSUJCAs6cOaN1jJWVFQICAlhuWUhOTsa6devw4sUL1KlTh+Vl4gYPHoyWLVum+2xZbpYjVy6cmZtFREQAgNaFmfI4ZV9ERAQKFSqktd/Gxgb58uXTOqZ48eLpzpGyz93dHREREVm+DmVMrVbjs88+Q7169VChQgUA8jO1s7ND3rx5tY59vdwy+rxT9mV1THR0NF6+fIlnz54hOTk5w2OuXLlisPdoKS5cuIA6derg1atXcHZ2xpYtW1CuXDkEBwezvEzUunXrcPbsWZw6dSrdPl5nloPJDZGJGTx4MC5evIijR48qHQq9QZkyZRAcHIznz59j06ZN6NWrFw4dOqR0WJSJf//9F8OGDcOePXvg4OCgdDhkRGyWymU8PT0BIF3v/4cPH2r2eXp6IjIyUmt/UlISnj59qnVMRudI+xqZHZOyn9IbMmQI/vrrLxw4cADvvPOOZrunpycSEhIQFRWldfzr5ZbdMnF1dYWjoyMKFCgAa2trlpuO7OzsULJkSVSrVg0zZsxA5cqVMWfOHJaXiTpz5gwiIyNRtWpV2NjYwMbGBocOHcJPP/0EGxsbeHh4sNwsBJObXKZ48eLw9PTEvn37NNuio6Nx4sQJ1KlTBwBQp04dREVF4cyZM5pj9u/fD7VajVq1ammOOXz4MBITEzXH7NmzB2XKlIG7u7vmmLSvk3JMyutQKiEEhgwZgi1btmD//v3pmvyqVasGW1tbrc8zLCwMd+7c0Sq3CxcuaCWme/bsgaurK8qVK6c5JqsysbOzQ7Vq1bSOUavV2LdvH8tNB2q1GvHx8SwvE9W0aVNcuHABwcHBmlv16tXRrVs3zX2Wm4VQukczGV5MTIw4d+6cOHfunAAgvv/+e3Hu3Dlx+/ZtIYQcCp43b17xxx9/iJCQENGmTZsMh4L7+/uLEydOiKNHj4pSpUppDQWPiooSHh4eokePHuLixYti3bp1wsnJKd1QcBsbG/Htt9+K0NBQMXnyZA4Fz8SgQYOEm5ubOHjwoHjw4IHmFhcXpzlm4MCBomjRomL//v3i9OnTok6dOqJOnTqa/SlDVJs3by6Cg4PFzp07RcGCBTMcojpq1CgRGhoq5s2bl+EQVXt7e7F8+XJx+fJl8fHHH4u8efNqjQ4hIcaOHSsOHTokbt68KUJCQsTYsWOFSqUSu3fvFkKwvMxF2tFSQrDcLAWTGwt04MABASDdrVevXkIIORx84sSJwsPDQ9jb24umTZuKsLAwrXM8efJEdOnSRTg7OwtXV1fRp08fERMTo3XM+fPnRf369YW9vb0oUqSImDlzZrpYNmzYIEqXLi3s7OxE+fLlRVBQkNHetznLqLwAiGXLlmmOefnypfjkk0+Eu7u7cHJyEu3atRMPHjzQOs+tW7dEixYthKOjoyhQoIAYMWKESExM1DrmwIEDokqVKsLOzk6UKFFC6zVSzJ07VxQtWlTY2dmJmjVrin/++ccYb9us9e3bVxQrVkzY2dmJggULiqZNm2oSGyFYXubi9eSG5WYZVEIIoUydEREREZHhsc8NERERWRQmN0RERGRRmNwQERGRRWFyQ0RERBaFyQ0RERFZFCY3REREZFGY3BAREZFFYXJDZEA7d+6Eu7s7Ro4cicOHD6NXr14Gf41bt25BpVIhODhY5+c0atQIn332mcFj0ceUKVNQpUoVRWPQlyl8bpZk+fLl6VbcJjIGJjdkdlQqVZa3KVOmKBbbli1bsHjxYrx8+RK9e/fGRx99pFgspmbkyJHp1tt5W9lJ9MyRpSRZnTp1wtWrVw16zoMHD0KlUqVb7JJyNxulAyDS14MHDzT3169fj0mTJiEsLEyzzdnZWYmwAAALFy4EAHTo0EGxGEyVs7OzomVj6YQQSE5Oho2N6f5Zd3R0hKOjo9JhUC7AmhsyO56enpqbm5sbVCqV5vGLFy/QrVs3eHh4wNnZGTVq1MDevXu1nu/j44OvvvoKPXv2hLOzM4oVK4Zt27bh0aNHaNOmDZydnVGpUiWcPn1a85wnT56gS5cuKFKkCJycnFCxYkWsXbtW67yNGjXC0KFDMXr0aOTLlw+enp7papHu3LmjeQ1XV1d07NgRDx8+zPL9njx5Ev7+/nBwcED16tVx7ty5dMdcvHgRLVq0gLOzMzw8PNCjRw88fvxYr8/1zz//RI0aNeDg4IACBQqgXbt2mn3Pnj1Dz5494e7uDicnJ7Ro0QLXrl3T7E9pbti1axf8/Pzg7OyM9957TysRfb1ZKqPaiLZt26J3796axz4+Ppg+fTr69u0LFxcXFC1aFIsWLdLsT1k93d/fHyqVCo0aNQIgV1j+8ssv8c4778De3h5VqlTBzp07s3z/L1680PxOFC5cGN999126Y+Lj4zFy5EgUKVIEefLkQa1atXDw4MEszxsVFYV+/fqhYMGCcHV1RZMmTXD+/Pl0n8tvv/0GHx8fuLm5oXPnzoiJiQEA9O7dG4cOHcKcOXM0tZO3bt3S1Fjs2LED1apVg729PY4ePQq1Wo0ZM2agePHicHR0ROXKlbFp0ybN66U8b9++fahevTqcnJxQt25drX8Qrl+/jjZt2hj8OsqoWeqPP/5A1apV4eDggBIlSmDq1KlISkrS7FepVPj111/Rrl07ODk5oVSpUti2bRsAWXPXuHFjAIC7uztUKpXm9yc+Ph5Dhw5FoUKF4ODggPr16+PUqVNZlhVZEIXXtiJ6K8uWLRNubm6ax8HBwWLBggXiwoUL4urVq2LChAnCwcFBsyK6EEIUK1ZM5MuXTyxYsEBcvXpVDBo0SLi6uor33ntPbNiwQYSFhYm2bdsKPz8/oVarhRBC3L17V8yePVucO3dOXL9+Xfz000/C2tpanDhxQnPehg0bCldXVzFlyhRx9epVsWLFCq1VopOTk0WVKlVE/fr1xenTp8U///wjqlWrJho2bJjp+4uJiREFCxYUXbt2FRcvXhR//vmnKFGihAAgzp07J4QQ4tmzZ5pViUNDQ8XZs2dFs2bNROPGjbViS7s44Ov++usvYW1tLSZNmiQuX74sgoODxfTp0zX7W7duLfz8/MThw4dFcHCwCAwMFCVLlhQJCQmacrC1tRUBAQHi1KlT4syZM8LPz0907dpVc47JkyeLypUrZxlTmzZtNAu8pi2refPmiWvXrokZM2YIKysrceXKFSGEECdPnhQAxN69e8WDBw/EkydPhBBCfP/998LV1VWsXbtWXLlyRYwePVrY2tqKq1evZvoZDBo0SBQtWlTs3btXhISEiA8++EC4uLhoxdivXz9Rt25dcfjwYREeHi5mz54t7O3tszxvQECAaNWqlTh16pS4evWqGDFihMifP78m1smTJwtnZ2fxv//9T1y4cEEcPnxYeHp6ivHjxwshhIiKihJ16tQR/fv316wWn5SUpFkgt1KlSmL37t0iPDxcPHnyRHz11VeibNmyYufOneL69eti2bJlwt7eXhw8eFAIkbqwbq1atcTBgwfFpUuXxLvvvivq1q2ridlY19Hr1+vhw4eFq6urWL58ubh+/brYvXu38PHxEVOmTNEcA0C88847Ys2aNeLatWti6NChwtnZWTx58kQkJSWJ33//XQAQYWFh4sGDByIqKkoIIcTQoUOFl5eX2L59u7h06ZLo1auXcHd313zuZNmY3JBZe/2PZUbKly8v5s6dq3lcrFgx0b17d83jBw8eCABi4sSJmm3Hjx8XANKtBpxWy5YtxYgRIzSPGzZsKOrXr691TI0aNcSYMWOEEELs3r1bWFtbizt37mj2X7p0SQAQJ0+ezPA1Fi5cKPLnzy9evnyp2TZ//nyt5GbatGmiefPmWs/7999/NX/wU2LLKrmpU6eO6NatW4b7rl69KgCIY8eOabY9fvxYODo6ig0bNgghZDkAEOHh4Zpj5s2bJzw8PDSPs5vcpC0rtVotChUqJObPny+EEOLmzZtan0UKLy8v8fXXX2ttq1Gjhvjkk08yfI8xMTHCzs5O836EEOLJkyfC0dFRE+Pt27eFtbW1uHfvntZzmzZtKsaNG5fheY8cOSJcXV3Fq1evtLb7+vqKhQsXCiHk5+Lk5CSio6M1+0eNGiVq1aqleZzRZ5WSpGzdulWz7dWrV8LJyUn8/fffWsd+9NFHokuXLlrP27t3r2Z/UFCQAKD1e/Y6Q1xHr1+vTZs21UqihRDit99+E4ULF9Y8BiAmTJigeRwbGysAiB07dmi9n2fPnmkdY2trK1avXq3ZlpCQILy8vMQ333yT6Xsky2G6jbNE2RAbG4spU6YgKCgIDx48QFJSEl6+fIk7d+5oHVepUiXNfQ8PDwBAxYoV022LjIyEp6cnkpOTMX36dGzYsAH37t1DQkIC4uPj4eTklOl5AaBw4cKIjIwEAISGhsLb2xve3t6a/eXKlUPevHkRGhqKGjVqpHs/oaGhqFSpEhwcHDTb6tSpo3XM+fPnceDAgQz7s1y/fh2lS5fO4JPSFhwcjP79+2e4LzQ0FDY2NqhVq5ZmW/78+VGmTBmEhoZqtjk5OcHX11fzOO17fxtpP9OUJsiszhsdHY379++jXr16Wtvr1aun1RyU1vXr15GQkKD1HvPly4cyZcpoHl+4cAHJycnpPs/4+Hjkz58/w/OeP38esbGx6fa/fPkS169f1zz28fGBi4uL5rE+n1316tU198PDwxEXF4dmzZppHZOQkAB/f3+tbWk/18KFCwOQv+9FixY12nX0uvPnz+PYsWP4+uuvNduSk5Px6tUrxMXFaa6vtK+TJ08euLq6Zvn5XL9+HYmJiVq/A7a2tqhZs6bW7yxZLiY3ZFFGjhyJPXv24Ntvv0XJkiXh6OiIDh06ICEhQes4W1tbzX2VSpXpNrVaDQCYPXs25syZgx9//BEVK1ZEnjx58Nlnn2V53pTzpJzDWGJjY9GqVSvMmjUr3b6UL603MUQnz4zeuxAi0+OtrKzS7U9MTNTpvMb+TDMSGxsLa2trnDlzBtbW1lr7MusoHRsbi8KFC2fYLydt35O3eY958uTRej0ACAoKQpEiRbSOs7e313qc1e+7sa6j18XGxmLq1Kn43//+l25f2oTeVH4HyHwwuSGLcuzYMfTu3VvTGTY2Nha3bt0yyHnbtGmD7t27A5B/rK9evYpy5crpfA4/Pz/8+++/+PfffzW1N5cvX0ZUVFSm5/Hz88Nvv/2GV69eaf7Y//PPP1rHVK1aFb///jt8fHyyPVKmUqVK2LdvH/r06ZNhDElJSThx4gTq1q0LQHawDgsL0+v9v65gwYJaHY6Tk5Nx8eJFTQdRXdjZ2Wmem8LV1RVeXl44duwYGjZsqNl+7Ngx1KxZM8Pz+Pr6wtbWFidOnEDRokUByE7UV69e1ZzD398fycnJiIyMxLvvvqtTfFWrVkVERARsbGzg4+Oj8/t6nZ2dndZ7zEy5cuVgb2+PO3fuaL13fRnrOnpd1apVERYWhpIlS2b7HBn9Dvj6+sLOzg7Hjh1DsWLFAMjE+dSpUxYxpJ7ejKOlyKKUKlUKmzdvRnBwMM6fP4+uXbsa5D+8UqVKYc+ePfj7778RGhqKAQMGvHGU0+sCAgJQsWJFdOvWDWfPnsXJkyfRs2dPNGzYUKtpIa2uXbtCpVKhf//+uHz5MrZv345vv/1W65jBgwfj6dOn6NKlC06dOoXr169j165d6NOnj05fiAAwefJkrF27FpMnT0ZoaCguXLigqQkqVaoU2rRpg/79++Po0aM4f/48unfvjiJFiqBNmzZ6fQZpNWnSBEFBQQgKCsKVK1cwaNAgvecqKVSoEBwdHbFz5048fPgQz58/BwCMGjUKs2bNwvr16xEWFoaxY8ciODgYw4YNy/A8zs7O+OijjzBq1Cjs378fFy9eRO/evWFllfonsnTp0ujWrRt69uyJzZs34+bNmzh58iRmzJiBoKCgDM8bEBCAOnXqoG3btti9ezdu3bqFv//+G1988YXWKKI38fHxwYkTJ3Dr1i08fvw4099pFxcXjBw5Ep9//jlWrFiB69ev4+zZs5g7dy5WrFih8+sZ6zp63aRJk7By5UpMnToVly5dQmhoKNatW4cJEybofI5ixYpBpVLhr7/+wqNHjxAbG4s8efJg0KBBGDVqFHbu3InLly+jf//+iIuL49xTuQSTG7Io33//Pdzd3VG3bl20atUKgYGBqFq16lufd8KECahatSoCAwPRqFEjeHp6om3btnqdQ6VS4Y8//oC7uzsaNGiAgIAAlChRAuvXr8/0Oc7Ozvjzzz9x4cIF+Pv744svvkjX/JRSS5GcnIzmzZujYsWK+Oyzz5A3b16tL+esNGrUCBs3bsS2bdtQpUoVNGnSBCdPntTsX7ZsGapVq4YPPvgAderUgRAC27dvT9dcoI++ffuiV69emgSvRIkSetXaAICNjQ1++uknLFy4EF5eXppka+jQoRg+fDhGjBiBihUrYufOndi2bRtKlSqV6blmz56Nd999F61atUJAQADq16+PatWqaR2zbNky9OzZEyNGjECZMmXQtm1bnDp1SlPb8zqVSoXt27ejQYMG6NOnD0qXLo3OnTvj9u3bmv4ouhg5ciSsra1Rrlw5FCxYMF3fl7SmTZuGiRMnYsaMGfDz88N7772HoKAgzbB5XRjrOnpdYGAg/vrrL+zevRs1atRA7dq18cMPP2hqW3RRpEgRTJ06FWPHjoWHhweGDBkCAJg5cybat2+PHj16oGrVqggPD8euXbvg7u5u8PdBpkclsmoUJyIykHHjxuHIkSM4evSo0qEQkYVjzQ0RGZUQAtevX8e+fftQvnx5pcMholyAyQ0RGdXz589Rrlw52NnZYfz48UqHQ0S5AJuliIiIyKKw5oaIiIgsCpMbIiIisihMboiIiMiiMLkhIiIii8LkhoiIiCwKkxsiIiKyKExuiIiIyKIwuSEiIiKLwuSGiIiILMr/ActDKiXtwTQ3AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar en el gráfico de las curvas de aprendizaje que el modelo se comporta de forma correcta ajustandose al problema y obteniendo una buena generalización a medida que aumenta el tamaño del conjunto de muestras. Cuantos más datos se usan para entrenar el modelo, más generalización se consigue (al tener más información del problema y de la función objetivo) y por tanto el error $E_{out}$ se acerca cada vez más al error $E_{in}$. El modelo es capaz de ajustar mejor los datos cuantos menos muestras haya, ya que al haber menos datos, el modelo tiene que predecir menos muestras y entonces puede ajustarse mejor a una cantidad menor de datos, por lo tanto el error $E_{in}$ aumenta con el tamaño del conjunto de entrenamiento. En la curva de aprendizaje que obtenemos se ve esto al principio como el error $E_{in}$ aumenta al umentar el tamaño del conjunto pero despues sigue estable. Por otro lado, cuantos más muestras se tienen, más información se tiene del problema y por tanto se puede obtener una mayor generalización de la función objetivo obteniendo un error $E_{out}$ menor a medida que aumenta el tamaño del conjunto de muestras. Es por esto que los errores $E_{in}$ y $E_{out}$ tienden a acercarse y converger a medida que aumenta el tamaño del conjunto de entrenamiento.\n",
        "A partir de estos resultados podemos establecer que este modelo ha conseguido ajustarse bien al problema consiguiendo generalizar la función objteivo, como osbervarmos en la disminución del error $E_{out}$ a medida que aumenta el tamaño del conjunto de entrenamiento, ya que cuanta más información se le ofrece al modelo para entrenar, mejoes resultados y error $E_{out}$ obtiene y por tanto más aprende."
      ],
      "metadata": {
        "id": "AxvI8x1fFuXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusión"
      ],
      "metadata": {
        "id": "6cWMXcQZJ60Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta práctica hemos utilizado diversos modelos para tratar de ajustar un problema con un conjunto de datos asociado para obtener un clasificador final óptimo comparando entre los modelos utilizados. En concreto hemos utilizado un modelo lineal y dos modelos no lineales. El modelo lineal escogido ha sido Regresión Logística empleado mediante SGD, y los dos modelos no lineales escogidos han sido Perceptrón Multicapa empleando SGD para su entrenameinto y SVM Soft, como se ha explicado al principio. Tras evaluar los modelos junto con diversos valores de hiperparámetros de cada uno, hemos comparado sus resultados utilizando la técnica de Cross Validation con un Fold de 5 y hemos elegido el mejor modelo basándonos en los resultados de las métricas que hemos elegido para comparar los modelos. Finalmente hemos evaluado el modelo entrenado con todo el conjunto de entrenamiento a la hora de predecir las muestras del conjunto de test y hemos analizado los resultados obtenidos.\n",
        "\n",
        " Por el proceso que hemos seguido para obtener el modelo final, la solución final obtenida es el mejor resultado posible que hemos obtenido para la muestra dada, ya que en primer lugar hemos elegido los modelos específicos mejores las propiedades del problema, hemos elegido las métricas también acorde con las características de la base de datos de la que disponíamos junto con las funciones de pérdida para los algoritmos de aprendizaje, hemos utilizado técnicas como Cross Validation para obtener una comparación precisa entre los modelos y elegir los hiperparámetros adecuados y finalmente hemos comprobado que la solución final se ajusta correctamente al problema, obteniendo el error $E_{out}$ y los resultados de las métricas sobre el conjunto de test que nos indican que hemos obtenido una buena solución, y obteniendo las curvas de aprendizaje que nos indican la buena generalización que ha obtenido el modelo para este problema con este conjunto de muestras."
      ],
      "metadata": {
        "id": "NQ0A38_5KDXn"
      }
    }
  ]
}